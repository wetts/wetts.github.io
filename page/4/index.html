<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wetts.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Stay Hungry, Stay Foolish. [build by hexo&#x2F;next&#x2F;gitalk&#x2F;hexo-generator-search&#x2F;LaTeX]">
<meta property="og:type" content="website">
<meta property="og:title" content="Wetts&#39;s blog">
<meta property="og:url" content="https://wetts.github.io/page/4/index.html">
<meta property="og:site_name" content="Wetts&#39;s blog">
<meta property="og:description" content="Stay Hungry, Stay Foolish. [build by hexo&#x2F;next&#x2F;gitalk&#x2F;hexo-generator-search&#x2F;LaTeX]">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Zhang Wetts">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://wetts.github.io/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Wetts's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Wetts's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Stay Hungry, Stay Foolish.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/wetts" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/19/%E5%B7%A5%E5%85%B7/VSCode/VSCode-%E5%BF%AB%E6%8D%B7%E9%94%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/19/%E5%B7%A5%E5%85%B7/VSCode/VSCode-%E5%BF%AB%E6%8D%B7%E9%94%AE/" class="post-title-link" itemprop="url">VSCode-快捷键.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-19 21:38:32" itemprop="dateCreated datePublished" datetime="2020-05-19T21:38:32+08:00">2020-05-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/VSCode/" itemprop="url" rel="index"><span itemprop="name">VSCode</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><p>重命名并求改引用：<code>F2</code></p>
</li>
<li><p>格式化代码：<code>shift + alt + f</code> (Win、Mac)</p>
</li>
<li><p>workbench.files.action.showActiveFileInExplorer：<code>cmd + m</code> (Mac)</p>
</li>
<li><p>光标上一个位置：<code>ctrl + -</code> (Mac)</p>
</li>
<li><p>光标下一个位置：<code>ctrl + shift + -</code> (Mac)</p>
</li>
<li><p>code-runner 快速执行：<code>ctrl + alt + n</code></p>
</li>
<li><p>转换成大写：<code>shift + ctrl + u</code> (Mac)</p>
</li>
<li><p>转换成小写：<code>shift + ctrl + l</code> (Mac)</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" class="post-title-link" itemprop="url">目标检测.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-18 22:36:32" itemprop="dateCreated datePublished" datetime="2020-05-18T22:36:32+08:00">2020-05-18</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">机器视觉</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>滑动窗口目标检测<ul>
<li>缺点：计算成本</li>
</ul>
</li>
</ul>
<h3 id="评价对象检测算法"><a href="#评价对象检测算法" class="headerlink" title="评价对象检测算法"></a>评价对象检测算法</h3><p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E4%BA%A4%E5%B9%B6%E6%AF%94.png" alt="交并比"></p>
<p>一般约定，在计算机检测任务中，如果 $IoU \geq 0.5$，就说检测正确，如果预测器和实际边界框完美重叠，$IoU$ 就是 1，因为交集就等于并集。但一般来说只要 $IoU \geq 0.5$，那么结果是可以接受的，看起来还可以。一般约定，0.5 是阈值，用来判断预测的边界框是否正确。</p>
<h3 id="非极大值抑制（Non-max-suppression）"><a href="#非极大值抑制（Non-max-suppression）" class="headerlink" title="非极大值抑制（Non-max suppression）"></a>非极大值抑制（Non-max suppression）</h3><p>算法可能对同一个对象做出多次检测，所以算法不是对某个对象检测出一次，而是检测出多次。非极大值抑制这个方法可以确保你的算法对每个对象只检测一次。</p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E9%9D%9E%E6%9E%81%E5%A4%A7%E6%8A%91%E5%88%B6.png" alt="非极大抑制"></p>
<p>这个 $p_c$ 检测概率，首先看概率最大的那个，这个例子（右边车辆）中是 0.9，然后就说这是最可靠的检测，所以我们就用高亮标记，就说我这里找到了一辆车。这么做之后，非极大值抑制就会逐一审视剩下的矩形，所有和这个最大的边框有很高交并比，高度重叠的其他边界框，那么这些输出就会被抑制。所以这两个矩形 $p_c$ 分别是 0.6 和 0.7，这两个矩形和淡蓝色矩形重叠程度很高，所以会被抑制，变暗，表示它们被抑制了。</p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E9%9D%9E%E6%9E%81%E5%A4%A7%E6%8A%91%E5%88%B62.png" alt="非极大抑制2"></p>
<p>接下来，逐一审视剩下的矩形，找出概率最高，$p_c$ 最高的一个，在这种情况下是 0.8，我们就认为这里检测出一辆车（左边车辆），然后非极大值抑制算法就会去掉其他 $IoU$ 值很高的矩形。所以现在每个矩形都会被高亮显示或者变暗，如果你直接抛弃变暗的矩形，那就剩下高亮显示的那些，这就是最后得到的两个预测结果。</p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E9%9D%9E%E6%9E%81%E5%A4%A7%E6%8A%91%E5%88%B63.png" alt="非极大抑制3"></p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E9%9D%9E%E6%9E%81%E5%A4%A7%E6%8A%91%E5%88%B6%E7%AE%97%E6%B3%95.png" alt="非极大抑制算法"></p>
<h3 id="Anchor-Boxes"><a href="#Anchor-Boxes" class="headerlink" title="Anchor Boxes"></a>Anchor Boxes</h3><p>对象检测中存在的一个问题是每个格子只能检测出一个对象，如果你想让一个格子检测出多个对象，你可以这么做，就是使用 anchor box 这个概念。</p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/AnchorBoxes.png" alt="AnchorBoxes"></p>
<p>对于这个例子，我们继续使用3×3网格，注意行人的中点和汽车的中点几乎在同一个地方，两者都落入到同一个格子中。所以对于那个格子，如果 $y$ 输出这个向量$y= \ \begin{bmatrix} p_{c} \ b_{x} \ b_{y} \ b_{h} \ b_{w} \ c_{1} \ c_{2}\ c_{3} \\end{bmatrix}$，你可以检测这三个类别，行人、汽车和摩托车，它将无法输出检测结果，所以我必须从两个检测结果中选一个。</p>
<p>而<strong>anchor box</strong>的思路是，这样子，预先定义两个不同形状的<strong>anchor box</strong>，或者<strong>anchor box</strong>形状，你要做的是把预测结果和这两个<strong>anchor box</strong>关联起来。一般来说，你可能会用更多的<strong>anchor box</strong>，可能要5个甚至更多，但对于这个视频，我们就用两个<strong>anchor box</strong>，这样介绍起来简单一些。</p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/AnchorBoxes2.png" alt="AnchorBoxes2"></p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/AnchorBoxes3.png" alt="AnchorBoxes3"></p>
<p>你要做的是定义类别标签，用的向量不再是上面这个$\begin{bmatrix} p_{c} &amp; b_{x} &amp;b_{y} &amp; b_{h} &amp; b_{w} &amp; c_{1} &amp; c_{2} &amp; c_{3} \\end{bmatrix}^{T}$，而是重复两次，$y=  \begin{bmatrix} p_{c} &amp; b_{x} &amp; b_{y} &amp;b_{h} &amp; b_{w} &amp; c_{1} &amp; c_{2} &amp; c_{3} &amp; p_{c} &amp; b_{x} &amp; b_{y} &amp; b_{h} &amp; b_{w} &amp;c_{1} &amp; c_{2} &amp; c_{3} \\end{bmatrix}^{T}$，前面的$p_{c},b_{x},b_{y},b_{h},b_{w},c_{1},c_{2},c_{3}$（绿色方框标记的参数）是和<strong>anchor box 1</strong>关联的8个参数，后面的8个参数（橙色方框标记的元素）是和<strong>anchor box 2</strong>相关联。因为行人的形状更类似于<strong>anchor box 1</strong>的形状，而不是<strong>anchor box 2</strong>的形状，所以你可以用这8个数值（前8个参数），这么编码$p_{c} =1$，是的，代表有个行人，用$b_{x},b_{y},b_{h}$和$b_{w}$来编码包住行人的边界框，然后用$c_{1},c_{2},c_{3}$($c_{1}= 1,c_{2} = 0,c_{3} = 0$)来说明这个对象是个行人。</p>
<p>然后是车子，因为车子的边界框比起<strong>anchor box 1</strong>更像<strong>anchor box 2</strong>的形状，你就可以这么编码，这里第二个对象是汽车，然后有这样的边界框等等，这里所有参数都和检测汽车相关($p_{c}= 1,b_{x},b_{y},b_{h},b_{w},c_{1} = 0,c_{2} = 1,c_{3} = 0$)。</p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/AnchorBoxes%E7%AE%97%E6%B3%95.png" alt="AnchorBoxes算法"></p>
<p>总结一下，用<strong>anchor box</strong>之前，你做的是这个，对于训练集图像中的每个对象，都根据那个对象中点位置分配到对应的格子中，所以输出$y$就是3×3×8，因为是3×3网格，对于每个网格位置，我们有输出向量，包含$p_{c}$，然后边界框参数$b_{x},b_{y},b_{h}$和$b_{w}$，然后$c_{1},c_{2},c_{3}$。</p>
<p>现在用到<strong>anchor box</strong>这个概念，是这么做的。现在每个对象都和之前一样分配到同一个格子中，分配到对象中点所在的格子中，以及分配到和对象形状交并比最高的<strong>anchor box</strong>中。所以这里有两个<strong>anchor box</strong>，你就取这个对象，如果你的对象形状是这样的（编号1，红色框），你就看看这两个<strong>anchor box</strong>，<strong>anchor box 1</strong>形状是这样（编号2，紫色框），<strong>anchor box 2</strong>形状是这样（编号3，紫色框），然后你观察哪一个<strong>anchor box</strong>和实际边界框（编号1，红色框）的交并比更高，不管选的是哪一个，这个对象不只分配到一个格子，而是分配到一对，即（<strong>grid cell，anchor box</strong>）对，这就是对象在目标标签中的编码方式。所以现在输出 $y$ 就是3×3×16，上一张幻灯片中你们看到 $y$ 现在是16维的，或者你也可以看成是3×3×2×8，因为现在这里有2个<strong>anchor box</strong>，而 $y$ 是8维的。$y$ 维度是8，因为我们有3个对象类别，如果你有更多对象，那么$y$ 的维度会更高。</p>
<h3 id="YOLO-算法（Putting-it-together-YOLO-algorithm）"><a href="#YOLO-算法（Putting-it-together-YOLO-algorithm）" class="headerlink" title="YOLO 算法（Putting it together: YOLO algorithm）"></a>YOLO 算法（Putting it together: YOLO algorithm）</h3><h3 id="候选区域（Region-proposals）"><a href="#候选区域（Region-proposals）" class="headerlink" title="候选区域（Region proposals）"></a>候选区域（Region proposals）</h3><p>滑动窗法，使用训练过的分类器，在这些窗口中全部运行一遍，然后运行一个检测器，看看里面是否有车辆，行人和摩托车。现在也可以运行一下卷积算法，这个算法的其中一个缺点是，它在显然没有任何对象的区域浪费时间。</p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F.png" alt="候选区域"></p>
<p>所以这里这个矩形区域（编号1）基本是空的，显然没有什么需要分类的东西。也许算法会在这个矩形上（编号2）运行，而你知道上面没有什么有趣的东西。</p>
<p><strong>R-CNN</strong>的算法，意思是带区域的卷积网络，或者说带区域的<strong>CNN</strong>。这个算法尝试选出一些区域，在这些区域上运行卷积网络分类器是有意义的，所以这里不再针对每个滑动窗运行检测算法，而是只选择一些窗口，在少数窗口上运行卷积网络分类器。</p>
<p>选出候选区域的方法是运行图像分割算法，分割的结果是下边的图像，为了找出可能存在对象的区域。比如说，分割算法在这里得到一个色块，所以你可能会选择这样的边界框（编号1），然后在这个色块上运行分类器，就像这个绿色的东西（编号2），在这里找到一个色块，接下来我们还会在那个矩形上（编号2）运行一次分类器，看看有没有东西。在这种情况下，如果在蓝色色块上（编号3）运行分类器，希望你能检测出一个行人，如果你在青色色块(编号4)上运行算法，也许你可以发现一辆车，我也不确定。</p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/%E5%80%99%E9%80%89%E5%8C%BA%E5%9F%9F2.png" alt="候选区域2"></p>
<p><img src="/2020/05/18/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/RCNN.png" alt="RCNN"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/15/%E8%AF%AD%E8%A8%80/Python/%E7%8E%AF%E5%A2%83/Python-%E6%8D%A2pip%E6%BA%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/15/%E8%AF%AD%E8%A8%80/Python/%E7%8E%AF%E5%A2%83/Python-%E6%8D%A2pip%E6%BA%90/" class="post-title-link" itemprop="url">Python-换pip源.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-15 19:00:24" itemprop="dateCreated datePublished" datetime="2020-05-15T19:00:24+08:00">2020-05-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="临时使用"><a href="#临时使用" class="headerlink" title="临时使用"></a>临时使用</h2><p>清华源：<code>-i https://pypi.tuna.tsinghua.edu.cn/simple</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">https://pypi.tuna.tsinghua.edu.cn/simple/	# 清华大学</span><br><span class="line">https://mirrors.aliyun.com/pypi/simple/		# 阿里云</span><br><span class="line">https://pypi.douban.com/simple/				# 豆瓣</span><br><span class="line">https://pypi.mirrors.ustc.edu.cn/simple/	# 中国科学技术大学</span><br></pre></td></tr></table></figure>

<h2 id="设为默认"><a href="#设为默认" class="headerlink" title="设为默认"></a>设为默认</h2><p>修改 <code>~/.config/pip/pip.conf</code>（Linux），<code>%APPDATA%\pip\pip.ini</code>（Windows 10）或 <code>$HOME/Library/Application Support/pip/pip.conf</code>（macOS）（没有就创建一个），修改 index-url 至 tuna，例如</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure>

<p>pip 和 pip3 并存时，只需修改 <code>~/.pip/pip.conf</code>。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7/" class="post-title-link" itemprop="url">Java-关键字-violate的有序性.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-13 22:03:52" itemprop="dateCreated datePublished" datetime="2020-05-13T22:03:52+08:00">2020-05-13</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_21729419/article/details/113733500">https://blog.csdn.net/qq_21729419/article/details/113733500</a></p>
<h2 id="中心思想"><a href="#中心思想" class="headerlink" title="中心思想"></a>中心思想</h2><p>使普通全局变量的写对其他线程立即可见（使用volatile有序性来传递）</p>
<h2 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>先来一堆有必要的废话</p>
<ul>
<li>LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</li>
<li>StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。</li>
<li>LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。</li>
<li>StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。</li>
</ul>
<p>Java内存模型允许编译器和处理器对指令重排序以提高运行性能，并且只会对不存在数据依赖性的指令重排序。</p>
<p>为了实现volatile的有序性内存语义(jdk5之后)，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。</p>
<ul>
<li>在每个volatile写操作的前面插入一个StoreStore屏障。</li>
<li>在每个volatile写操作的后面插入一个StoreLoad屏障。</li>
<li>在每个volatile读操作的前面插入一个LoadLoad屏障。</li>
<li>在每个volatile读操作的后面插入一个LoadStore屏障</li>
</ul>
<p>volatile写操作插入内存屏障后生成的指令序列如下图所示。<br><img src="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7/1.jpeg" alt="1"></p>
<p>volatile读操作插入内存屏障后生成的指令序列如下图所示。<br><img src="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7/2.jpeg" alt="2"></p>
<p>传递性 ：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。</p>
<p>相信大家对上面的内容很熟悉了，但是代表啥意思呢，估计你还是一头雾水。我们举个例子</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">int e = 0;</span><br><span class="line">volatile f = 0;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">//thread 1</span><br><span class="line">e = 1;    //操作 A</span><br><span class="line">f = 1;    //操作 B</span><br><span class="line"> </span><br><span class="line">//thread 2</span><br><span class="line"> </span><br><span class="line">int j = f;   //操作 C</span><br><span class="line">int k = e;    //操作 D</span><br></pre></td></tr></table></figure>

<p>我们假设 thread 1 执行结束之后thread 2执行，由于f是volatile变量，那么可知B操作的写,对于C操作的读是可见的。那么可得B先发生与C,每个线程单独来看， A先发生与B, C先发生与D,最后我们再加上传递性可知。</p>
<p>A-&gt;B-&gt;C-&gt;D</p>
<p>至此我们可以得到普通变量e的的写入对于其他线程立即可见（注意变量f在其中起到的作用）</p>
<p>Reentrantlock 也借助了volatile的这个特性</p>
<h2 id="总结一下有序性的含义"><a href="#总结一下有序性的含义" class="headerlink" title="总结一下有序性的含义"></a>总结一下有序性的含义</h2><ol>
<li>禁止指令重排</li>
<li>volatile写会将线程工作缓存（cpu缓存）中的所有数据写入主存</li>
<li>volatile读会将线程工作缓存（cpu缓存）中的所有数据失效，读的时候需要从主存中取。</li>
</ol>
<h2 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h2><p>前面举的例子比较难测试出反例（对普通变量的写，不通过volatile的有序性保证，其他线程不是立即可见），所以写了下面的测试代码。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">static int a = 0;</span><br><span class="line">static volatile int b = 0;  //去掉volatile修饰会发生死循环，即变量a对于其他线程不是立即可见</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">    Thread thread = new Thread(() -&gt; &#123;</span><br><span class="line">        while(a==0) &#123;</span><br><span class="line">            int c = b;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    thread.start();</span><br><span class="line"></span><br><span class="line">    Thread.sleep(200);</span><br><span class="line"></span><br><span class="line">    new Thread(() -&gt; &#123;</span><br><span class="line">        a = 1;</span><br><span class="line">        b = 1;</span><br><span class="line">    &#125;).start();</span><br><span class="line">    </span><br><span class="line">    thread.join();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate/" class="post-title-link" itemprop="url">Java-关键字-violate.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-13 21:43:05" itemprop="dateCreated datePublished" datetime="2020-05-13T21:43:05+08:00">2020-05-13</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zzti_erlie/article/details/86355477">https://blog.csdn.net/zzti_erlie/article/details/86355477</a></p>
<h2 id="极简计算机发展史"><a href="#极简计算机发展史" class="headerlink" title="极简计算机发展史"></a>极简计算机发展史</h2><p>我们知道，计算机CPU和内存的交互是最频繁的，内存是我们的高速缓存区。而刚开始用户磁盘和CPU进行交互，CPU运转速度越来越快，磁盘远远跟不上CPU的读写速度，才设计了内存，但是随着CPU的发展，内存的读写速度也远远跟不上CPU的读写速度，因此，为了解决这一纠纷，CPU厂商在每颗CPU上加入了高速缓存，用来缓解这种症状，因此，现在CPU同内存交互就变成了下面的样子。</p>
<p><img src="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate/1.png" alt="1"></p>
<p>单核CPU的性能不可能无限制的增长，要想很多的提升新能，需要多个处理器协同工作。 基于高速缓存的存储交互很好的解决了处理器与内存之间的矛盾，也引入了新的问题：缓存一致性问题。在多处理器系统中，每个处理器有自己的高速缓存，而他们又共享同一块内存（下文成主存，main memory 主要内存），当多个处理器运算都涉及到同一块内存区域的时候，就有可能发生缓存不一致的现象。为了解决这一问题，需要各个处理器运行时都遵循一些协议，在运行时需要用这些协议保证数据的一致性。</p>
<p><img src="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate/2.png" alt="2"></p>
<p>缓存一致性协议中最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存设置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中该变量是无效状态，那么它就会从内存重新读取</p>
<h2 id="Java内存模型"><a href="#Java内存模型" class="headerlink" title="Java内存模型"></a>Java内存模型</h2><p>Java的内存模型和上面的结构还是挺相似的，此时在看工作内存和主内存关系，从逻辑上，高速缓存对应工作内存，每个线程分配到CPU时间片时，独自享有高速缓存的使用能力。主内存对应存储的物理内存。特别注意，这只是逻辑上的对等关系，物理的上具体对应关系十分复杂，这里不讨论。</p>
<p><img src="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate/3.png" alt="3"></p>
<h2 id="volatile的作用是什么？"><a href="#volatile的作用是什么？" class="headerlink" title="volatile的作用是什么？"></a>volatile的作用是什么？</h2><p>volatile可以保证可见性，有序性，但不能保证原子性</p>
<h3 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h3><p>可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值</p>
<p>假如说有2个线程对一个变量data进行操作，线程先会把主内存中的值缓存到工作内存，这样做的原因和上面提到的高速缓存类似，提高效率</p>
<p><img src="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate/4.png" alt="4"></p>
<p>但是这样会引入新的问题，假如说线程A把data修改为1，线程A的工作内存data值为1，但是主内存和线程B的工作内存data值为0，此时就有可能出现Java并发编程中的可见性问题</p>
<p><img src="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate/5.png" alt="5"></p>
<p>举个例子，如下面代码，线程A已经将flag的值改变，但是线程B并没有及时的感知到，导致一直进行死循环</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">public class Test &#123;</span><br><span class="line"></span><br><span class="line">    public static boolean flag = false;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        new Thread(()-&gt;&#123;</span><br><span class="line">            while(!flag) &#123;</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(&quot;threadB end&quot;);</span><br><span class="line">        &#125;).start();</span><br><span class="line"></span><br><span class="line">        try &#123;</span><br><span class="line">            TimeUnit.SECONDS.sleep(1);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        new Thread(()-&gt;&#123;</span><br><span class="line">            flag = true;</span><br><span class="line">            System.out.println(&quot;threadA end&quot;);</span><br><span class="line">        &#125;).start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出为，线程B一直没有结束</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">threadA end</span><br></pre></td></tr></table></figure>

<p>但是如果将data定义为如下形式，线程A对data的变更，线程B立马能感知到</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public static volatile boolean flag = false;</span><br></pre></td></tr></table></figure>

<p>输出为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">threadA end</span><br><span class="line">threadB end</span><br></pre></td></tr></table></figure>

<p>那么是如何实现的呢？其实volatile保证可见性的方式和上面提到的缓存一致性协议的原理很类似</p>
<ol>
<li>线程A将工作内存的data更改后，强制将data值刷回主内存</li>
<li>如果线程B的工作内存中有data变量的缓存时，会强制让这个data变量缓存失效</li>
<li>当线程B需要读取data变量的值时，先从工作内存中读，发现已经过期，就会从主内存中加载data变量的最新值了</li>
</ol>
<p><img src="/2020/05/13/%E8%AF%AD%E8%A8%80/Java/basic_Java/%E5%85%B3%E9%94%AE%E5%AD%97/Java-%E5%85%B3%E9%94%AE%E5%AD%97-violate/6.png" alt="6"></p>
<h3 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h3><p>有序性即程序执行的顺序按照代码的先后顺序执行</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int i = 0;              </span><br><span class="line">boolean flag = false;</span><br><span class="line">i = 1;                //语句1  </span><br><span class="line">flag = true;          //语句2</span><br></pre></td></tr></table></figure>

<p>上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。</p>
<p>下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。</p>
<p>比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。</p>
<p>但是有依赖关系的语句不会进行重排序，如下面求圆面积的代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">double pi = 4.14   //A</span><br><span class="line">double r = 1.0     //B</span><br><span class="line">double area = pi * r * r   //c </span><br></pre></td></tr></table></figure>

<p>程序的执行顺序只有下面这2个形式：A-&gt;B-&gt;C和B-&gt;A-&gt;C，因为A和C之间存在依赖关系，同时B和C之间也存在依赖关系。因此最终执行的指令序列中C不能被重排序到A和B前面。</p>
<p>虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">//线程1:</span><br><span class="line">context = loadContext();   //语句1</span><br><span class="line">inited = true;             //语句2</span><br><span class="line"> </span><br><span class="line">//线程2:</span><br><span class="line">while(!inited )&#123;</span><br><span class="line">  sleep()</span><br><span class="line">&#125;</span><br><span class="line">doSomethingwithconfig(context);</span><br></pre></td></tr></table></figure>

<p>上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。</p>
<p>从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性</p>
<p>当写双重检测锁定版本的单例模式时，就要用到volatile来保证可见性</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">public class Singleton &#123;</span><br><span class="line"></span><br><span class="line">   private volatile static Singleton uniqueInstance;</span><br><span class="line"></span><br><span class="line">   private Singleton() &#123;&#125;</span><br><span class="line"></span><br><span class="line">   public static Singleton getInstance() &#123;</span><br><span class="line">       if (uniqueInstance == null) &#123;</span><br><span class="line">           synchronized (Singleton.class) &#123;</span><br><span class="line">               if (uniqueInstance == null) &#123;</span><br><span class="line">                   uniqueInstance = new Singleton();</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       return uniqueInstance;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h3><p>原子性即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public class Test &#123;</span><br><span class="line"></span><br><span class="line">    public static volatile int inc = 0;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        //新建一个线程池</span><br><span class="line">        ExecutorService service = Executors.newCachedThreadPool();</span><br><span class="line">        //Java8 lambda表达式执行runnable接口</span><br><span class="line">        for (int i = 0; i &lt; 5; i++) &#123;</span><br><span class="line">            service.execute(() -&gt; &#123;</span><br><span class="line">                for (int j = 0; j &lt; 1000; j++) &#123;</span><br><span class="line">                    inc++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        //关闭线程池</span><br><span class="line">        service.shutdown();</span><br><span class="line">        try &#123;</span><br><span class="line">            TimeUnit.SECONDS.sleep(2);</span><br><span class="line">        &#125; catch (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(&quot;inc = &quot; + inc);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>执行上述代码结果并不是每次都是5000，表明volatile并不能保证原子</p>
<p>可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有5个线程分别进行了1000次操作，那么最终inc的值应该是1000*5=5000。</p>
<p>这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。</p>
<p>在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：</p>
<p>假如某个时刻变量inc的值为10，</p>
<p>线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，也不会导致主存中的值刷新，所以线程2会直接去主存读取inc的值（这个部分小编感觉是海子大佬的笔误，应该是线程2会直接去工作内存读取inc的值，因为工作内存中inc并没有失效），发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。</p>
<p>然后线程1接着进行加1操作，由于已经读取了inc的值（inc++，包括3个操作，1.读取inc的值，2.进行加1操作，3.写入新的值），注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。</p>
<p>那么两个线程分别进行了一次自增操作后，inc只增加了1。</p>
<p>根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。</p>
<p>解决方案：可以通过synchronized或lock，进行加锁，来保证操作的原子性。也可以通过使用AtomicInteger</p>
<p>应用</p>
<ol>
<li>状态标记量</li>
<li>单例模式中的double check</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/12/artificial_intelligence/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/12/artificial_intelligence/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" class="post-title-link" itemprop="url">几种常见的损失函数.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-12 23:51:39" itemprop="dateCreated datePublished" datetime="2020-05-12T23:51:39+08:00">2020-05-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" itemprop="url" rel="index"><span itemprop="name">损失函数</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/lliuye/p/9549881.html">https://www.cnblogs.com/lliuye/p/9549881.html</a></p>
<hr>
<h2 id="损失函数、代价函数与目标函数"><a href="#损失函数、代价函数与目标函数" class="headerlink" title="损失函数、代价函数与目标函数"></a>损失函数、代价函数与目标函数</h2><ul>
<li>损失函数（Loss Function）：是定义在单个样本上的，是指一个样本的误差。</li>
<li>代价函数（Cost Function）：是定义在整个训练集上的，是所有样本误差的平均，也就是所有损失函数值的平均。</li>
<li>目标函数（Object Function）：是指最终需要优化的函数，一般来说是经验风险+结构风险，也就是（代价函数+正则化项）。</li>
</ul>
<h2 id="常用的损失函数"><a href="#常用的损失函数" class="headerlink" title="常用的损失函数"></a>常用的损失函数</h2><h3 id="0-1损失函数（0-1-loss-function）"><a href="#0-1损失函数（0-1-loss-function）" class="headerlink" title="0-1损失函数（0-1 loss function）"></a>0-1损失函数（0-1 loss function）</h3><p>$$<br>L(y, f(x))=\left{\begin{array}{ll}<br>1, &amp; y \neq f(x) \<br>0, &amp; y=f(x)<br>\end{array}\right.<br>$$</p>
<p>也就是说，当预测错误时，损失函数为 1，当预测正确时，损失函数值为 0。该损失函数不考虑预测值和真实值的误差程度。只要错误，就是 1。</p>
<h3 id="平方损失函数（quadratic-loss-function）"><a href="#平方损失函数（quadratic-loss-function）" class="headerlink" title="平方损失函数（quadratic loss function）"></a>平方损失函数（quadratic loss function）</h3><p>$$<br>L(y, f(x))=(y-f(x))^{2}<br>$$</p>
<p>是指预测值与实际值差的平方。</p>
<h3 id="绝对值损失函数（absolute-loss-function）"><a href="#绝对值损失函数（absolute-loss-function）" class="headerlink" title="绝对值损失函数（absolute loss function）"></a>绝对值损失函数（absolute loss function）</h3><p>$$<br>L(y, f(x))=|y-f(x)|<br>$$</p>
<p>该损失函数的意义和上面差不多，只不过是取了绝对值而不是求绝对值，差距不会被平方放大。</p>
<h3 id="对数损失函数（logarithmic-loss-function）"><a href="#对数损失函数（logarithmic-loss-function）" class="headerlink" title="对数损失函数（logarithmic loss function）"></a>对数损失函数（logarithmic loss function）</h3><p>$$<br>L(y, p(y | x))=-\log p(y | x)<br>$$</p>
<p>这个损失函数就比较难理解了。事实上，该损失函数用到了极大似然估计的思想。P(Y|X)通俗的解释就是：在当前模型的基础上，对于样本X，其预测值为Y，也就是预测正确的概率。由于概率之间的同时满足需要使用乘法，为了将其转化为加法，我们将其取对数。最后由于是损失函数，所以预测正确的概率越高，其损失值应该是越小，因此再加个负号取个反。</p>
<hr>
<p>对数损失是用于最大似然估计的。</p>
<p>一组参数在一堆数据下的似然值，等于每一条数据在这组参数下的条件概率之积。</p>
<p>而损失函数一般是每条数据的损失之和，为了把积变为和，就取了对数。</p>
<p>再加个负号是为了让最大似然值和最小损失对应起来。</p>
<h3 id="Hinge-loss"><a href="#Hinge-loss" class="headerlink" title="Hinge loss"></a>Hinge loss</h3><p>Hinge loss一般分类算法中的损失函数，尤其是SVM，其定义为：<br>$$<br>L(w, b)=\max {0,1-y f(x)}<br>$$<br>其中 $𝑦=+1$ 或 $𝑦=−1$，$f(𝑥)=wx+b$，当为SVM的线性核时。</p>
<h2 id="常用的代价函数"><a href="#常用的代价函数" class="headerlink" title="常用的代价函数"></a>常用的代价函数</h2><h3 id="均方误差（Mean-Squared-Error）"><a href="#均方误差（Mean-Squared-Error）" class="headerlink" title="均方误差（Mean Squared Error）"></a>均方误差（Mean Squared Error）</h3><p>$$<br>M S E=\frac{1}{N} \sum_{i=1}^{N}\left(y^{(i)}-f\left(x^{(i)}\right)\right)^{2}<br>$$<br>均方误差是指参数估计值与参数真值之差平方的期望值；MSE 可以评价数据的变化程度，MSE 的值越小，说明预测模型描述实验数据具有更好的精确度。（$i$ 表示第 $i$ 个样本，$N$ 表示样本总数）</p>
<p>通常用来做回归问题的代价函数。</p>
<h3 id="均方根误差"><a href="#均方根误差" class="headerlink" title="均方根误差"></a>均方根误差</h3><p>$$<br>R M S E=\sqrt{\frac{1}{N} \sum_{i=1}^{N}\left(y^{(i)}-f\left(x^{(i)}\right)\right)^{2}}<br>$$</p>
<p>均方根误差是均方误差的算术平方根，能够直观观测预测值与实际值的离散程度。</p>
<p>通常用来作为回归算法的性能指标。</p>
<h3 id="平均绝对误差（Mean-Absolute-Error）"><a href="#平均绝对误差（Mean-Absolute-Error）" class="headerlink" title="平均绝对误差（Mean Absolute Error）"></a>平均绝对误差（Mean Absolute Error）</h3><p>$$<br>M A E=\frac{1}{N} \sum_{i=1}^{N}\left|y^{(i)}-f\left(x^{(i)}\right)\right|<br>$$</p>
<p>平均绝对误差是绝对误差的平均值，平均绝对误差能更好地反映预测值误差的实际情况。</p>
<p>通常用来作为回归算法的性能指标。</p>
<h3 id="交叉熵代价函数（Cross-Entry）"><a href="#交叉熵代价函数（Cross-Entry）" class="headerlink" title="交叉熵代价函数（Cross Entry）"></a>交叉熵代价函数（Cross Entry）</h3><p>$$<br>H(p, q)=-\sum_{i=1}^{N} p\left(x^{(i)}\right) \log q\left(x^{(-i)}\right)<br>$$</p>
<p>交叉熵是用来评估当前训练得到的概率分布与真实分布的差异情况，减少交叉熵损失就是在提高模型的预测准确率。其中 $p(x)$ 是指真实分布的概率，$q(x)$ 是模型通过数据计算出来的概率估计。</p>
<p>比如对于二分类模型的交叉熵代价函数：<br>$$<br>L(w, b)=-\frac{1}{N} \sum_{i=1}^{N}\left(y^{(i)} \log f\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-f\left(x^{(i)}\right)\right)\right)<br>$$</p>
<p>其中 $f(x)$ 可以是sigmoid函数。或深度学习中的其它激活函数。而 $y^(i) \in 0, 1$。</p>
<p>通常用做分类问题的代价函数。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/" class="post-title-link" itemprop="url">Hadoop.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-10 12:58:16" itemprop="dateCreated datePublished" datetime="2020-05-10T12:58:16+08:00">2020-05-10</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Hadoop-的优化与发展"><a href="#Hadoop-的优化与发展" class="headerlink" title="Hadoop 的优化与发展"></a>Hadoop 的优化与发展</h2><h3 id="Hadoop-的局限与不足"><a href="#Hadoop-的局限与不足" class="headerlink" title="Hadoop 的局限与不足"></a>Hadoop 的局限与不足</h3><p>Hadoop1.0 的核心组件（仅指 MapReduce 和 HDFS，不包括 Hadoop 生态系统内的 Pig、Hive、HBase 等其他组件）主要存在以下不足。</p>
<ol>
<li>抽象层次低。需要手工编写代码来完成，有时只是为了实现一个简单的功能，也需要编写大量的代码。</li>
<li>表达能力有限。MapReduce 把复杂分布式编程工作高度抽象到两个函数上，即 Map 和 Reduce，在降低开发人员程序开发复杂度的同时，却也带来了表达能力有限的问题，实际生产环境中的一些应用是无法用简单的 Map 和 Reduce 来完成的。</li>
<li>开发者自己管理作业之间的依赖关系。一个作业（Job）只包含 Map 和 Reduce 两个阶段，通常的实际应用问题需要大量的作业进行协作才能顺利解决，这些作业之间往往存在复杂的依赖关系，但是 MapReduce 框架本身并没有提供相关的机制对这些依赖关系进行有效管理，只能由开发者自己管理。</li>
<li>难以看到程序整体逻辑。用户的处理逻辑都隐藏在代码细节中，没有更高层次的抽象机制对程序整体逻辑进行设计，这就给代码理解和后期维护带来了障碍。</li>
<li>执行迭代操作效率低。对于一些大型的机器学习、数据挖掘任务，往往需要多轮迭代才能得到结果。采用 MapReduce 实现这些算法时，每次迭代都是一次执行 Map、Reduce 任务的过程，这个过程的数据来自分布式文件系统 HDFS，本次迭代的处理结果也被存放到 HDFS 中，继续用于下一次迭代过程。反复读写 HDFS 文件中的数据，大大降低了迭代操作的效率。</li>
<li>资源浪费。在 MapReduce 框架设计中，Reduce 任务需要等待所有 Map 任务都完成后才可以开始，造成了不必要的资源浪费。</li>
<li>实时性差。只适用于离线批数据处理，无法支持交互式数据处理、实时数据处理。</li>
</ol>
<h3 id="针对-Hadoop-的改进与提升"><a href="#针对-Hadoop-的改进与提升" class="headerlink" title="针对 Hadoop 的改进与提升"></a>针对 Hadoop 的改进与提升</h3><p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/Hadoop1%E5%88%B02.png" alt="Hadoop1到2"></p>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/Hadoop%E7%A5%9E%E6%80%81%E7%B3%BB%E7%BB%9F.png" alt="Hadoop神态系统"></p>
<h2 id="HDFS2-0-的新特性"><a href="#HDFS2-0-的新特性" class="headerlink" title="HDFS2.0 的新特性"></a>HDFS2.0 的新特性</h2><p>相对于之前的 HDFS1.0 而言，HDFS2.0 增加了 HDFS HA 和 HDFS 联邦等新特性。</p>
<h3 id="HDFS-HA"><a href="#HDFS-HA" class="headerlink" title="HDFS HA"></a>HDFS HA</h3><p>对于分布式文件系统 HDFS 而言，名称节点（NameNode）是系统的核心节点，存储了各类元数据信息，并负责管理文件系统的命名空间和客户端对文件的访问。但是，在 HDFS1.0 中，只存在一个名称节点，一旦这个唯一的名称节点发生故障，就会导致整个集群变得不可用，这就是常说的“单点故障问题”。虽然 HDFS1.0 中存在一个“第二名称节点（Secondary NameNode）”，但是第二名称节点并不是名称节点的备用节点，它与名称节点有着不同的职责，其主要功能是周期性地从名称节点获取命名空间镜像文件（FsImage）和修改日志（EditLog），进行合并后再发送给名称节点，替换掉原来的 FsImage，以防止日志文件 EditLog 过大，导致名称节点失败恢复时消<br>耗过多时间。合并后的命名空间镜像文件 FsImage 在第二名称节点中也保存一份，当名称节点失效的时候，可以使用第二名称节点中的 FsImage 进行恢复。</p>
<p>由于第二名称节点无法提供“热备份”功能，即在名称节点发生故障的时候，系统无法实时切换到第二名称节点立即对外提供服务，仍然需要进行停机恢复，因此 HDFS1.0 的设计是存在单点故障问题的。为了解决单点故障问题，HDFS2.0 采用了 HA（High Availability）架构。在一个典型的 HA 集群中，一般设置两个名称节点，其中一个名称节点处于“活跃（Active）”状态，另一个处于“待命（Standby）”状态。处于活跃状态的名称节点负责对外处理所有客户端的请求，而处于待命状态的名称节点则作为备用节点，保存了足够多的系统元数据，当名称节点出现故障时提供快速恢复能力。也就是说，在 HDFS HA 中，处于待命状态的名称节点提供了“热备份”，一旦活跃名称节点出现故障，就可以立即切换到待命名称节点，不会影响到系统的正常对外服务。</p>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/HDFS%20HA.png" alt="HDFS HA"></p>
<p>由于待命名称节点是活跃名称节点的“热备份”，因此活跃名称节点的状态信息必须实时同步到待命名称节点。两种名称节点的状态同步，可以借助于一个共享存储系统来实现，比如 NFS（Network File Systerm）、QJM（Quorum Jourmal Manager）或者 Zookeeper。活跃名称节点将更新数据写人到共享存储系统，待命名称节点会一直监听该系统，一旦发现有新的写人，就立即从公共存储系统中读取这些数据并加载到自己的内存中，从而保证与活跃名称节点状态完全同步。</p>
<p>此外，名称节点中保存了数据块（Block）到实际存储位置的映射信息，即每个数据块是由哪个数据节点存储的。当一个数据节点加入 HDFS 集群时，它会把自己所包含的数据块列表报告给名称节点，此后会通过“心跳”的方式定期执行这种告知操作，以确保名称节点的块映射是最新的。因此，为了实现故障时的快速切换，必须保证待命名称节点一直包含最新的集群中各个块的位置信息。为了做到这一点，需要给数据节点配置两个名称节点的地址（即活跃名称节点和待命名称节点），并把块的位置信息和心跳信息同时发送到这两个名称节点。为了防止出现“两个管家”现象，HA 还要保证任何时刻都只有一个名称节点处于活跃状态，否则，如果有两个名称节点处于活跃状态，HDFS 集群中出现“两个管家”，就会导致数据丢失或者其他异常，这个任务是由 Zookeeper 来实现的，Zookeeper 可以确保任意时刻只有一个名称节点提供对外服务。</p>
<h3 id="HDFS-联邦"><a href="#HDFS-联邦" class="headerlink" title="HDFS 联邦"></a>HDFS 联邦</h3><h4 id="HDFS1-0-中存在的问题"><a href="#HDFS1-0-中存在的问题" class="headerlink" title="HDFS1.0 中存在的问题"></a>HDFS1.0 中存在的问题</h4><p>HDFS1.0 采用单名称节点的设计，不仅会带来单点故障问题，还存在可扩展性、性能和隔离性等问题。在可扩展性方面，名称节点把整个 HDFS 文件系统中的元数据信息都保存在自己的内存中，HDFS1.0 中只有一个名称节点，不可以水平扩展，而单个名称节点的内存空间是有上限的，这限制了系统中数据块、文件和目录的数目。是否可以通过纵向扩展的方式（即为单个名称节点增加更多的 CPU、内存等资源）解决这个问题呢？答案是否定的。纵向扩展带来的第一个问题就是，会带来过长的系统启动时间，比如一个具有 50 GB 内存的 HDFS 启动一次大概需要消耗 30min~2h，单纯增大内存空间只会让系统启动时间变得更长。其次，当在内存空间清理时发生错误，就会导致整个 HDFS 集群宕机。</p>
<p>在系统整体性能方面，整个 HDFS 文件系统的性能会受限于单个名称节点的吞吐量。在隔离性方面，单个名称节点难以提供不同程序之间的隔离性，一个程序可能会影响其他运行的程序（比如一个程序消耗过多资源导致其他程序无法顺利运行）。HDFS HA 虽然提供了两个名称节点，但是在某个时刻也只会有一个名称节点处于活跃状态，另个则处于待命状态。因而，HDFS HA 在本质上还是单名称节点，只是通过“热备份”设计方式解决了单点故障问题，并没有解决可扩展性、系统性能和隔离性三个方面的问题。</p>
<h4 id="HDFS-联邦的设计"><a href="#HDFS-联邦的设计" class="headerlink" title="HDFS 联邦的设计"></a>HDFS 联邦的设计</h4><p>HDFS 联邦可以很好地解决上述三个方面的问题。在 HDFS 联邦中，设计了多个相互独立的名称节点，使得 HDFS 的命名服务能够水平扩展，这些名称节点分别进行各自命名空间和块的管理，相互之间是联邦关系，不需要彼此协调。HDFS 联邦并不是真正的分布式设计，但是采用这种简单的“联合”设计方式，在实现和管理复杂性方面，都要远低于真正的分布式设计，而且可以快速满足需求。在兼容性方面，HDFS 联邦具有良好的向后兼容性，可以无缝地支持单名称节点架构中的配置。所以，原有针对单名称节点的部署配置，不需要作任何修改就可以继续工作。</p>
<p>HDFS 联邦中的名称节点提供了命名空间和块管理功能。在 HDFS 联邦中，所有名称节点会共享底层的数据节点存储资源。每个数据节点要向集群中所有的名称节点注册，并周期性地向名称节点发送“心跳”和块信息，报告自已的状态，同时也会处理来自名称节点的指令。</p>
<p>HDFS1.0 只有一个命名空间，这个命名空间使用底层数据节点全部的块。与 HDFS1.0 不同的是，HDFS 联邦拥有多个独立的命名空间，其中，每一个命名空间管理属于自己的一组块，这些属于同一个命名空间的块构成一个“块池”（Block Pool）。每个数据节点会为多个块池提供块的存储。可以看出，数据节点是一个物理概念，而块池则属于逻辑概念，一个块池是一组块的逻辑集合，块池中的各个块实际上是存储在各个不同的数据节点中的。因此，HDFS 联邦中的一个名称节点失效，也不会影响到与它相关的数据节点继续为其他名称节点提供服务。</p>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/HDFS%E8%81%94%E9%82%A6%E6%9E%B6%E6%9E%84.png" alt="HDFS联邦架构"></p>
<h4 id="HDFS-联邦的访问方式"><a href="#HDFS-联邦的访问方式" class="headerlink" title="HDFS 联邦的访问方式"></a>HDFS 联邦的访问方式</h4><p>对于 HDFS 联邦中的多个命名空间，可以采用客户端挂载表（Client Side Mount Table）方式进行数据共享和访问。每个阴影三角形代表一个独立的命名空间，上方空白三角形表示从客户方向去访问下面子命名空间。客户可以访问不同的挂载点来访问不同的子命名空间。这就是 HDFS 联邦中命名空间管理的基本原理，即把各个命名空间挂载到全局“挂载表”（Mount-table）中，实现数据全局共享；同样地，命名空间挂载到个人的挂载表中，就成为应用程序可见的命名空间。</p>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%8C%82%E8%BD%BD%E8%A1%A8%E6%96%B9%E5%BC%8F%E8%AE%BF%E9%97%AE%E5%A4%9A%E4%B8%AA%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4.png" alt="客户端挂载表方式访问多个命名空间"></p>
<h4 id="HDFS-联邦相对于-HDFS1-0-的优势"><a href="#HDFS-联邦相对于-HDFS1-0-的优势" class="headerlink" title="HDFS 联邦相对于 HDFS1.0 的优势"></a>HDFS 联邦相对于 HDFS1.0 的优势</h4><p>采用 HDFS 联邦的设计方式，可解决单名称节点存在的以下 3 个问题。</p>
<ol>
<li>HDFS 集群可扩展性。多个名称节点各自分管一部分目录，使得个集群可以扩展到更多节点，不再像 HDFS1.0 中那样由于内存的限制制约文件存储数目。</li>
<li>性能更高效。多个名称节点管理不同的数据，且同时对外提供服务，将为用户提供更高的读写吞吐率。</li>
<li>良好的隔离性。用户可根据需要将不同业务数据交由不同名称节点管理，这样不同业务之间影响很小。</li>
</ol>
<p>需要注意的是，HDFS 联邦并不能解决单点故障问题，也就是说，每个名称节点都存在单点故障问题，需要为每个名称节点部署一个后备名称节点，以应对名称节点宕机后对业务产生的影响。</p>
<h2 id="新一代资源管理调度框架-YARN"><a href="#新一代资源管理调度框架-YARN" class="headerlink" title="新一代资源管理调度框架 YARN"></a>新一代资源管理调度框架 YARN</h2><h3 id="MapReduce1-0-的缺陷"><a href="#MapReduce1-0-的缺陷" class="headerlink" title="MapReduce1.0 的缺陷"></a>MapReduce1.0 的缺陷</h3><p>MapReduce1.0 采用 Master/Slave 架构设计，包括二个 JobTracker 和若干个 TaskTracker，前者负责作业的调度和资源的管理，后者负责执行 JobTracker 指派的具体任务。这种架构设计具有一些很难克服的缺陷，具体如下。</p>
<ol>
<li>存在单点故障。由 JobTracker 负责所有 MapReduce 作业的调度，而系统中只有一个 JobTracker，因此会存在单点故障问题，即这个唯一的 JobTracker 出现故障就会导致系统不可用。</li>
<li>JobTracker“大包大揽”导致任务过重。JobTracker 既要负责作业的调度和失败恢复，又要负责资源管理分配。执行过多的任务，需要消耗大量的资源，例如，当存在非常多的 MapReduce 任务时，JobTracker 需要巨大的内存开销，这也潜在地增加了 JobTracker 失败的风险。正因如此，业内普遍总结出 MapReduce1.0 支持主机数目的上限为 4000 个。</li>
<li>容易出现内存溢出。在 TaskTracker 端，资源的分配并不考虑 CPU、内存的实际使用情况，而只是根据 MapReduce 任务的个数来分配资源，当两个具有较大内存消耗的任务被分配到同一个 TaskTracker 上时，很容易发生内存溢出的情况。</li>
<li>资源划分不合理。资源（CPU、内存）被强制等量划分成多个“槽”（Slot），槽又被进一步划分为 Map 槽和 Reduce 槽两种，分别供 Map 任务和 Reduce 任务使用，彼此之间不能使用分配给对方的槽，也就是说，当 Map 任务已经用完 Map 槽时，即使系统中还有大量剩余的 Reduce 槽，也不能拿来运行 Map 任务，反之亦然。这就意味着，当系统中只存在单一 Map 任务或 Reduce 任务时，会造成资源的浪费。</li>
</ol>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/MapReduce1.png" alt="MapReduce1"></p>
<h3 id="YARN-设计思路"><a href="#YARN-设计思路" class="headerlink" title="YARN 设计思路"></a>YARN 设计思路</h3><p>为了克服 MapReduce1.0 版本的缺陷，Hadoop2.0 以后的版本对其核心子项目 MapReduce1.0 的体系结构进行了重新设计，生成了 MapReduce2.0 和 YARN（Yet Another Resource Negotiator）。YARN 架构设计基本思路就是“放权”，即不让 JobTracker 这一个组件承担过多的功能，把原 JobTracker 三大功能（资源管理、任务调度和任务监控）进行拆分，分别交给不同的新组件去处理。重新设计后得到的 YARN 包括 ResourceManager 、ApplicationMaster 和 NodeManager，其中，由 ResourceManager 负责资源管理，由 ApplicationMaster 负责任务调度和监控，由 NodeManager 负责执行原 TaskTracker 的任务。通过这种“放权”的设计，大大降低了 JobTracker 的负担，提升了系统运行的效率和稳定性。</p>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/YARN%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF.png" alt="YARN架构设计思路"></p>
<p>在 Hadoop1.0 中，其核心子项目 MapReduce1.0 既是一个计算框架，也是一个资源管理调度框架。到了 Hadoop2.0 以后，MapReduce1.0 中的资源管理调度功能被单独分离出来形成了 YARN，它是一个纯粹的资源管理调度框架，而不是一个计算框架；而被剥离了资源管理调度功能的 MapReduce 框架就变成了 MapReduce2.0，它是运行在 YARN 之上的一个纯粹的计算框架，不再自己负责资源调度管理服务，而是由 YARN 为其提供资源管理调度服务。</p>
<h3 id="YARN-体系架构"><a href="#YARN-体系架构" class="headerlink" title="YARN 体系架构"></a>YARN 体系架构</h3><p>YARN 体系结构中包含了三个组件：ResourceManager、ApplicationMaster 和 NodeManager。</p>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/YARN%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.png" alt="YARN体系架构"></p>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/YARN%E5%90%84%E4%B8%AA%E7%BB%84%E4%BB%B6%E7%9A%84%E5%8A%9F%E8%83%BD.png" alt="YARN各个组件的功能"></p>
<p>ResourceManager（RM）是一个全局的资源管理器，负责整个系统的资源管理和分配，主要包括两个组件，即调度器（Scheduler）和应用程序管理器（Applications Manager）。调度器主要负责资源管理和分配，不再负责跟踪和监控应用程序的执行状态，也不负责执行失败恢复，因为这些任务都已经交给 ApplicationMaster 组件来负责。调度器接收来自 ApplicationMaster 的应用程序资源请求，并根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等)，把集群中的资源以“容器”的形式分配给提出申请的应用程序，容器的选择通常会考虑应用程序所要处理的数据的位置，进行就近选择，从而实现“计算向数据靠拢”。在 MapReduce1.0 中，资源分配的单位是“槽”，而在 YARN 中是以容器（Container）作为动态资源分配单位，每个容器中都封装了一定数量的 CPU、内存、磁盘等资源，从而限定每个应用程序可以使用的资源量。同时，在 YARN 中调度器被设计成是一个可插拔的组件，YARN 不仅自身提供了许多种直接可用的调度器，也允许用户根据自己的需求重新设计调度器。应用程序管理器负责系统中所有应用程序的管理工作，主要包括应用程序提交、与调度器协商资源以启动 ApplicationMaster、 监控 ApplicationMaster 运行状态并在失败时重新启动等。</p>
<p>在 Hadoop 平台上，用户的应用程序是以作业（Job）的形式提交的，然后一个作业会被分解成多个任务（包括 Map 任务和 Reduce 任务）进行分布式执行。ResourceManager 接收用户提交的作业，按照作业的上下文信息以及从 NodeManager 收集来的容器状态信息，启动调度过程，为用户作业启动一个 ApplicationMaster。</p>
<p>ApplicationMaster 的主要功能是: </p>
<ol>
<li>当用户作业提交时，ApplicationMaster 与 ResourceManager 协商获取资源，ResourceManager 会以容器的形式为 ApplicationMaster 分配资源；</li>
<li>把获得的资源进步分配给内部的各个任务（Map 任务或 Reduce 任务），实现资源的“二次分配”；</li>
<li>与 NodeManager 保持交互通信进行应用程序的启动、运行、监控和停止，监控申请到的资源的使用情况，对所有任务的执行进度和状态进行监控，并在任务发生失败时执行失败恢复（即重新申请资源重启任务）；</li>
<li>定时向 ResourceManager 发送“心跳”消息，报告资源的使用情况和应用的进度信息；</li>
<li>当作业完成时，ApplicationMaster 向 ResourceManager 注销容器，执行周期完成。</li>
</ol>
<p>NodeManager 是驻留在一个 YARN 集群中的每个节点上的代理，主要负责容器生命周期管理，监控每个容器的资源（CPU、内存等）使用情况，跟踪节点健康状况，并以“心跳”的方式与 ResourceManager 保持通信，向 ResourceManager 汇报作业的资源使用情况和每个容器的运行状态，同时，它还要接收来自 ApplicationMaster 的启动/停止容器的各种请求。需要说明的是，NodeManager 主要负责管理抽象的容器，只处理与容器相关的事情，而不具体负责每个任务（Map 任务或 Reduce 任务）自身状态的管理，因为这些管理工作是由 ApplicationMaster 完成的，ApplicationMaster 会通过不断与 NodeManager 通信来掌握各个任务的执行状态。</p>
<p>在集群部署方面，YARN 的各个组件是和 Hadoop 集群中的其他组件进行统一部署的。YARN 的 ResourceManager 组件和 HDFS 的名称节点（NameNode）部署在一个节点上，YARN 的 ApplicationMaster 及 NodeManager 是和 HDFS 的数据节点（DataNode）部署在一-起的。YARN 中的容器代表了 CPU、内存、网络等计算资源，它也是和 HDFS 的数据节点一起的。</p>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/YARN%E5%92%8CHadoop%E5%B9%B3%E5%8F%B0%E5%85%B6%E4%BB%96%E7%BB%84%E4%BB%B6%E7%9A%84%E7%BB%9F%E4%B8%80%E9%83%A8%E7%BD%B2.png" alt="YARN和Hadoop平台其他组件的统一部署"></p>
<h3 id="YARN-工作流程"><a href="#YARN-工作流程" class="headerlink" title="YARN 工作流程"></a>YARN 工作流程</h3><p>在 YARN 框架中执行一个 MapReduce 程序时，从提交到完成需要经历如下8个步骤。</p>
<ol>
<li>用户编写客户端应用程序，向 YARN 提交应用程序，提交的内容包括 ApplicationMaster 程序、启动 ApplicationMaster 的命令、用户程序等。</li>
<li>YARN 中的 ResourceManager 负责接收和处理来自客户端的请求。接到客户端应用程序请求后，ResourceManager 里面的调度器会为应用程序分配一个容器。同时，ResourceManager 的应用程序管理器会与该容器所在的 NodeManager 通信，为该应用程序在该容器中启动一个 ApplicationMaster。</li>
<li>ApplicationMaster 被创建后会首先向 ResourceManager 注册，从而使得用户可以通过 ResourceManager 来直接查看应用程序的运行状态。接下来的步骤4~7是具体的应用程序执行步骤。</li>
<li>ApplicationMaster 采用轮询的方式通过 RPC 协议向 ResourceManager 申请资源。</li>
<li>ResourceManager 以“容器”的形式向提出申请的 ApplicationMaster 分配资源，一旦 ApplicationMaster 申请到资源后，就会与该容器所在的 NodeManager 进行通信，要求它启动任务。</li>
<li>当 ApplicationMaster 要求容器启动任务时，它会为任务设置好运行环境（包括环境变量、JAR 包、二进制程序等），然后将任务启动命令写到一个脚本中，最后通过在容器中运行该脚本来启动任务。</li>
<li>各个任务通过某个 RPC 协议向 ApplicationMaster 汇报自己的状态和进度，让 AplicationMater 可以随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。</li>
<li>应用程序运行完成后，ApplicationMaster 向 ResourceManager 的应用程序管理器注销并关闭自己。若 ApplicationMaster 因故失败，ResourceManager 中的应用程序管理器会监测到失败的情形，然后将其重新启动，直到所有的任务执行完毕。</li>
</ol>
<p><img src="/2020/05/10/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hadoop/YARN%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="YARN的工作流程"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/" class="post-title-link" itemprop="url">Hive.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-08 18:32:49" itemprop="dateCreated datePublished" datetime="2020-05-08T18:32:49+08:00">2020-05-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="数据仓库概念"><a href="#数据仓库概念" class="headerlink" title="数据仓库概念"></a>数据仓库概念</h3><p>数据仓库的体系结构通常包含四个层次：数据源、数据存储和管理、数据服务、数据应用，具体如下：</p>
<ul>
<li>数据源：是数据仓库的数据来源，包括了外部数据、现有业务系统和文档资料等；</li>
<li>数据集成：完成数据的抽取、清洗、转换和加载任务，数据源中的数据采用 ETL 工具以固定的周期加载到数据仓库中；</li>
<li>数据存储和管理：这一层次主要涉及对数据的存储和管理，包括数据仓库、数据集市、数据仓库检测、运行与维护工具和元数据管理等；</li>
<li>数据服务：为前端工具和应用提供数据服务，可以直接从数据仓库中获取数据供前端应用使用，也可以通过 OLAP（Online Analytical Processing）服务器为前端应用提供更加复杂的数据服务。OLAP 服务器提供了不同聚集粒度的多维数据集合，使得应用不需要直接访问数据仓库中的底层细节数据，大大减少了数据计算量，提高了查询响应速度。OLAP 服务器还支持针对多维数据集的上钻、下探、切片、切块和旋转等操作，增强了多维数据分析能力；</li>
<li>数据应用：这一层次直接面向最终用户，包括数据查询工具、自由报表工具、数据分析工具、数据挖掘工具和各类应用系统。</li>
</ul>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="数据仓库体系结构"></p>
<h3 id="Hive-简介"><a href="#Hive-简介" class="headerlink" title="Hive 简介"></a>Hive 简介</h3><p>Hive 是一个构建于 Hadoop 顶层的数据仓库工具，依赖 HDFS 来存储数据，依赖 MapReduce 来处理数据。Hive 定义了简单的类似 SQL 的查询语言 HiveQL，它与大部分 SQL 语法兼容，但是，并不完全支持 SQL 标准，比如，HiveSQL 不支持更新操作，也不支持索引和事务，它的子查询和连接操作也存在很多局限。</p>
<h3 id="Hive-与-Hadoop-生态系统中其他组件的关系"><a href="#Hive-与-Hadoop-生态系统中其他组件的关系" class="headerlink" title="Hive 与 Hadoop 生态系统中其他组件的关系"></a>Hive 与 Hadoop 生态系统中其他组件的关系</h3><p>HDFS 作为高可靠的底层存储，用来存储海量数据；MapReduce 对这些海量数据进行批处理，实现高性能计算；Hive 架构在 MapReduce、HDFS 之上，其自身并不存储和处理数据，需要分别借助于 HDFS 和 MapReduce 实现数据的存储和处理，用 HiveQL 语句编写的处理逻辑，最终都要转化为 MapReduce 任务来运行；Pig 可以作为 Hive 的替代工具，是一种数据流语言和运行环境，适合用于在 Hadoop 平台上查询半结构化数据集，常用于 ETL 过程的一部分，即将外部数据装载到 Hadoop 集群中，然后转换为用户需要的数据格式；HBase 是一个面向列的、分布式的、可伸缩的数据库，它可以提供数据的实时访问功能，而 Hive 只能处理静态数据，主要是 BI 报表数据，就设计初衷而言，在 Hadoop 上设计 Hive，是为了减少复杂 MapReduce 应用程序的编写工作，在 Hadoop 上设计 HBase 则是为了实现对数据的实时访问，所以，HBase 与 Hive 的功能是互补的，它实现了 Hive 不能提供的功能。</p>
<h3 id="Hive-与传统数据库的对比"><a href="#Hive-与传统数据库的对比" class="headerlink" title="Hive 与传统数据库的对比"></a>Hive 与传统数据库的对比</h3><p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/Hive%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%AF%B9%E6%AF%94.png" alt="Hive与传统数据库的对比"></p>
<h2 id="Hive-系统架构"><a href="#Hive-系统架构" class="headerlink" title="Hive 系统架构"></a>Hive 系统架构</h2><p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/Hive%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84.png" alt="Hive系统架构"></p>
<p>Hive 主要由以下三个模块组成：用户接口模块、驱动模块以及元数据存储模块。</p>
<p>用户接口模块包括 CLI、HWI、JDBC、ODBC、Thrift Server 等，用来实现外部应用对 Hive 的访问。</p>
<ul>
<li>CLI 是 Hive 自带的一个命令行界面</li>
<li>HWI 是 Hive 的一个简单网页界面</li>
<li>JDBC、ODBC 以及 Thrift Server 可以向用户提供进行编程访问的接口<ul>
<li>Thrift Server 是基于 Thrift 软件框架开发的，它提供 Hive 的 RPC 通信接口</li>
</ul>
</li>
</ul>
<p>驱动模块（Driver）包括编译器、优化器、执行器等，负责把 HiveSQL 语句转换成一系列 MapReduce 作业，所有命令和查询都会进入到驱动模块，通过该模块对输入进行解析编译，对计算过程进行优化，然后按照指定的步骤执行。</p>
<p>元数据存储模块（Metastore）是一个独立的关系型数据库，通常是与 MySQL 数据库连接后创建的一个 MySQL 实例，也可以是 Hive 自带的 derby 数据库实例。元数据存储模块中主要保存表模式和其他系统元数据，如表的名称、表的列及其属性、表的分区及其属性、表的属性、表中数据所在位置信息等。</p>
<h2 id="Hive-工作原理"><a href="#Hive-工作原理" class="headerlink" title="Hive 工作原理"></a>Hive 工作原理</h2><p>Hive 可以快速实现简单的 MapReduce 统计，主要是通过自身组件把 HiveQL 语句转换成 MapReduce 任务来实现的。</p>
<h3 id="SQL-语句转换成-MapReduce-作业的基本原理"><a href="#SQL-语句转换成-MapReduce-作业的基本原理" class="headerlink" title="SQL 语句转换成 MapReduce 作业的基本原理"></a>SQL 语句转换成 MapReduce 作业的基本原理</h3><h4 id="用-MapReduce-实现连接操作"><a href="#用-MapReduce-实现连接操作" class="headerlink" title="用 MapReduce 实现连接操作"></a>用 MapReduce 实现连接操作</h4><p>假设参与连接（join）的两个表分别为用户表 User 和订单表 Order，User 表有两个属性，即 uid 和 name，Order 表也有两个属性，即 uid 和 orderid，它们的连接键为公共属性 uid。这里对两个表执行连接操作，得到用户的订单号与用户名的对应关系，具体的 SQL 语句命令如下：<code>select name, orderid from user u join order o on u.uid=o.uid;</code></p>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/%E7%94%A8MapReduce%E5%AE%9E%E7%8E%B0%E8%BF%9E%E6%8E%A5%E6%93%8D%E4%BD%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.png" alt="用MapReduce实现连接操作的基本原理"></p>
<p>首先，在 Map 阶段， User 表以 uid 为键（key），以 name 和表的标记位（这里 User 的标记位记为 1）为值（value）进行 Map 操作，把表中记录转化成生成一系列键值对的形式。同样地，Order 表以 uid 为键，以 orderid 和表的标记位（这里表 Order 的标记位记为 2）为值进行 Map 操作，把表中 记录转化成生成一系列键值对的形式。比如，User 表中记录 <code>(1,Lily)</code> 转化为键值对 <code>(1,&lt;1,Lily&gt;)</code>，其中，括号中的第一个“1”是 uid 的值，第二个“1”是表 User 的标记位，用来标识这个键值对来自 User 表；再比如，Order 表中记录 <code>(1,101)</code> 转化为键值对 <code>(1,&lt;2,101&gt;)</code>，其中，“2”是表 Order 的标记位，用来标识这个键值对来自 Order 表。</p>
<p>接着，在 Shuffle 阶段，把 User 表和 Order 表生成的键值对按键值进行哈希，然后传送给对应的 Reduce 机器执行，比如键值对 <code>(1,&lt;1,Lily&gt;)</code>、<code>(1,&lt;2,101&gt;)</code> 和 <code>(1,&lt;2,102&gt;)</code> 传送到同一台 Reduce 机器上，键值对 <code>(2,&lt;1,Tom&gt;)</code> 和 <code>(2,&lt;2,103&gt;)</code> 传送到另一台 Reduce 机器上。当 Reduce 机器接收这些键值对时，还需要按表的标记位对这些键值对进行排序，以优化连接操作。</p>
<p>最后，在 Reduce 阶段，对同一台 Reduce 机器上的键值对，根据“值”（value）中的表标记位，对来自 User 和 Order 这两个表的数据进行笛卡尔积连接操作，以生成最终的连接结果。比如，键值对 <code>(1,&lt;1,Lily&gt;)</code> 与键值对 <code>(1,&lt;2,101&gt;)</code> 和 <code>(1,&lt;2,102&gt;)</code> 的连接结果分别为 <code>(Lily ,101&gt;)</code> 和 <code>(Lily, 102)</code>，键值对 <code>(2,&lt;1,Tom&gt;)</code> 和键值对 <code>(2,&lt;2,103&gt;)</code> 的连接结果为 <code>(Tom, 103)</code>。</p>
<h4 id="用-MapReduce-实现分组操作"><a href="#用-MapReduce-实现分组操作" class="headerlink" title="用 MapReduce 实现分组操作"></a>用 MapReduce 实现分组操作</h4><p>假设分数表 Score 具有两个属性，即 rank（排名）和 level（级别），这里存在一个分组（Group By）操作，其功能是把表 Score 的不同片段按照 rank 和 level 的组合值进行合并，计算不同 rank 和 level 的组合值分别有几条记录。具体的 SQL 语句命令如下：<code>select rank, level ,count(*) as value from score group by rank, level;</code></p>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/%E7%94%A8MapReduce%E5%AE%9E%E7%8E%B0%E5%88%86%E7%BB%84%E6%93%8D%E4%BD%9C%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png" alt="用MapReduce实现分组操作的实现原理"></p>
<p>首先，在 Map 阶段，对表 Score 进行 Map 操作，生成一系列键值对，对于每个键值对，其键为 <code>&lt;rank,level&gt;</code>，值为“拥有该 <code>&lt;rank,value&gt;</code> 组合值的记录的条数”。比如，Score 表的第一片段中有两条记录 <code>(A,1)</code>，所以，记录 <code>(A,1)</code> 转化为键值对 <code>(&lt;A,1&gt;,2)</code>，Score 表的第二片段中只有一条记录 <code>(A,1)</code>，所以，记录 <code>(A,1)</code> 转化为键值对 <code>(&lt;A,1&gt;,1)</code>。</p>
<p>接着，在 Shuffle 阶段，对 Score 表生成的键值对，按照“键”的值进行哈希，然后根据哈希结果传送给对应的 Reduce 机器去执行，比如键值 对 <code>(&lt;A,1&gt;,2)</code> 和 <code>(&lt;A,1&gt;,1)</code> 传送到同一台 Reduce 机器上，键值对 <code>(&lt;B,2&gt;,1)</code> 传送到另一台 Reduce 机器上。然后，Reduce 机器对接收到的这些键值对，按“键”的值进行排序。</p>
<p>最后，在 Reduce 阶段，对于 Reduce 机器上的这些键值对，把具有相同键的所有键值对的“值”进行累加，生成分组的最终结果，比如，在同一台 Reduce 机器上的键值对 <code>(&lt;A,1&gt;,2)</code> 和 <code>(&lt;A,1&gt;,1&gt;)</code> Reduce 后的输出结果为 <code>(&lt;A,1&gt;,3)</code>，<code>(&lt;B,2&gt;,1)</code> 的 Reduce 后的输出结果为 <code>(&lt;B,2&gt;,1)</code>。</p>
<h3 id="Hive-中-SQL-查询转换成-MapReduce-作业的过程"><a href="#Hive-中-SQL-查询转换成-MapReduce-作业的过程" class="headerlink" title="Hive 中 SQL 查询转换成 MapReduce 作业的过程"></a>Hive 中 SQL 查询转换成 MapReduce 作业的过程</h3><p>当用户向 Hive 输入一段命令或查询（即 HiveQL 语句）时，Hive 需要与 Hadoop 交互工作来完成该操作。该命令或查询首先进入到驱动模块，由驱动模块中的编译器进行解析编译，并由优化器对该操作进行优化计算，然后交给执行器去执行。执行器通常的任务是启动一个或多个 MapReduce 任务，有时也不需要启动 MapReduce 任务，比如，执行包含 <code>*</code> 的操作时（如 <code>select * from 表</code>），就是全表扫描，选择所有的属性和所有的元组，不存在投影和选择操作，因此，不需要执行 Map 和 Reduce 操作。</p>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/Hive%E4%B8%ADSQL%E6%9F%A5%E8%AF%A2%E7%9A%84MapReduce%E4%BD%9C%E4%B8%9A%E8%BD%AC%E5%8C%96%E8%BF%87%E7%A8%8B.png" alt="Hive中SQL查询的MapReduce作业转化过程"></p>
<p>在 Hive 中，用户通过命令行 CLI 或其他 Hive 访问工具，向 Hive 输入一段命令或查询以后，SQL 查询被 Hive 自动转化为 MapReduce 作业，具体步骤如下：</p>
<ol>
<li>由 Hive 驱动模块中的编译器——Antlr 语言识别工具，对用户输入的 SQL 语言进行词法和语法解析，将 SQL 语句转化为抽象语法树（AST Tree）的形式；</li>
<li>对该抽象语法树进行遍历，进一步转化成 QueryBlock 查询单元。因为抽象语法树的结构仍很复杂，不方便直接翻译为 MapReduce 算法程序，所以，Hive 把抽象语法树进一步转化为 QueryBlock，其中，QueryBlock 是一条最基本的 SQL 语法组成单元，包括输入源、计算过程和输出三个部分；</li>
<li>再对 QueryBlock 进行遍历，生成 OperatorTree（操作树）。其中，OperatorTree 由很多逻辑操作符组成，如 TableScanOperator、SelectOperator、FilterOperator、JoinOperator、 GroupByOperator 和 ReduceSinkOperator 等。这些逻辑操作符可以在 Map 阶段和 Reduce 阶 段完成某一特定操作；</li>
<li>通过 Hive 驱动模块中的逻辑优化器对 OperatorTree 进行优化，变换 OperatorTree 的形式，合并多余的操作符，从而减少 MapReduce 任务数量以及 Shuffle 阶段的数据量；</li>
<li>对优化后的 OperatorTree 进行遍历，根据 OperatorTree 中的逻辑操作符生成需要执行的 MapReduce 任务；</li>
<li>启动 Hive 驱动模块中的物理优化器，对生成的 MapReduce 任务进行优化，生成最终的 MapReduce 任务执行计划；</li>
<li>最后由 Hive 驱动模块中的执行器，对最终的 MapReduce 任务进行执行输出。</li>
</ol>
<p>需要说明的是，Hive 驱动模块中的执行器执行最终的 MapReduce 任务时，Hive 本身是不会生成 MapReduce 算法程序的，它需要通过一个表示“Job 执行计划”的 XML 文件，来驱动执行内置的、原生的 Mapper 和 Reducer 模块。Hive 通过和 JobTracker 通信来初始化 MapReduce 任务，而不需要直接部署在 JobTracker 所在的管理节点上执行。通常在大型集群上，会有专门的网关机来部署 Hive 工具。这些网关机的作用主要是远程操作和管理节点上的 JobTracker 通信来执行任务。Hive 要处理的数据文件通常存储在 HDFS 上，HDFS 由名称节点（NameNode）来管理。</p>
<h2 id="Hive-HA-基本原理"><a href="#Hive-HA-基本原理" class="headerlink" title="Hive HA 基本原理"></a>Hive HA 基本原理</h2><p>Hive 的功能十分强大，可以支持采用 SQL 方式查询 Hadoop 平台上的数据，但是，在实际应用中，Hive 也暴露出不稳定的问题，在极少数情况下，甚至会出现端口不响应或者进程丢失的问题。Hive HA（High Availability）的出现，就是为了解决这类问题。</p>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/Hive/HiveHA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86.png" alt="HiveHA基本原理"></p>
<p>在 Hive HA 中，在 Hadoop 集群上构建的数据仓库是由多个 Hive 实例进行管理的，这些 Hive 实例被纳入到一个资源池中，并由 HAProxy 提供一个统一的对外接口。客户端的查询请求首先访问 HAProxy，由 HAProxy 对访问请求进行转发。HAProxy 收到请求后，会轮询资源池里可用的 Hive 实例，执行逻辑可用性测试，如果某个 Hive 实例逻辑可用，就会把客户端的访问请求转发到该 Hive 实例上，如果该 Hive 实例逻辑不可用，就把它放入黑名单，并继续从资源池中取出下一个 Hive 实例进行逻辑可用性测试。对于黑名单中的 Hive 实例，HiveHA 会每隔一段时间进行统一处理，首先尝试重启该 Hive 实例，如果重启成功，就再次把它放入到资源池中。由于采用 HAProxy 提供统一的对外访问接口，因此，对于程序开发人员来说，可以把它认为是一台超强“Hive”。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/MapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/MapReduce/" class="post-title-link" itemprop="url">MapReduce.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-08 18:18:06" itemprop="dateCreated datePublished" datetime="2020-05-08T18:18:06+08:00">2020-05-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="模型简介"><a href="#模型简介" class="headerlink" title="模型简介"></a>模型简介</h3><p>在 MapReduce 中，一个存储在分布式文件系统中的大规模数据集会被切分成许多独立的小数据块，这些小数据块可以被多个 Map 任务并行处理。MapReduce 框架会为每个 Map 任务输入一个数据子集，Map 任务生成的结果会继续作为 Reduce 任务的输人，最终由 Reduce 任务输出最后结果，并写入分布式文件系统。</p>
<p>特别注意：适合用 MapReduce 来传护理的数据集需要满足一个前提条件：待处理的数据集可以分解成许多小的数据集，而且每一个小数据集都可以完全并行地进行处理。</p>
<p>MapReduce 设计的一个理念就是“计算向数据靠拢”，而不是“数据向计算靠拢”，因为移动数据需要大量的网络传输开销，尤其是在大规模数据环境下，这种开销尤为惊人，所以，移动计算要比移动数据更加经济。本着这个理念，在一个集群中，只要有可能，MapReduce 框架就会将 Map 程序就近地在 HDFS 数据所在的节点运行，即将计算节点和存储节点放在一起运行，从而减少了节点间的数据移动开销。</p>
<h2 id="MapReduce-的工作流程"><a href="#MapReduce-的工作流程" class="headerlink" title="MapReduce 的工作流程"></a>MapReduce 的工作流程</h2><h3 id="工作流程概述"><a href="#工作流程概述" class="headerlink" title="工作流程概述"></a>工作流程概述</h3><p>MapReduce的 核心思想可以用“分而治之”来描述，也就是把一个大的数据集拆分成多个小数据块在多台机器上并行处理，也就是说，一个大的 MapReduce 作业，首先会被拆分成许多个 Map 任务在多台机器上并行执行，每个 Map 任务通常运行在数据存储的节点上，这样，计算和数据就可以放在一起运行，不需要额外的数据传输开销。当 Map 任务结束后，会生成以 <code>&lt;key,value&gt;</code> 形式表示的许多中间结果。然后，这些中间结果会被分发到多个 Reduce 任务在多台机器上并行执行，具有相同 key 的 <code>&lt;key,value&gt;</code> 会被发送到同个 Reduce 任务那里，Reduce 任务会对中间结果进行汇总计算得到最后结果，并输出到分布式文件系统中。</p>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/MapReduce/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" alt="工作流程"></p>
<p>需要指出的是，不同的 Map 任务之间不会进行通信，不同的 Reduce 任务之间也不会发生任何信息交换；用户不能显式地从一台机器向另台机器发送消息，所有的数据交换都是通过 MapReduce 框架自身去实现的。</p>
<p>在 MapReduce 的整个执行过程中，Map 任务的输人文件、Reduce 任务的处理结果都是保存在分布式文件系统中的，而 Map 任务处理得到的中间结果则保存在本地存储中（如磁盘）。另外，只有当 Map 处理全部结束后， Reduce 过程才能开始；只有 Map 需要考虑数据局部性，实现“计算向数据靠拢”，而 Reduce 则无需考虑数据局部性。</p>
<h3 id="各个执行阶段"><a href="#各个执行阶段" class="headerlink" title="各个执行阶段"></a>各个执行阶段</h3><ol>
<li>MapReduce 框架使用 InputFormat 模块做 Map 前的预处理，比如验证输人的格式是否符合输人定义；然后，将输人文件切分为逻辑上的多个 InputSplit，InputSplit 是 MapReduce 对文件进行处理和运算的输人单位，只是一个逻辑概念，每个 InputSplit 并没有对文件进行实际切割，只是记录了要处理的数据的位置和长度。</li>
<li>因为 InputSplit 是逻辑切分而非物理切分，所以还需要通过 RecordReader（RR）根据 InputSplit 中的信息来处理 InputSplit 中的具体记录，加载数据并转换为适合 Map 任务读取的键值对，输人给 Map 任务。</li>
<li>Map 任务会根据用户自定义的映射规则，输出一系列的 <code>&lt;key,value&gt;</code> 作为中间结果。</li>
<li>为了让 Reduce 可以并行处理 Map 的结果，需要对 Map 的输出进行一定的分区（Portition）、排序（Sort）、合并（Combine）、归并（Merge）等操作，得到 <code>&lt;key, value-list&gt;</code> 形式的中间结果，再交给对应的 Reduce 进行处理，这个过程称为 Shufle。从无序的 <code>&lt;key,value&gt;</code> 到有序的 <code>&lt;key, value-list&gt;</code>，这个过程用 Shuffle（洗牌）来称呼是非常形象的。</li>
<li>Reduce 以一系列 <code>&lt;key, value-list&gt;</code> 中间结果作为输人，执行用户定义的逻辑，输出结果给 OutputFormat 模块。</li>
<li>OutputFormat 模块会验证输出目录是否已经存在以及输出结果类型是否符合配置文件中的配置类型，如果都满足，就输出 Reduce 的结果到分布式文件系统。</li>
</ol>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/MapReduce/MapReduce%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%90%84%E4%B8%AA%E6%89%A7%E8%A1%8C%E9%98%B6%E6%AE%B5.png" alt="MapReduce工作流程中的各个执行阶段"></p>
<h3 id="Shuffle-过程详解"><a href="#Shuffle-过程详解" class="headerlink" title="Shuffle 过程详解"></a>Shuffle 过程详解</h3><h4 id="Shuffle-过程简介"><a href="#Shuffle-过程简介" class="headerlink" title="Shuffle 过程简介"></a>Shuffle 过程简介</h4><p>所谓 Shuffle，是指对 Map 输出结果进行分区、排序、合并等处理并交给 Reduce 的过程。因此，Shuffle 过程分为 Map 端的操作和 Reduce 端的操作。</p>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/MapReduce/Shuffle%E8%BF%87%E7%A8%8B.png" alt="Shuffle过程"></p>
<h4 id="Map-端的-Shuffle-过程"><a href="#Map-端的-Shuffle-过程" class="headerlink" title="Map 端的 Shuffle 过程"></a>Map 端的 Shuffle 过程</h4><p>Map 的输出结果首先被写入缓存，当缓存满时，就启动溢写操作，把缓存中的数据写入磁盘文件，并清空缓存。当启动溢写操作时，首先需要把缓存中的数据进行分区，然后对每个分区的数据进行排序（Sort）和合并（Combine），之后再写人磁盘文件。每次溢写操作会生成一个新的磁盘文件，随着 Map 任务的执行，磁盘中就会生成多个溢写文件。在 Map 任务全部结束之前，这些溢写文件会被归并（Merge）成一个大的磁盘文件，然后通知相应的 Reduce 任务来领取属于自己处理的数据。</p>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/MapReduce/Map%E7%AB%AF%E7%9A%84Shuffle%E8%BF%87%E7%A8%8B.png" alt="Map端的Shuffle过程"></p>
<h5 id="输入数据和执行-Map-任务"><a href="#输入数据和执行-Map-任务" class="headerlink" title="输入数据和执行 Map 任务"></a>输入数据和执行 Map 任务</h5><p>Map 任务的输入数据一般保存在分布式文件系统（如 GFS 或 HDFS）的文件块中，这些文件块的格式是任意的，可以是文档，也可以是二进制格式的。Map 任务接受 <code>&lt;key, value&gt;</code>作为输入后，按一定的映射规则转换成一批 <code>&lt;key, value&gt;</code> 进行输出。</p>
<h5 id="写入缓存"><a href="#写入缓存" class="headerlink" title="写入缓存"></a>写入缓存</h5><p>每个 Map 任务都会被分配一个缓存，Map 的输出结果不是立即写入磁盘，而是首先写人缓存。在缓存中积累一定数量的 Map 输出结果以后，再一次性批量写人磁盘，这样可以大大减少对磁盘 I/O 的影响。因为，磁盘包含机械部件，它是通过磁头移动和盘片的转动来寻址定位数据的，每次寻址的开销很大，如果每个 Map 输出结果都直接写人磁盘，会引入很多次寻址开销，而一次性批量写入，就只需要一次寻址、连续写入，大大降低了开销。需要注意的是，在写入缓存之前，key 与 value 值都会被序列化成字节数组。</p>
<h5 id="溢写（分区、排序和合并）"><a href="#溢写（分区、排序和合并）" class="headerlink" title="溢写（分区、排序和合并）"></a>溢写（分区、排序和合并）</h5><p>提供给 MapReduce 的缓存的容量是有限的，默认大小是 100 MB。随着 Map 任务的执行，缓存中 Map 结果的数量会不断增加，很快就会占满整个缓存。这时，就必须启动溢写（Spill）操作，把缓存中的内容一次性写人磁盘，并清空缓存。溢写的过程通常是由另外个单独的后台线程来完成的，不会影响 Map 结果往缓存写人，但是为了保证 Map 结果能够不停地持续写入缓存，不受溢写过程的影响，就必须让缓存中一直有可用的空间，不能等到全部占满才启动溢写过程，所以一般会设置一个溢写比例，如0.8，也就是说，当 100 MB 大小的缓存被填满 80 MB 数据时，就启动溢写过程，把已经写人的 80 MB 数据写人磁盘，剩余 20 MB 空间供 Map 结果继续写人。</p>
<p>但是，在溢写到磁盘之前，缓存中的数据首先会被分区（Partition）。缓存中的数据是 <code>&lt;key, value&gt;</code> 形式的键值对，这些键值对最终需要交给不同的 Reduce 任务进行并行处理。MapReduce 通过 Partitioner 接口对这些键值对进行分区，默认采用的分区方式是采用 Hash 函数对 key 进行哈希后再用 Reduce 任务的数量进行取模，可以表示成 <code>hash(key) mod R</code>，其中 R 表示 Reduce 任务的数量，这样，就可以把 Map 输出结果均匀地分配给这 R 个Reduce 任务去并行处理了。当然，MapReduce 也允许用户通过重载 Partitioner 接口来自定义分区方式。</p>
<p>对于每个分区内的所有键值对，后台线程会根据 key 对它们进行内存排序（Sort），排序是 MapReduce 的默认操作。排序结束后，还包含一个可选的合并（Combine）操作。如果用户事先没有定义 Combiner 函数，就不用进行合并操作。如果用户事先定义了 Combiner 函数，则这个时候会执行合并操作，从而减少需要溢写到磁盘的数据量。</p>
<p>所谓“合并”，是指将那些具有相同 key 的 <code>&lt;key,value&gt;</code> 的 value 加起来。比如，有两个键值对 <code>&lt;“xmu&quot; 1&gt;</code> 和 <code>&lt;“xmu” 1&gt;</code>，经过合并操作以后就可以得到一个键值对 <code>&lt;“xmu” 2&gt;</code>，减少了键值对的数量。这里需要注意，Map 端的这种合并操作，其实和 Reduce 的功能相似，但是由于这个操作发生在 Map 端，所以我们只能称之为“合并”，从而有别于 Reduce。不过，并非所有场合都可以使用 Combiner，因为 Combiner 的输出是 Reduce 任务的输人，Combiner 绝不能改变 Reduce 任务最终的计算结果，一般而言，累加、最大值等场景可以使用合并操作。</p>
<p>经过分区、排序以及可能发生的合并操作之后，这些缓存中的键值对就可以被写人磁盘，并清空缓存。每次溢写操作都会在磁盘中生成一个新的溢写文件，写人溢写文件中的所有键值对都是经过分区和排序的。</p>
<h5 id="文件归并"><a href="#文件归并" class="headerlink" title="文件归并"></a>文件归并</h5><p>每次溢写操作都会在磁盘中生成一个新的溢写文件，随着 MapReduce 任务的进行，磁盘中的溢写文件数量会越来越多。当然，如果 Map 输出结果很少，磁盘上只会存在一个溢写文件，但是通常都会存在多个溢写文件。最终，在 Map 任务全部结束之前，系统会对所有溢写文件中的数据进行归并（Merge），生成一个大的溢写文件，这个大的溢写文件中的所有键值对也是经过分区和排序的。</p>
<p>所谓“归并”，是指对于具有相同 key 的键值对会被归并成一个新的键值对。具体而言，对于若千个具有相同 key 的键值对 $&lt;k_1,v_1&gt;, &lt;k_1,v_2&gt; ….. &lt;k_1,v_n&gt;$ 会被归并成一个新的键值对 $&lt;k_1, &lt;v_1,v_2,…,v_n&gt;$。</p>
<p>另外，进行文件归并时，如果磁盘中已经生成的溢写文件的数量超过参数 min.num.spills.for.combine 的值时（默认值是 3，用户可以修改这个值），那么，就可以再次运行 Combiner，对数据进行合并操作，从而减少写人磁盘的数据量。但是，如果磁盘中只有一两个溢写文件时，执行合并操作就会“得不偿失”，因为执行合并操作本身也需要代价，因此不会运行 Combiner。</p>
<p>经过上述4个步骤以后，Map 端的 Shuffle 过程全部完成，最终生成的一个大文件会被存放在本地磁盘上。这个大文件中的数据是被分区的，不同的分区会被发送到不同的 Reduce 任务进行并行处理。JobTracker 会一直监测 Map 任务的执行，当监测到一个 Map 任务完成后，就会立即通知相关的 Reduce 任务来“领取”数据，然后开始 Reduce 端的 Shuffle 过程。</p>
<h4 id="Reduce-端的-Shuffle-过程"><a href="#Reduce-端的-Shuffle-过程" class="headerlink" title="Reduce 端的 Shuffle 过程"></a>Reduce 端的 Shuffle 过程</h4><p>Reduce 任务从 Map 端的不同 Map 机器领回属于自己处理的那部分数据，然后对数据进行归并（Merge）后交给 Reduce 处理。</p>
<p><img src="/2020/05/08/%E5%A4%A7%E6%95%B0%E6%8D%AE/MapReduce/Reduce%E7%AB%AF%E7%9A%84Shuffle%E8%BF%87%E7%A8%8B.png" alt="Reduce端的Shuffle过程"></p>
<h5 id="“领取”数据"><a href="#“领取”数据" class="headerlink" title="“领取”数据"></a>“领取”数据</h5><p>Map 端的 Shuffle 过程结束后，所有 Map 输出结果都保存在 Map 机器的本地磁盘上，Reduce 任务需要把这些数据“领取”（Fetch）回来存放到自己所在机器的本地磁盘上。因此，在每个 Reduce 任务真正开始之前，它大部分时间都在从 Map 端把属于自己处理的那些分区的数据“领取”过来。每个 Reduce 任务会不断地通过 RPC 向 JobTracker 询问 Map 任务是否已经完成；JobTracker 监测到一个 Map 任务完成后，就会通知相关的 Reduce 任务来“领取”数据；一旦一个 Reduce 任务收到 JobTracker 的通知，它就会到该 Map 任务所在机器上把属于自已处理的分区数据领取到本地磁盘中。一般系统中会存在多个 Map 机器，因此 Reduce 任务会使用多个线程同时从多个 Map 机器领回数据。</p>
<h5 id="归并数据"><a href="#归并数据" class="headerlink" title="归并数据"></a>归并数据</h5><p>从Map端领回的数据会首先被存放在 Reduce 任务所在机器的缓存中，如果缓存被占满，就会像 Map 端一样被溢写到磁盘中。由于在 Shuffle 阶段 Reduce 任务还没有真正开始执行，因此，这时可以把内存的大部分空间分配给 Shuffle 过程作为缓存。需要注意的是，系统中一般存在多个 Map 机器，Reduce 任务会从多个 Map 机器领回属于自己处理的那些分区的数据，因此缓存中的数据是来自不同的 Map 机器的，一般会存在很多可以合并（Combine）的键值对。当溢写过程启动时，具有相同 key 的键值对会被归并（Merge），如果用户定义了 Combiner，则归并后的数据还可以执行合并操作，减少写人磁盘的数据量。每个溢写过程结束后，都会在磁盘中生成一个溢写文件，因此磁盘上会存在多个溢写文件。最终，当所有的 Map 端数据都已经被领回时，和 Map 端类似，多个溢写文件会被归并成开个大文件，归并的时候还会对键值对进行排序，从而使得最终大文件中的键值对都是有序的。当然，在数据很少的情形下，缓存可以存储所有数据，就不需要把数据溢写到磁盘，而是直接在内存中执行归并操作，然后直接输出给 Reduce 任务。</p>
<p>需要说明的是，把磁盘上的多个溢写文件归并成一个大文件可能需要执行多轮归并操作。每轮归并操作可以归并的文件数量是由参数 io.sort.factor 的值来控制的（默认值是 10，可以修改）。假设磁盘中生成了 50 个溢写文件，每轮可以归并 10 个溢写文件，则需要经过 5 轮归并，得到 5 个归并后的大文件。</p>
<h5 id="把数据输人给-Reduce-任务"><a href="#把数据输人给-Reduce-任务" class="headerlink" title="把数据输人给 Reduce 任务"></a>把数据输人给 Reduce 任务</h5><p>磁盘中经过多轮归并后得到的若干个大文件，不会继续归并成一个新的大文件，而是直接输入给 Reduce 任务，这样可以减少磁盘读写开销。由此，整个 Shuffle 过程顺利结束。接下来，Reduce 任务会执行 Reduce 函数中定义的各种映射，输出最终结果，并保存到分布式文件系统中（比如 GFS 或 HDFS）。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2020/05/05/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2020/05/05/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" class="post-title-link" itemprop="url">数据增强.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-05-05 23:39:37" itemprop="dateCreated datePublished" datetime="2020-05-05T23:39:37+08:00">2020-05-05</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/" itemprop="url" rel="index"><span itemprop="name">机器视觉</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>最简单的数据扩充方法就是垂直镜像对称，假如，训练集中有这张图片，然后将其翻转得到右边的图像。对大多数计算机视觉任务，左边的图片是猫，然后镜像对称仍然是猫，如果镜像操作保留了图像中想识别的物体的前提下，这是个很实用的数据扩充技巧。</li>
<li>另一个经常使用的技巧是随机裁剪，给定一个数据集，然后开始随机裁剪，可能修剪这个（编号1），选择裁剪这个（编号2），这个（编号3），可以得到不同的图片放在数据集中，你的训练集中有不同的裁剪。随机裁剪并不是一个完美的数据扩充的方法，如果你随机裁剪的那一部分（红色方框标记部分，编号4），这部分看起来不像猫。但在实践中，这个方法还是很实用的，随机裁剪构成了很大一部分的真实图片。</li>
<li>镜像对称和随机裁剪是经常被使用的。当然，理论上，你也可以使用旋转，剪切（shearing：此处并非裁剪的含义，图像仅水平或垂直坐标发生变化）图像，可以对图像进行这样的扭曲变形，引入很多形式的局部弯曲等等。当然使用这些方法并没有坏处，尽管在实践中，因为太复杂了所以使用的很少。</li>
</ul>
<p><img src="/2020/05/05/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/%E9%9A%8F%E6%9C%BA%E8%A3%81%E5%89%AA.png" alt="随机裁剪"></p>
<ul>
<li>第二种经常使用的方法是彩色转换，有这样一张图片，然后给R、G和B三个通道上加上不同的失真值。</li>
</ul>
<p><img src="/2020/05/05/artificial_intelligence/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/%E8%89%B2%E5%BD%A9%E8%BD%AC%E6%8D%A2.png" alt="色彩转换"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/69/">69</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhang Wetts"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhang Wetts</p>
  <div class="site-description" itemprop="description">Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">682</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">67</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">350</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wetts" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wetts" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhang.wetts@163.com" title="E-Mail → mailto:zhang.wetts@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhang Wetts</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hibiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0}});</script></body>
</html>
