<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wetts.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Stay Hungry, Stay Foolish. [build by hexo&#x2F;next&#x2F;gitalk&#x2F;hexo-generator-search&#x2F;LaTeX]">
<meta property="og:type" content="website">
<meta property="og:title" content="Wetts&#39;s blog">
<meta property="og:url" content="https://wetts.github.io/page/12/index.html">
<meta property="og:site_name" content="Wetts&#39;s blog">
<meta property="og:description" content="Stay Hungry, Stay Foolish. [build by hexo&#x2F;next&#x2F;gitalk&#x2F;hexo-generator-search&#x2F;LaTeX]">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Zhang Wetts">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://wetts.github.io/page/12/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Wetts's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Wetts's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Stay Hungry, Stay Foolish.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/wetts" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">MongoDB-0-知识点汇总.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-01 12:10:14" itemprop="dateCreated datePublished" datetime="2019-09-01T12:10:14+08:00">2019-09-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MongoDB/" itemprop="url" rel="index"><span itemprop="name">MongoDB</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><ul>
<li>MongoDB 是一个文档数据库，提供好的性能，领先的非关系型数据库。采用 BSON 存储文档数据。</li>
<li>MongoDB的优势有哪些<ul>
<li>面向文档的存储：以 JSON 格式的文档保存数据。</li>
<li>任何属性都可以建立索引。</li>
<li>复制以及高可扩展性。</li>
<li>自动分片。</li>
<li>丰富的查询功能。</li>
<li>快速的即时更新。</li>
<li>来自 MongoDB 的专业支持。</li>
</ul>
</li>
<li>基础概念<ul>
<li>模型层面<ul>
<li>database 数据库，与 SQL 的数据库（database）概念相同，一个数据库包含多个集合（表）</li>
<li>collection 集合，相当于 SQL 中的表（table），一个集合可以存放多个文档（行）。不同之处就在于集合的结构（schema）是动态的，不需要预先声明一个严格的表结构。更重要的是，默认情况下 MongoDB 并不会对写入的数据做任何 schema 的校验。</li>
<li>document 文档，相当于 SQL 中的行（row），一个文档由多个字段（列）组成，并采用 bson（json）格式表示。</li>
<li>field 字段，相当于 SQL 中的列（column），相比普通 column 的差别在于 field 的类型可以更加灵活，比如支持嵌套的文档、数组。</li>
<li>此外，MongoDB 中字段的类型是固定的、区分大小写、并且文档中的字段也是有序的。</li>
<li>MongoDB 和关系型数据库术语对比<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB%E5%92%8C%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%AF%E8%AF%AD%E5%AF%B9%E6%AF%94%E5%9B%BE.jpg" alt="MongoDB和关系型数据库术语对比图"></li>
</ul>
</li>
</ul>
</li>
<li>SQL 层面<ul>
<li>_id 主键，MongoDB 默认使用一个_id 字段来保证文档的唯一性。</li>
<li>reference 引用，勉强可以对应于外键（foreign key）的概念，之所以是勉强是因为 reference 并没有实现任何外键的约束，而只是由客户端（driver）自动进行关联查询、转换的一个特殊类型。</li>
<li>view 视图，MongoDB 3.4 开始支持视图，和 SQL 的视图没有什么差异，视图是基于表/集合之上进行动态查询的一层对象，可以是虚拟的，也可以是物理的（物化视图）。</li>
<li>index 索引，与 SQL 的索引相同。</li>
<li>$lookup，这是一个聚合操作符，可以用于实现类似 SQL-join 连接的功能</li>
<li>transaction 事务，从 MongoDB 4.0 版本开始，提供了对于事务的支持</li>
<li>aggregation 聚合，MongoDB 提供了强大的聚合计算框架，group by 是其中的一类聚合操作。</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_SQL%E6%A6%82%E5%BF%B5%E6%98%A0%E5%B0%84%E5%AF%B9%E6%AF%94%E5%9B%BE.png" alt="MongoDB_SQL概念映射对比图"></li>
</ul>
</li>
</ul>
</li>
<li>分布式 ID<ul>
<li>MongoDB 采用 ObjectId 来表示主键的类型，数据库中每个文档都拥有一个_id 字段表示主键。</li>
<li>_id 的生成规则如下：<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_ID%E7%94%9F%E6%88%90%E8%A7%84%E5%88%99.png" alt="MongoDB_ID生成规则"></li>
<li>4-byte Unix 时间戳</li>
<li>3-byte 机器 ID</li>
<li>2-byte 进程 ID</li>
<li>3-byte 计数器（初始化随机）</li>
</ul>
</li>
<li>值得一提的是 _id 的生成实质上是由客户端（Driver）生成的，这样可以获得更好的随机性，同时降低服务端的负载。</li>
<li>当然服务端也会检测写入的文档是否包含 _id 字段，如果没有就生成一个。</li>
</ul>
</li>
</ul>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><ul>
<li>MongoDB 支持非常丰富的索引类型。</li>
<li>索引的技术实现依赖于底层的存储引擎，在当前的版本中 MongoDB 使用 wiredTiger 作为默认的引擎。</li>
<li>在索引的实现上使用了 B+树的结构。</li>
<li><strong>大部分基于SQL数据库的一些索引调优技巧在 MongoDB 上仍然是可行的。</strong></li>
<li>索引特性<ul>
<li>unique=true，表示一个唯一性索引</li>
<li>expireAfterSeconds=3600，表示这是一个TTL索引，并且数据将在1小时后老化</li>
<li>sparse=true，表示稀疏的索引，仅索引非空（non-null）字段的文档</li>
<li>partialFilterExpression: { rating: { $gt: 5 }，条件式索引，即满足计算条件的文档才进行索引</li>
</ul>
</li>
<li>索引分类<ul>
<li>哈希（HASH）索引，哈希是另一种快速检索的数据结构，MongoDB 的 HASH 类型分片键会使用哈希索引。</li>
<li>地理空间索引，用于支持快速的地理空间查询，如寻找附近1公里的商家。</li>
<li>文本索引，用于支持快速的全文检索</li>
<li>模糊索引（Wildcard Index），一种基于匹配规则的灵活式索引，在4.2版本开始引入。</li>
</ul>
</li>
<li>索引评估、调优<ul>
<li>使用 <code>explain()</code> 命令可以用于查询计划分析，进一步评估索引的效果。</li>
</ul>
</li>
</ul>
<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><ul>
<li>一个典型的 MongoDB 集群架构会同时采用分片+副本集的方式<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_%E9%9B%86%E7%BE%A4%E5%AE%9E%E4%BE%8B.jpg" alt="MongoDB_集群实例"></li>
<li>架构说明<ul>
<li>数据分片（Shards）<ul>
<li>分片用于存储真正的集群数据，可以是一个单独的 Mongod 实例，也可以是一个副本集。生产环境下 Shard 一般是一个 Replica Set，以防止该数据片的单点故障。</li>
<li>对于分片集合（sharded collection）来说，每个分片上都存储了集合的一部分数据（按照分片键切分），如果集合没有分片，那么该集合的数据都存储在数据库的 Primary Shard中。</li>
</ul>
</li>
<li>配置服务器（Config Servers）<ul>
<li>保存集群的元数据（metadata），包含各个 Shard 的路由规则，配置服务器由一个副本集（ReplicaSet）组成。</li>
</ul>
</li>
<li>查询路由（Query Routers）<ul>
<li>Mongos 是 Sharded Cluster 的访问入口，其本身并不持久化数据。Mongos 启动后，会从 Config Server 加载元数据，开始提供服务，并将用户的请求正确路由到对应的Shard。</li>
<li>Sharding 集群可以部署多个 Mongos 以分担客户端请求的压力。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>分片机制<ul>
<li>数据如何切分<ul>
<li>首先，基于分片切分后的数据块称为 chunk，一个分片后的集合会包含多个 chunk，每个 chunk 位于哪个分片（Shard）则记录在 Config Server（配置服务器）上。</li>
<li>Mongos 在操作分片集合时，会自动根据分片键找到对应的 chunk，并向该 chunk 所在的分片发起操作请求。</li>
<li>数据是根据分片策略来进行切分的，而分片策略则由分片键（ShardKey）+分片算法（ShardStrategy）组成。<ul>
<li>MongoDB 支持两种分片算法：<ul>
<li>范围分片<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_%E5%88%86%E7%89%87%E7%AE%97%E6%B3%95_%E8%8C%83%E5%9B%B4%E5%88%86%E7%89%87.png" alt="MongoDB_分片算法_范围分片"></li>
</ul>
</li>
<li>哈希分片<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_%E5%88%86%E7%89%87%E7%AE%97%E6%B3%95_%E5%93%88%E5%B8%8C%E5%88%86%E7%89%87.png" alt="MongoDB_分片算法_哈希分片"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>如何保证均衡<ul>
<li>真实的场景中，会存在下面两种情况：<ul>
<li>全预分配，chunk 的数量和 shard 都是预先定义好的，比如 10 个 shard，存储 1000 个 chunk，那么每个 shard 分别拥有 100 个 chunk。</li>
<li>非预分配，这种情况则比较复杂，一般当一个 chunk 太大时会产生分裂（split），不断分裂的结果会导致不均衡；或者动态扩容增加分片时，也会出现不均衡的状态。 这种不均衡的状态由集群均衡器进行检测，一旦发现了不均衡则执行 chunk 数据的搬迁达到均衡。</li>
</ul>
</li>
<li>MongoDB 的数据均衡器运行于 Primary Config Server（配置服务器的主节点）上，而该节点也同时会控制 Chunk 数据的搬迁流程。<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_%E5%88%86%E7%89%87%E6%9C%BA%E5%88%B6_%E6%95%B0%E6%8D%AE%E8%87%AA%E5%8A%A8%E5%9D%87%E8%A1%A1.png" alt="MongoDB_分片机制_数据自动均衡"></li>
<li>对于数据的不均衡是根据两个分片上的 Chunk 个数差异来判定的，阈值对应表如下：<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_%E5%88%86%E7%89%87%E6%9C%BA%E5%88%B6_%E6%95%B0%E6%8D%AE%E8%87%AA%E5%8A%A8%E5%9D%87%E8%A1%A1%E8%A7%84%E5%88%99.png" alt="MongoDB_分片机制_数据自动均衡规则"></li>
</ul>
</li>
</ul>
</li>
<li>MongoDB 的数据迁移对集群性能存在一定影响，这点无法避免，目前的规避手段只能是将均衡窗口对齐到业务闲时段。</li>
</ul>
</li>
<li>应用高可用<ul>
<li>应用节点可以通过同时连接多个 Mongos 来实现高可用<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_Mongos_%E8%BF%9E%E6%8E%A5.png" alt="MongoDB_Mongos_连接"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>副本集<ul>
<li>副本集可以作为 Shard Cluster 中的一个Shard（片）之外，对于规模较小的业务来说，也可以使用一个单副本集的方式进行部署。</li>
<li>MongoDB 的副本集采取了一主多从的结构，即一个 Primary Node + N* Secondary Node 的方式，数据从主节点写入，并复制到多个备节点。</li>
<li>架构<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MongoDB_%E5%89%AF%E6%9C%AC%E6%9E%B6%E6%9E%84.png" alt="MongoDB_副本架构"></li>
</ul>
</li>
<li>利用副本集，我们可以实现：<ul>
<li>数据库高可用，主节点宕机后，由备节点自动选举成为新的主节点；</li>
<li>读写分离，读请求可以分流到备节点，减轻主节点的单点压力。<ul>
<li>请注意，读写分离只能增加集群”读”的能力，对于写负载非常高的情况却无能为力。</li>
<li>对此需求，使用分片集群并增加分片，或者提升数据库节点的磁盘IO、CPU能力可以取得一定效果。</li>
</ul>
</li>
</ul>
</li>
<li>选举<ul>
<li>MongoDB 副本集通过 Raft 算法来完成主节点的选举，这个环节在初始化的时候会自动完成</li>
</ul>
</li>
<li>心跳<ul>
<li>副本集中的每个节点上都会定时向其他节点发送心跳，以此来感知其他节点的变化，比如是否失效、或者角色发生了变化。</li>
<li>利用心跳，MongoDB 副本集实现了自动故障转移的功能</li>
<li>流程<ul>
<li>默认情况下，节点会每 2 秒向其他节点发出心跳，这其中包括了主节点。如果备节点在 10 秒内没有收到主节点的响应就会主动发起选举。</li>
<li>此时新一轮选举开始，新的主节点会产生并接管原来主节点的业务。整个过程对于上层是透明的，应用并不需要感知，因为 Mongos 会自动发现这些变化。</li>
<li>如果应用仅仅使用了单个副本集，那么就会由 Driver 层来自动完成处理。</li>
</ul>
</li>
</ul>
</li>
<li>复制<ul>
<li>主节点和备节点的数据是通过日志（oplog）复制来实现的，这很类似于 mysql 的 binlog。</li>
<li>流程<ul>
<li>在每一个副本集的节点中，都会存在一个名为 local.oplog.rs 的特殊集合。当 Primary 上的写操作完成后，会向该集合中写入一条 oplog，而 Secondary 则持续从 Primary 拉取新的 oplog 并在本地进行回放以达到同步的目的。</li>
</ul>
</li>
<li>MongoDB 对于 oplog 的设计是比较仔细的，比如：<ul>
<li>oplog 必须保证有序，通过 optime 来保证。</li>
<li>oplog 必须包含能够进行数据回放的完整信息。</li>
<li>oplog 必须是幂等的，即多次回放同一条日志产生的结果相同。</li>
<li>oplog 集合是固定大小的，为了避免对空间占用太大，旧的 oplog 记录会被滚动式的清理。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="事务与一致性"><a href="#事务与一致性" class="headerlink" title="事务与一致性"></a>事务与一致性</h2><ul>
<li>实质上，MongoDB 很早就有事务的概念，但是这个事务只能是针对单文档的，即单个文档的操作是有原子性保证的。</li>
<li>在 4.0 版本之后，MongoDB 开始支持多文档的事务：<ul>
<li>4.0 版本支持副本集范围的多文档事务。</li>
<li>4.2 版本支持跨分片的多文档事务（基于两阶段提交）。</li>
</ul>
</li>
<li>在事务的隔离性上，MongoDB 支持快照（snapshot）的隔离级别，可以避免脏读、不可重复读和幻读。</li>
<li>一致性<ul>
<li>在分布式架构的 CAP 理论以及许多延续的观点中提到，由于网络分区的存在，要求系统在一致性和可用性之间做出选择，而不能两者兼得。<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MongoDB/MongoDB-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/CAP%E7%90%86%E8%AE%BA.jpg" alt="CAP理论"></li>
</ul>
</li>
<li>在 MongoDB 中，这个选择是可以由开发者来定的。MongoDB 允许客户端为其操作设定一定的级别或者偏好，包括：<ul>
<li>read preference<ul>
<li>读取偏好，可指定读主节点、读备节点，或者是优先读主、优先读备、取最近的节点</li>
</ul>
</li>
<li>write concern<ul>
<li>写关注，指定写入结果达到什么状态时才返回，可以为无应答（none）、应答（ack），或者是大多数节点完成了数据复制等等</li>
</ul>
</li>
<li>read concern<ul>
<li>读关注，指定读取的数据版本处于怎样的状态，可以为读本地、读大多数节点写入，或者是线性读（linearizable）等等。</li>
</ul>
</li>
</ul>
</li>
<li>使用不同的设定将会产生对于C（一致性）、A（可用性）的不同的抉择，比如：<ul>
<li>将读偏好设置为 primary，此时读写都在主节点上。这保证了数据的一致性，但一旦主节点宕机会导致失败（可用性降低）</li>
<li>将读偏好设置为 secondaryPrefered，此时写主，优先读备，可用性提高了，但数据存在延迟（出现不一致）</li>
<li>将读写关注都设置为 majority（大多数），一致性提升了，但可用性也同时降低了（节点失效会导致大多数写失败）</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">MySQL-0-知识点汇总.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-01 12:10:14" itemprop="dateCreated datePublished" datetime="2019-09-01T12:10:14+08:00">2019-09-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MySQL/" itemprop="url" rel="index"><span itemprop="name">MySQL</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><h3 id="三范式"><a href="#三范式" class="headerlink" title="三范式"></a>三范式</h3><ol>
<li>第一范式：确保每列的原子性</li>
<li>第二范式：非主键列不存在对主键的部分依赖（要求每个表只描述一件事情）</li>
<li>第三范式：满足第二范式，并且表中的列不存在对非主键列的传递依赖</li>
</ol>
<h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><ul>
<li>分类<ul>
<li>DQL<ul>
<li>Data Query Language，数据查询语言</li>
<li>最常用的为保留字 SELECT，并且常与 FROM 子句、WHERE 子句组成查询 SQL 查询语句。</li>
</ul>
</li>
<li>DML<ul>
<li>Data Manipulation Language，数据操纵语言</li>
<li>主要用来对数据库的数据进行一些操作，常用的就是 INSERT、UPDATE、DELETE。</li>
</ul>
</li>
<li>DPL<ul>
<li>事务处理语言</li>
<li>事务处理语句能确保被 DML 语句影响的表的所有行及时得以更新。DPL 语句包括 BEGIN TRANSACTION、COMMIT 和 ROLLBACK。</li>
</ul>
</li>
<li>DCL<ul>
<li>数据控制语言</li>
<li>通过 GRANT 和 REVOKE，确定单个用户或用户组对数据库对象的访问权限。</li>
</ul>
</li>
<li>DDL<ul>
<li>数据定义语言</li>
<li>常用的有 CREATE 和 DROP，用于在数据库中创建新表或删除表，以及为表加入索引等。</li>
</ul>
</li>
<li>CCL<ul>
<li>指针控制语言</li>
<li>它的语句，像 DECLARE CURSOR、FETCH INTO 和 UPDATE WHERE CURRENT 用于对一个或多个表单独行的操作。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="引擎"><a href="#引擎" class="headerlink" title="引擎"></a>引擎</h2><ul>
<li>MyISAM<ul>
<li>不支持事务</li>
<li>不支持外键</li>
<li>是非聚集索引，也是使用 B+ Tree 作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MyISAM%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6.png" alt="MyISAM索引文件"></li>
</ul>
</li>
<li>用一个变量保存了整个表的行数</li>
<li>支持全文索引</li>
<li>支持表级锁</li>
<li>可以没有唯一索引</li>
<li>Myisam 存储文件有 frm、MYD、MYI<ul>
<li>frm 是表定义文件</li>
<li>myd 是数据文件</li>
<li>myi 是索引文件</li>
</ul>
</li>
</ul>
</li>
<li>InnoDB<ul>
<li>支持事务</li>
<li>支持外键</li>
<li>是聚集索引，使用 B+ Tree 作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按 B+ Tree 组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/InnoDB%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6.png" alt="InnoDB索引文件"></li>
<li>相关问题<ul>
<li><strong>为什么 MySQL 用 B+ 树做索引而不用 B-树或红黑树？</strong><ul>
<li>在大规模数据存储的时候，红黑树往往出现由于树的深度过大而造成磁盘 IO 读写过于频繁，进而导致效率低下的情况。<ul>
<li>磁盘读写 IO 跟树的深度有关系，磁盘一次 IO 读取的数据多能做的事也将更多。（我们知道要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘 IO 频繁读写。）根据磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，B 树可以有多个子女，从几十到上千，但是降低树的高度。</li>
</ul>
</li>
<li>数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次 I/O 就可以完全载入。为了达到这个目的，在实际实现 B-Tree 还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个 node 只需一次 I/O。<ul>
<li>B-Tree 有许多变种，其中最常见的是 B+Tree，例如 MySQL 就普遍使用 B+Tree 实现其索引结构。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>不保存表的具体行数，执行 <code>select count(*) from table</code> 时需要全表扫描<ul>
<li>想逛问题<ul>
<li><strong>为什么 InnoDB 没有保存行数呢？</strong><ul>
<li>因为 InnoDB 的事务特性，在同一时刻表中的行数对于不同的事务而言是不一样的，因此 count 统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>不支持全文索引（5.7以后的InnoDB支持全文索引了）</li>
<li>支持表、行（默认）级锁</li>
<li>须有唯一索引（如主键）（用户没有指定的话会自己找/生产一个隐藏列 Row_id 来充当默认主键）</li>
<li>Innodb 存储文件有 frm、ibd<ul>
<li>frm 是表定义文件</li>
<li>ibd 是数据文件</li>
</ul>
</li>
<li>InnoDB 的内存结构和磁盘结构<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_InnoDB_%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%92%8C%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84.jpg" alt="MySQL_InnoDB_内存结构和磁盘结构"></li>
<li>内存结构<ul>
<li>主要分为：Buffer Pool、Change Buffer、Adaptive HashIndex、（redo）log buffer</li>
<li>Innodb buffer pool<ul>
<li>MySQL InnoDB 缓冲池，CPU 读取或者写入数据时，不直接和低速的磁盘打交道，直接和缓冲区进行交互，从而解决了因为磁盘性能慢导致的数据库性能差的问题，弥补了两者之间的速度差异。</li>
<li>Buffer Pool 中更新的数据未刷新到磁盘中，该内存页称之为脏页。最终脏页的数据会刷新到磁盘中，将磁盘中的数据覆盖。</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E5%86%85%E9%83%A8%E6%B5%81%E7%A8%8B.jpg" alt="MySQL_语句执行内部流程"></li>
<li>Buffer Pool 预热<ul>
<li>MySQL 在重启后，Buffer Pool 里面没有什么数据，这个时候业务上对数据库的数据操作，MySQL 就只能从磁盘中读取数据到内存中，这个过程可能需要很久才能是内存中的数据是业务频繁使用的。Buffer Pool 中数据从无到业务频繁使用热数据的过程称之为预热。所以在预热这个过程中，MySQL 数据库的性能不会特别好，并且 Buffer Pool 越大，预热过程越长。</li>
<li>为了减短这个预热过程，在 MySQL 关闭前，把 Buffer Pool 中的页面信息保存到磁盘，等到 MySQL 启动时，再根据之前保存的信息把磁盘中的数据加载到 Buffer Pool 中即可。</li>
<li>结构<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_buffer_pool_%E7%BB%93%E6%9E%84.png" alt="MySQL_buffer_pool_结构"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Change Buffer<ul>
<li>在更新数据的时候，如果这个数据页不是唯一索引（索引的值不允许重复），也就不需要从磁盘加载索引页判断数据是不是重复（唯一性检查）。这种情况下可以先把修改记录在内存的缓冲池中，从而提升更新语句（Insert、Delete、Update）的执行速度。</li>
<li>这一块区域就是 Change Buffer。5.5 之前叫 Insert Buffer 插入缓冲，现在也能支持 delete 和 update，最后把 Change Buffer 记录到数据页的操作叫做 merge。<ul>
<li>相关问题<ul>
<li><strong>什么时候发生 merge？</strong><ul>
<li>在访问这个数据页的时候、或者通过后台线程、或者数据库 shut down、redo log 写满时触发</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Adaptive Hash Index<ul>
<li>InnoDB 存储引擎会监控对表上索引的查找，如果观察到建立哈希索引可以带来速度的提升，则建立哈希索引，所以称之为自适应（adaptive）的。自适应哈希索引通过缓冲池的 B+ 树构造而来，因此建立的速度很快。而且不需要将整个表都建哈希索引，InnoDB 存储引擎会自动根据访问的频率和模式来为某些页建立哈希索引。</li>
</ul>
</li>
<li>（redo）Log Buffer<ul>
<li>如果 Buffer Pool 里面的脏页还没有刷入磁盘时，数据库宕机或者重启，这些数据丢失。如果写操作写到一半，甚至可能会破坏数据文件导致数据库不可用，怎么办？</li>
<li>为了避免这个问题，InnoDB 把所有的修改操作专门写入一个日志文件，并且在数据库启动时从这个文件进行恢复操作（实现 crash-safe）——用它来实现事务的持久性。</li>
<li>这个文件就是磁盘的 redo log（叫做重做日志）。</li>
</ul>
</li>
</ul>
</li>
<li>磁盘结构<ul>
<li>系统表空间 system tablespace</li>
<li>独占表空间 file-per-table tablespaces<ul>
<li>我们可以让每张表独占一个表空间。这个开关通过 innodb_file_per_table 设置，默认开启。</li>
</ul>
</li>
<li>通用表空间 general tablespaces<ul>
<li>通用表空间也是一种共享的表空间，跟 ibdata1 类似。可以创建一个通用的表空间，用来存储不同数据库的表，数据路径和文件可以自定义</li>
</ul>
</li>
<li>临时表空间 temporary tablespaces<ul>
<li>存储临时表的数据，包括用户创建的临时表，和磁盘的内部临时表。对应数据目录下的 ibtmp1 文件。当数据服务器正常关闭时，该表空间被删除，下次重新产生。</li>
</ul>
</li>
<li>redo log</li>
<li>undo Log</li>
</ul>
</li>
</ul>
</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_Innodb%E6%9E%B6%E6%9E%84.PNG" alt="MySQL_Innodb架构"></li>
</ul>
</li>
</ul>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><ul>
<li>五大类<ul>
<li>整数类型：BIT、BOOL、TINY INT、SMALL INT、MEDIUM INT、INT、BIG INT</li>
<li>浮点数类型：FLOAT、DOUBLE、DECIMAL<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B_%E6%95%B4%E6%95%B0%E7%B1%BB%E5%9E%8B_%E6%B5%AE%E7%82%B9%E6%95%B0%E7%B1%BB%E5%9E%8B.jpg" alt="MySQL_数据类型_整数类型_浮点数类型"></li>
</ul>
</li>
<li>字符串类型：CHAR、VARCHAR、TINY TEXT、TEXT、MEDIUM TEXT、LONGTEXT、TINY BLOB、BLOB、MEDIUM BLOB、LONG BLOB<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B_%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B.jpg" alt="MySQL_数据类型_字符串类型"></li>
</ul>
</li>
<li>日期类型：Date、DateTime、TimeStamp、Time、Year<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B_%E6%97%A5%E6%9C%9F%E7%B1%BB%E5%9E%8B.jpg" alt="MySQL_数据类型_日期类型"></li>
</ul>
</li>
<li>其他数据类型：BINARY、VARBINARY、ENUM、SET、Geometry、Point、MultiPoint、LineString、MultiLineString、Polygon、GeometryCollection 等</li>
</ul>
</li>
</ul>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><ul>
<li>InnoDB<ul>
<li>分类<ul>
<li>物理分类<ul>
<li>聚集索引<ul>
<li>聚集索引就是以主键创建的索引</li>
<li>每个表只能有一个聚簇索引，因为一个表中的记录只能以一种物理顺序存放，实际的数据⻚只能按照一颗 B+ 树进行排序</li>
<li>表记录的排列顺序和与索引的排列顺序一致</li>
<li>聚集索引存储记录是物理上连续存在</li>
<li>聚簇索引主键的插入速度要比非聚簇索引主键的插入速度慢很多</li>
<li>聚簇索引适合排序，非聚簇索引不适合用在排序的场合，因为聚簇索引叶节点本身就是索引和 数据按相同顺序放置在一起，索引序即是数据序，数据序即是索引序，所以很快。非聚簇索引叶节点是保留了一个指向数据的指针，索引本身当然是排序的，但是数据并未排序，数据查询的时候需要消耗额外更多的 I/O，所以较慢</li>
<li>更新聚集索引列的代价很高，因为会强制 innodb 将每个被更新的行移动到新的位置</li>
</ul>
</li>
<li>非聚集索引<ul>
<li>除了主键以外的索引</li>
<li>聚集索引的叶节点就是数据节点，而非聚簇索引的叶节点仍然是索引节点，并保留一个链接指向对应数据块</li>
<li>聚簇索引适合排序，非聚簇索引不适合用在排序的场合</li>
<li>聚集索引存储记录是物理上连续存在，非聚集索引是逻辑上的连续。</li>
</ul>
</li>
</ul>
</li>
<li>逻辑分类<ul>
<li>唯一索引</li>
<li>主键索引</li>
<li>普通索引</li>
<li>全文索引</li>
<li>联合索引<ul>
<li>最左匹配原则</li>
<li>索引覆盖<ul>
<li>在查询里，联合索引已经“覆盖了”我们的查询需求，故称为覆盖索引。从辅助索引中就能直接得到查询结果，而不需要回表到聚簇索引中进行再次查询，所以可以减少搜索次数（不需要从辅助索引树回表到聚簇索引树），或者说减少IO操作（通过辅助索引树可以一次性从磁盘载入更多节点），从而提升性能。</li>
</ul>
</li>
<li>索引下推<ul>
<li>例子<ul>
<li>在开始之前先先准备一张用户表（user），其中主要几个字段有：id、name、age、address。建立联合索引（name，age）。</li>
<li>执行<code>SELECT * from user where  name like &#39;陈%&#39; and age=20</code></li>
</ul>
</li>
<li>MySQL5.6 之前的版本<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8_1.jpeg" alt="MySQL索引下推_1"></li>
<li>会忽略 age 这个字段，直接通过 name 进行查询，在索引课树上查找到了两个结果，id 分别为 2、1，然后拿着取到的 id 值一次次的回表查询，因此这个过程需要回表两次。</li>
</ul>
</li>
<li>MySQL5.6 及之后版本<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8_2.jpeg" alt="MySQL索引下推_2"></li>
<li>并没有忽略 age 这个字段，而是在索引内部就判断了 age 是否等于 20，对于不等于 20 的记录直接跳过，因此在 (name,age) 这棵索引树中只匹配到了一个记录，此时拿着这个 id 去主键索引树中回表查询全部数据，这个过程只需要回表一次。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>优化使用<ul>
<li>对查询进行优化，要尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。</li>
<li>应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描</li>
<li>不在索引上进行任何操作<ul>
<li>索引上进行计算、函数、类型转换等操作都会导致索引从当前位置（联合索引多个字段，不影响前面字段的匹配）失效，可能会进行全表扫描。</li>
<li>隐式类型转换<ul>
<li>在查询时一定要注意字段类型问题，比如a字段时字符串类型的，而匹配参数用的是int类型，此时就会发生隐式类型转换，相当于相当于在索引上使用函数。</li>
</ul>
</li>
</ul>
</li>
<li>只查询需要的列<ul>
<li>查询无用的列在数据传输和解析绑定过程中会增加网络 IO，以及 CPU 的开销</li>
<li>会使得覆盖索引”失效”，这里的失效并非真正的不走索引。覆盖索引的本质就是在索引中包含所要查询的字段，而<code>select *</code>将使覆盖索引失去意义，仍然需要进行回表操作</li>
</ul>
</li>
<li>应尽量避免在 where 子句中使用 != 或 &lt;&gt; 操作符，否则将引擎放弃使用索引而进行全表扫描。</li>
<li>应尽量避免在 where 子句中使用 or 来连接条件，如果一个字段有索引，一个字段没有索引，将导致引擎放弃使用索引而进行全表扫描</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><ul>
<li>事务特点（ACID）<ul>
<li>原子性（atomicity）<ul>
<li><strong>MySQL 怎么保证原子性的？</strong><ul>
<li>利用 Innodb 的undo log。</li>
<li>undo log 名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的 sql 语句，他需要记录你要回滚的相应日志信息。</li>
<li>例如<ol>
<li>当你 delete 一条数据的时候，就需要记录这条数据的信息，回滚的时候，insert 这条旧数据</li>
<li>当你 update 一条数据的时候，就需要记录之前的旧值，回滚的时候，根据旧值执行 update 操作</li>
<li>当你 insert 一条数据的时候，就需要这条记录的主键，回滚的时候，根据主键执行 delete 操作</li>
</ol>
</li>
<li>undo log 记录了这些回滚需要的信息，当事务执行失败或调用了 rollback，导致事务需要回滚，便可以利用 undo log 中的信息将数据回滚到修改之前的样子。</li>
</ul>
</li>
</ul>
</li>
<li>一致性（consistency）<ul>
<li><strong>MySQL 怎么保证一致性的？</strong><ul>
<li>这个问题分为两个层面来说。<ul>
<li>从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说 ACID 四大特性之中，C（一致性）是目的，A（原子性）、I（隔离性）、D（持久性）是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现 AID 三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。</li>
<li>但是，如果你在事务里故意写出违反约束的代码，一致性还是无法保证的。例如，你在转账的例子中，你的代码里故意不给 B 账户加钱，那一致性还是无法保证。因此，还必须从应用层角度考虑。</li>
<li>从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>隔离性（isolation）<ul>
<li><strong>MySQL 怎么保证隔离性的？</strong><ul>
<li>利用的是锁和 MVCC 机制。</li>
</ul>
</li>
</ul>
</li>
<li>持久性（durability）<ul>
<li><strong>MySQL 怎么保证持久性的？</strong><ul>
<li>是利用 Innodb 的 redo log。MySQL 是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。怎么解决这个问题？简单啊，事务提交前直接把数据写入磁盘就行啊。这么做有什么问题？<ul>
<li>只修改一个页面里的一个字节，就要将整个页面刷入磁盘，太浪费资源了。毕竟一个页面 16kb 大小，你只改其中一点点东西，就要将 16kb 的内容刷入磁盘，听着也不合理。</li>
<li>毕竟一个事务里的 SQL 可能牵涉到多个数据页的修改，而这些数据页可能不是相邻的，也就是属于随机 IO。显然操作随机 IO，速度会比较慢。</li>
</ul>
</li>
<li>于是，决定采用 redo log 解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在 redo log 中记录这次操作。当事务提交的时候，会将 redo log 日志进行刷盘（redo log一部分在内存中，一部分在磁盘上）。当数据库宕机重启的时候，会将 redo log 中的内容恢复到数据库中，再根据 undo log 和 binlog 内容决定回滚数据还是提交数据。<ul>
<li><strong>采用 redo log 的好处？</strong><ul>
<li>好处就是将 redo log 进行刷盘比对数据页刷盘效率高，具体表现如下<ul>
<li>redo log 体积小，毕竟只记录了哪一页修改了啥，因此体积小，刷盘快。</li>
<li>redo log 是一直往末尾进行追加，属于顺序 IO。效率显然比随机 IO 来的快。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>实现方式<ul>
<li>通过预写日志方式实现的，redo 和 undo 机制是数据库实现事务的基础</li>
<li>redo 日志用来在断电/数据库崩溃等状况发生时重演一次刷数据的过程，把 redo 日志里的数据刷到数据库里，保证了事务的持久性（Durability）</li>
<li>undo 日志是在事务执行失败的时候撤销对数据库的操作，保证了事务的原子性</li>
</ul>
</li>
<li>事务的离级别<ul>
<li>Read Uncommitted（读未提交）<ul>
<li>所有事务都可以看到其他未提交事务的执行结果</li>
<li>会产生<strong>脏读（Dirty Read）</strong></li>
</ul>
</li>
<li>Read Committed（读已提交）<ul>
<li>一个事务只能看⻅已经提交事务所做的改变</li>
<li>会产生<strong>不可重复读（Nonrepeatable Read）</strong></li>
<li>通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了脏读（Dirty Read）问题<ul>
<li>每次发起查询，都重新生成一个 ReadView</li>
</ul>
</li>
</ul>
</li>
<li>Repeatable Read（可重读）<ul>
<li>MySQL 的默认事务隔离级别</li>
<li>确保同一事务的多个实例在并发读取数据时，会看到同样的数据行</li>
<li>会产生<strong>幻读（Phantom Read）</strong><ul>
<li>幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影”行。</li>
</ul>
</li>
<li>通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了不可重复读（Nonrepeatable Read）问题<ul>
<li>创建事务 trx 结构的时候，就生成了当前的 global read view。使用 trx_assign_read_view 函数创建，一直维持到事务结束。在事务结束这段时间内每一次查询都不会重新重建 Read View，从而实现了可重复读。</li>
</ul>
</li>
</ul>
</li>
<li>Serializable（串行化）<ul>
<li>通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。在每个读的数据行上加上共享锁</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="并发控制"><a href="#并发控制" class="headerlink" title="并发控制"></a>并发控制</h2><ul>
<li>LBCC<ul>
<li>基于锁的并发控制 Lock Based Concurrency Control（LBCC）</li>
</ul>
</li>
<li>MVCC<ul>
<li>多版本的并发控制 Multi Version Concurrency Control（MVCC）</li>
<li>在 Mysql 的 InnoDB 引擎中就是指在读已提交（READ COMMITTD）和可重复读（REPEATABLE READ）这两种隔离级别下的事务对于 SELECT 操作会访问版本链中的记录的过程。</li>
<li>当前读、快照读<ul>
<li>当前读<ul>
<li>像 select lock in share mode（共享锁），select for update、update、insert、delete（排他锁） 这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。</li>
</ul>
</li>
<li>快照读<ul>
<li>不加锁的 select 操作就是快照读</li>
</ul>
</li>
</ul>
</li>
<li>实现原理<ul>
<li>通过 Undo 日志中的版本链和 ReadView 一致性视图来实现的。</li>
<li>每行记录的隐藏字段：<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_MVCC_1.png" alt="MySQL_MVCC_1"></li>
<li>DB_TRX_ID<ul>
<li>6byte，最近修改（修改/插入）事务 ID：记录创建这条记录/最后一次修改该记录的事务ID</li>
</ul>
</li>
<li>DB_ROLL_PTR<ul>
<li>7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）</li>
</ul>
</li>
<li>DB_ROW_ID<ul>
<li>6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引</li>
</ul>
</li>
<li>实际还有一个删除 flag 隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除 flag 变了</li>
</ul>
</li>
<li>Undo 日志<ul>
<li>undo log 主要分为两种：<ul>
<li>insert undo log<ul>
<li>代表事务在 insert 新记录时产生的 undo log，只在事务回滚时需要，并且在事务提交后可以被立即丢弃</li>
</ul>
</li>
<li>update undo log<ul>
<li>事务在进行 update 或 delete 时产生的 undo log；不仅在事务回滚时需要，在快照读时也需要；所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被 purge 线程统一清除<ul>
<li>purge<ul>
<li>更新或者删除操作都只是设置一下老记录的 deleted_bit，并不真正将过时的记录删除。</li>
<li>为了节省磁盘空间，InnoDB 有专门的 purge 线程来清理 deleted_bit 为 true 的记录。为了不影响 MVCC 的正常工作，purge 线程自己也维护了一个 read view（这个 read view 相当于系统中最老活跃事务的 read view）；如果某个记录的 deleted_bit 为 true，并且 DB_TRX_ID 相对于 purge 线程的 read view 可见，那么这条记录一定是可以被安全清除的。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>插入数据时流程<ul>
<li>举例<ol>
<li>比如一个有个事务插入 person 表插入了一条新记录，记录如下，name 为 Jerry, age 为 24 岁，隐式主键是 1，事务 ID 和回滚指针，我们假设为 NULL<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_MVCC_%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE_1.png" alt="MySQL_MVCC_插入数据_1"></li>
</ul>
</li>
<li>现在来了一个事务 1 对该记录的 name 做出了修改，改为 Tom<ul>
<li>在事务 1 修改该行（记录）数据时，数据库会先对该行加排他锁</li>
<li>然后把该行数据拷贝到 undo log 中，作为旧记录，既在 undo log 中有当前行的拷贝副本</li>
<li>拷贝完毕后，修改该行 name 为 Tom，并且修改隐藏字段的事务 ID 为当前事务 1 的 ID, 我们默认从 1 开始，之后递增，回滚指针指向拷贝到 undo log 的副本记录，既表示我的上一个版本就是它</li>
<li>事务提交后，释放锁</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_MVCC_%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE_2.png" alt="MySQL_MVCC_插入数据_2"></li>
</ul>
</li>
<li>又来了个事务 2 修改 person 表的同一个记录，将 age 修改为 30 岁<ul>
<li>在事务 2 修改该行数据时，数据库也先为该行加锁</li>
<li>然后把该行数据拷贝到 undo log 中，作为旧记录，发现该行记录已经有 undo log 了，那么最新的旧数据作为链表的表头，插在该行记录的 undo log 最前面</li>
<li>修改该行 age 为 30 岁，并且修改隐藏字段的事务 ID 为当前事务 2 的 ID, 那就是 2，回滚指针指向刚刚拷贝到 undo log 的副本记录</li>
<li>事务提交，释放锁</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_MVCC_%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE_3.png" alt="MySQL_MVCC_插入数据_3"></li>
</ul>
</li>
</ol>
<ul>
<li>从上面，我们就可以看出，不同事务或者相同事务的对同一记录的修改，会导致该记录的 undo log 成为一条记录版本线性表，既链表，undo log 的链首就是最新的旧记录，链尾就是最早的旧记录（当然就像之前说的该 undo log 的节点可能是会 purge 线程清除掉，向图中的第一条 insert undo log，其实在事务提交之后可能就被删除丢失了，不过这里为了演示，所以还放在这里）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Read View（读视图）<ul>
<li>Read View 就是事务进行快照读操作的时候生产的读视图（Read View），在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照。</li>
</ul>
</li>
<li>流程<ul>
<li>三个全局属性<ul>
<li>trx_list<ul>
<li>一个数值列表，用来维护 Read View 生成时刻系统正活跃的事务 ID</li>
</ul>
</li>
<li>up_limit_id<ul>
<li>记录 trx_list 列表中事务 ID 最小的ID</li>
</ul>
</li>
<li>low_limit_id<ul>
<li>ReadView 生成时刻系统尚未分配的下一个事务 ID，也就是目前已出现过的事务 ID 的最大值+1</li>
</ul>
</li>
</ul>
</li>
<li>流程<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_MVCC_%E6%B5%81%E7%A8%8B.png" alt="MySQL_MVCC_流程"></li>
</ul>
<ol>
<li>首先比较 DB_TRX_ID &lt; up_limit_id, 如果小于，则当前事务能看到 DB_TRX_ID 所在的记录，如果大于等于进入下一个判断</li>
<li>接下来判断 DB_TRX_ID &gt;= low_limit_id , 如果大于等于则代表 DB_TRX_ID 所在的记录在 Read View 生成后才出现的，那对当前事务肯定不可见，如果小于则进入下一个判断</li>
<li>判断 DB_TRX_ID 是否在活跃事务之中，<code>trx_list.contains(DB_TRX_ID)</code>，如果在，则代表我 Read View 生成时刻，你这个事务还在活跃，还没有 Commit，你修改的数据，我当前事务也是看不见的；如果不在，则说明，你这个事务在 Read View 生成之前就已经 Commit 了，你修改的结果，我当前事务是能看见的</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><ul>
<li>undo log<ul>
<li>基本概念<ul>
<li>undo log 有两个作用<ul>
<li>提供回滚</li>
<li>多个行版本控制（MVCC）</li>
</ul>
</li>
<li>undo log 和 redo log 记录物理日志不一样，它是逻辑日志。可以认为当 delete 一条记录时，undo log 中会记录一条对应的 insert 记录，反之亦然，当 update 一条记录时，它记录一条对应相反的 update 记录。</li>
<li>当执行 rollback 时，就可以从 undo log 中的逻辑记录读取到相应的内容并进行回滚。有时候应用到行版本控制的时候，也是通过 undo log 来实现的：当读取的某一行被其他事务锁定时，它可以从 undo log 中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。</li>
<li>undo log 是采用段（segment）的方式来记录的，每个 undo 操作在记录的时候占用一个 undo log segment。</li>
<li>另外，undo log 也会产生 redo log，因为 undo log 也要实现持久性保护。</li>
</ul>
</li>
<li>存储方式<ul>
<li>innodb 存储引擎对undo的管理采用段的方式。rollback segment 称为回滚段，每个回滚段中有 1024 个 undo log segment。<ul>
<li>版本区别<ul>
<li>老版本，只支持 1 个 rollback segment，这样就只能记录 1024 个 undo log segment。</li>
<li>MySQL5.5 可以支持 128 个 rollback segment，即支持 128*1024 个 undo 操作，还可以通过变量 innodb_undo_logs（5.6 版本以前该变量是 innodb_rollback_segments）自定义多少个 rollback segment，默认值为 128。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>delete/update 操作的内部机制<ul>
<li>insert 操作无需分析，就是插入行而已</li>
<li>delete 操作实际上不会直接删除，而是将 delete 对象打上 delete flag，标记为删除，最终的删除操作是 purge 线程完成的。</li>
<li>update 分为两种情况：update 的列是否是主键列。<ul>
<li>如果不是主键列，在 undo log 中直接反向记录是如何 update 的。即 update 是直接进行的。</li>
<li>如果是主键列，update 分两部执行：先删除该行，再插入一行目标行。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>redo log<ul>
<li>出现原因<ul>
<li>在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。这么做会有严重的性能问题，主要体现在两个方面：<ul>
<li>因为 Innodb 是以页为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！</li>
<li>一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机 I/O 写入性能太差！</li>
</ul>
</li>
</ul>
</li>
<li>redo log 是重做日志，提供再写入操作，实现事务的持久性。日志记录事务对数据页做了哪些修改。</li>
<li>redo log 又包括了内存中的日志缓冲（redo log buffer）以及保存在磁盘的重做日志文件（redo log file）<ul>
<li>前者存储在内存中，容易丢失，后者持久化在磁盘中，不会丢失。</li>
</ul>
</li>
<li>底层原理<ul>
<li>结构<ul>
<li>InnoDB 的 redo log 的大小是固定的，分别有多个日志文件采用循环方式组成一个循环闭环，当写到结尾时，会回到开头循环写日志。<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_redo_log_%E7%8E%AF%E5%BD%A2.png" alt="MySQL_redo_log_环形"><ul>
<li>write pos 表示 redo log 当前记录的 LSN（逻辑序列号）位置，check point 表示数据页更改记录刷盘后对应 redo log 所处的 LSN（逻辑序列号）位置。</li>
<li>write pos 到 check point 之间的部分是 redo log 空着的部分，用于记录新的记录；check point 到 write pos 之间是 redo log 待落盘的数据页更改记录。当 write pos 追 上check point 时，会先推动 check point 向前移动，空出位置再记录新的日志。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>日志块（log block）<ul>
<li>innodb 存储引擎中，redo log 以块为单位进行存储的，每个块占 512 字节，这称为 redo log block。所以不管是 log buffer 中还是 os buffer 中以及 redo log file on disk 中，都是这样以 512 字节的块存储的。</li>
<li>每个 redo log block 由 3 部分组成：日志块头、日志块尾和日志主体。其中日志块头占用 12 字节，日志块尾占用 8 字节，所以每个 redo log block 的日志主体部分只有 512-12-8=492 字节。<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_redo_log_%E6%97%A5%E5%BF%97%E5%9D%97.png" alt="MySQL_redo_log_日志块"></li>
<li>日志块头包含 4 部分：<ul>
<li>log_block_hdr_no：（4 字节）该日志块在 redo log buffer 中的位置 ID。</li>
<li>log_block_hdr_data_len：（2 字节）该 log block 中已记录的 log 大小。写满该 log block 时为 0x200，表示 512 字节。</li>
<li>log_block_first_rec_group：（2 字节）该 log block 中第一个 log 的开始偏移位置。<ul>
<li>因为有时候一个数据页产生的日志量超出了一个日志块，这是需要用多个日志块来记录该页的相关日志。例如，某一数据页产生了 552 字节的日志量，那么需要占用两个日志块，第一个日志块占用 492 字节，第二个日志块需要占用 60个字节，那么对于第二个日志块来说，它的第一个 log 的开始位置就是 73 字节（60+12）。如果该部分的值和 log_block_hdr_data_len 相等，则说明该 log block 中没有新开始的日志块，即表示该日志块用来延续前一个日志块。</li>
</ul>
</li>
<li>lock_block_checkpoint_no：（4 字节）写入检查点信息的位置。</li>
</ul>
</li>
<li>日志尾只有一个部分：log_block_trl_no，该值和块头的 log_block_hdr_no 相等。</li>
</ul>
</li>
<li>因为 redo log 记录的是数据页的变化，当一个数据页产生的变化需要使用超过 492 字节的 redo log 来记录，那么就会使用多个 redo log block 来记录该数据页的变化。</li>
</ul>
</li>
<li>log group 和 redo log file<ul>
<li>log group 表示的是 redo log group，一个组内由多个大小完全相同的 redo log file 组成。这个组是一个逻辑的概念，并没有真正的文件来表示这是一个组。</li>
<li>写入方式<ul>
<li>在 innodb 将 log buffer 中的 redo log block 刷到这些 log file 中时，会以追加写入的方式循环轮训写入。即先在第一个 log file（即 ib_logfile0）的尾部追加写，直到满了之后向第二个 log file（即 ib_logfile1）写。当第二个 log file 满了会清空一部分第一个 log file 继续写入。</li>
</ul>
</li>
<li>结构<ul>
<li>在每个组的第一个 redo log file 中，前 2KB 记录 4 个特定的部分，从 2KB 之后才开始记录 log block。除了第一个 redo log file 中会记录，log group 中的其他 log file 不会记录这 2KB，但是却会腾出这 2KB 的空间。<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_redo_log_log_group.png" alt="MySQL_redo_log_log_group"></li>
</ul>
</li>
</ul>
</li>
<li>redo log file 的大小对 innodb 的性能影响非常大，设置的太大，恢复的时候就会时间较长，设置的太小，就会导致在写 redo log 的时候循环切换 redo log file。</li>
</ul>
</li>
<li>redo log 的格式<ul>
<li>因为 innodb 存储引擎存储数据的单元是页（和 SQL Server 中一样），所以 redo log 也是基于页的格式来记录的。默认情况下，innodb 的页大小是 16KB，一个页内可以存放非常多的 log block（每个 512 字节），而 log block 中记录的又是数据页的变化。</li>
<li>其中 log block 中 492 字节的部分是 log body，该 log body 的格式分为 4 部分：<ul>
<li>redo_log_type：占用 1 个字节，表示 redo log 的日志类型。</li>
<li>space：表示表空间的 ID，采用压缩的方式后，占用的空间可能小于 4 字节。</li>
<li>page_no：表示页的偏移量，同样是压缩过的。</li>
<li>redo_log_body 表示每个重做日志的数据部分，恢复时会调用相应的函数进行解析。<ul>
<li>例如 insert 语句和 delete 语句写入 redo log 的内容是不一样的。</li>
</ul>
</li>
</ul>
</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_redo_log_%E6%A0%BC%E5%BC%8F.png" alt="MySQL_redo_log_格式"></li>
</ul>
</li>
</ul>
</li>
<li>流程<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_redo_log_%E5%86%99%E5%85%A5%E6%B5%81%E7%A8%8B.jpg" alt="MySQL_redo_log_写入流程"></li>
<li>InnoDB 的更新操作采用的是 Write Ahead Log 策略。<ul>
<li>WAL 即 Write Ahead Log，WAL 的主要意思是说在将元数据的变更操作写入磁盘之前，先预先写入到一个 log 文件中。</li>
<li>可以将对数据文件的随机写转换为堆 redo log 的顺序写，提高了性能。</li>
</ul>
</li>
<li>只有当 redo log 日志满了的情况下，才会主动触发脏页刷新到磁盘，而脏页不仅只有 redo log 日志满了的情况才会刷新到磁盘，以下几种情况同样会触发脏页的刷新：<ul>
<li>系统内存不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘；</li>
<li>MySQL 认为空闲的时间，这种情况没有性能问题；</li>
<li>MySQL 正常关闭之前，会把所有的脏页刷入到磁盘，这种情况也没有性能问题。</li>
</ul>
</li>
<li>启动、宕机时的写入<ul>
<li>启动 InnoDB 的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。因为 redo log 记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志（如 binlog）要快很多。</li>
<li>重启 InnoDB 时，首先会检查磁盘中数据页的 LSN，如果数据页的 LSN 小于日志中的 LSN，则会从 checkpoint 开始恢复。</li>
<li>还有一种情况，在宕机前正处于 checkpoint 的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 LSN 大于日志中的 LSN，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。</li>
</ul>
</li>
</ul>
</li>
<li>写入机制<ul>
<li>MySQL 支持用户自定义在 commit 时如何将 log buffer 中的日志刷 log file 中。这种控制通过变量 innodb_flush_log_at_trx_commit 的值来决定。该变量有 3 种值：0、1、2，默认为 1。但注意，这个变量只是控制 commit 动作是否刷新 log buffer 到磁盘。<ul>
<li>当设置为 1 的时候，事务每次提交都会将 log buffer 中的日志写入 os buffer 并调用 <code>fsync()</code> 刷到 log file on disk 中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO 的性能较差。</li>
<li>当设置为 0 的时候，事务提交时不会将 log buffer 中日志写入到 os buffer，而是每秒写入 os buffer 并调用 <code>fsync()</code> 写入到 log file on disk 中。也就是说设置为 0 时是（大约）每秒刷新写入到磁盘中的，当系统崩溃，会丢失 1 秒钟的数据。</li>
<li>当设置为 2 的时候，每次提交都仅写入到 os buffer，然后是每秒调用 <code>fsync()</code> 将 os buffer 中的日志写入到 log file on disk。【一般建议选择取值 2，因为 MySQL 挂了数据没有损失，整个服务器挂了才会损失 1 秒的事务提交数据。】</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_redo_log_%E5%88%B7%E7%9B%98.png" alt="MySQL_redo_log_刷盘"></li>
</ul>
</li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>redo log 与 binlog 的区别？</strong><ol>
<li>redo log 是在 InnoDB 存储引擎层产生，而 binlog 是 MySQL 数据库的上层产生的，并且二进制日志不仅仅针对 INNODB 存储引擎，MySQL 数据库中的任何存储引擎对于数据库的更改都会产生二进制日志。</li>
<li>两种日志记录的内容形式不同。MySQL 的 binlog 是逻辑日志，其记录是对应的 SQL 语句。而 innodb 存储引擎层面的重做日志是物理日志。</li>
<li>两种日志与记录写入磁盘的时间点不同，二进制日志只在事务提交完成后进行一次写入。而 innodb 存储引擎的重做日志在事务进行中不断地被写入，并日志不是随事务提交的顺序进行写入的。<ul>
<li>二进制日志仅在事务提交时记录，并且对于每一个事务，仅在事务提交时记录，并且对于每一个事务，仅包含对应事务的一个日志。而对于 innodb 存储引擎的重做日志，由于其记录是物理操作日志，因此每个事务对应多个日志条目，并且事务的重做日志写入是并发的，并非在事务提交时写入，其在文件中记录的顺序并非是事务开始的顺序。</li>
</ul>
</li>
<li>binlog 不是循环使用，在写满或者重启之后，会生成新的 binlog 文件，redo log 是循环使用。</li>
<li>binlog 可以作为恢复数据使用，主从复制搭建，redo log 作为异常宕机或者介质故障后的数据恢复使用。</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li>binlog<ul>
<li>binlog 是二进制日志文件，用于记录 MySQL 的数据更新或者潜在更新（比如 DELETE 语句执行删除而实际并没有符合条件的数据），在 MySQL 主从复制中就是依靠的 binlog。</li>
<li>binlog 是 MySQL 的逻辑日志，并且由 Server 层进行记录，<strong>使用任何存储引擎的 MySQL 数据库都会记录 binlog 日志</strong>。<ul>
<li>逻辑日志：可以简单理解为记录的就是 sql 语句。</li>
<li>物理日志：因为 MySQL 数据最终是保存在数据页中的，物理日志记录的就是数据页变更。</li>
</ul>
</li>
<li>binlog 是通过追加的方式进行写入的，可以通过 max_binlog_size 参数设置每个 binlog 文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。</li>
<li>binlog 的三种工作模式：<ul>
<li>Row level<ul>
<li>简介：日志中会记录每一行数据被修改的情况，然后在 slave 端对相同的数据进行修改。</li>
<li>优点：能清楚的记录每一行数据修改的细节</li>
<li>缺点：数据量太大</li>
</ul>
</li>
<li>Statement level（默认）<ul>
<li>简介：每一条被修改数据的 sql 都会记录到 master 的 bin-log 中，slave 在复制的时候 sql 进程会解析成和原来 master 端执行过的相同的 sql 再次执行。在主从同步中一般是不建议用 statement 模式的，因为会有些语句不支持，比如语句中包含 UUID 函数，以及 LOAD DATA IN FILE 语句等</li>
<li>优点：解决了 Row level 的缺点，不需要记录每一行的数据变化，减少 bin-log 日志量，节约磁盘 IO，提高新能　</li>
<li>缺点：容易出现主从复制不一致</li>
</ul>
</li>
<li>Mixed<ul>
<li>简介：在 Mixed 模式下，一般的语句修改使用 statment 格式保存 binlog，如一些函数，statement 无法完成主从复制的操作，则采用 row 格式保存 binlog，MySQL 会根据执行的每一条具体的 sql 语句来区分对待记录的日志形式，也就是在 Statement 和 Row 之间选择一种。</li>
</ul>
</li>
</ul>
</li>
<li>写入机制<ul>
<li>事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。<ul>
<li>binlog cache<ul>
<li>系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。</li>
</ul>
</li>
</ul>
</li>
<li>一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_binlog%E5%86%99%E5%85%A5.png" alt="MySQL_binlog写入"><ul>
<li>可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件。</li>
<li>图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。</li>
<li>图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS（Input/Output Operations Per Second）。</li>
</ul>
</li>
<li>write 和 fsync 的时机，是由参数 sync_binlog 控制的：<ul>
<li>0：表示每次提交事务都只 write，不 fsync；</li>
<li>1：表示每次提交事务都会执行 fsync；（默认值）</li>
<li>N：表示每次提交事务都 write，但累积 N 个事务后才 fsync。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>两阶段提交<ul>
<li>MySQL 最开始是没有 InnoDB 引擎的，binlog 日志位于 Server 层，只是用于归档和主从复制，本身不具备 crash safe 的能力。而 InnoDB 依靠 redo log 具备了 crash safe 的能力，redo log 和 binlog 同时记录，就需要保证两者的一致性。</li>
<li>提交过程<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_Innodb_%E4%BA%8C%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.png" alt="MySQL_Innodb_二阶段提交"></li>
</ul>
<ol>
<li>prepare 阶段<ul>
<li>此阶段负责：<ul>
<li>在 Innodb 层获取独占模式的 prepare_commit_mutex，将事务的 trx_id 写入 redo log（redo 日志的写机制为 WAL 所以在事务修改前就会写 redo buffer 而不是 commit 时一次性写入）。</li>
</ul>
</li>
</ul>
</li>
<li>commit 阶段<ol>
<li>第一步，写 binlog<ul>
<li>此阶段调用两个方法 <code>write()</code> 和 <code>fsync()</code>，前者负责将 binlog 从 binlog cache 写入文件系统缓存，后者负责将文件系统缓存中的 binlog 写入 disk，后者的调用机制是由 sync_binlog 参数控制的。</li>
<li>注意 binlog 也是有 cache 的，在事务执行过程中生成的 binlog 会被存储在 binlog cache 中，此 cache 大小由 binlog_cache_size，这个 size 是 session 级别的，即每个会话都有一个 binlog cache。</li>
</ul>
</li>
<li>第二步，innodb 进行 commit<ul>
<li>在 Innodb 层写入 commit flag，调用 write 和 fsync 将 commit 信息的 redo 写入磁盘，然后释放 prepare_commit_mutex。</li>
<li>引擎层将 redo log buffer 中的 redo 写入文件系统缓存（write），然后将文件系统缓存中的 redo log 写入 disk（fsync），写入机制取决于 innodb_flush_log_at_trx_commit 参数。</li>
</ul>
</li>
</ol>
</li>
</ol>
</li>
<li>redo log 和 binlog 是两种不同的日志，就类似于分布式中的多节点提交请求，需要保证事务的一致性。redo log 和 binlog 有一个公共字段 XID，代表事务 ID。当参数 innodb_support_xa 打开时，在执行事务的第一条 SQL 时候会去注册 XA，根据第一条 SQL 的 query id 拼凑 XID 数据，然后存储在事务对象中。</li>
<li>如果两个日志单纯的分开提交，则可能会引发一些问题，如果简单分开提交，那么对于一条更新语句执行，有两种情况：<ul>
<li>先写 binlog，后写 redo log：如果 binlog 写入了，在写 redo log 之前数据库宕机。那么在重启恢复的时候，通过 binlog 恢复了数据没问题。但是由于 redo log 没有写入，这个事务应该无效，也就是原库中就不应该有这条语句对应的更新。但是通过 binlog 恢复数据后，数据库中就多了这条更新</li>
<li>先写 redo log，后写 binlog：如果 redo log 写入了，在写 binlog 之前数据库宕机。那么在重启恢复的时候，通过 binlog 恢复从库，那么相对于主库来说，从库就少了这条更新</li>
</ul>
</li>
<li>采取了两段提交之后，怎么做 crash 恢复呢？<ul>
<li>如果在写入 binlog 之前宕机了，那么事务需要回滚；如果事务 commit 之前宕机了，那么此时 binlog cache 中的数据可能还没有刷盘，那么验证 binlog 的完整性：到 redo log 中找到最近事务的 XID，根据这个 XID 到 binlog 中去找（XID Event），如果找到了，说明在 binlog 中对应事务已经提交，那么提交 redo log 中事务即可；否则需要回滚事务。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><ul>
<li>主从复制、读写分离就是为了数据库能支持更大的并发。</li>
<li>原理<ol>
<li>当 Master 节点进行 insert、update、delete 操作时，会按顺序写入到 binlog 中。</li>
<li>salve 从库连接 master 主库，Master 有多少个 slave 就会创建多少个 binlog dump 线程。</li>
<li>当 Master 节点的 binlog 发生变化时，binlog dump 线程会通知所有的 salve 节点，并将相应的 binlog 内容推送给 slave 节点。</li>
<li>I/O 线程接收到 binlog 内容后，将内容写入到本地的 relay-log。</li>
<li>SQL 线程读取 I/O 线程写入的 relay-log，并且根据 relay-log 的内容对从数据库做对应的操作。</li>
</ol>
<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E7%9A%84%E5%8E%9F%E7%90%86.png" alt="MySQL_主从复制的原理"></li>
</ul>
</li>
<li>同步策略<ul>
<li>「同步策略」：Master 会等待所有的 Slave 都回应后才会提交，这个主从的同步的性能会严重的影响。</li>
<li>「半同步策略」：Master 至少会等待一个 Slave 回应后提交。<ul>
<li>从 MySQL5.5 开始，引入了半同步复制，此时的技术暂且称之为传统的半同步复制。技术发展到 MySQL5.7后，已经演变为增强半同步复制（也成为无损复制）。<ul>
<li>传统的半同步复制<ul>
<li>在传统的半同步复制中，主库写数据到 BINLOG，且执行 Commit 操作后，会一直等待从库的 ACK，即从库写入 Relay Log 后，并将数据落盘，返回给主库消息，通知主库可以返回前端应用操作成功，这样会出现一个问题，就是实际上主库已经将该事务 Commit 到了事务引擎层，应用已经可以可以看到数据发生了变化，只是在等待返回而已，如果此时主库宕机，有可能从库还没能写入 Relay Log，就会发生主从库不一致。</li>
</ul>
</li>
<li>增强半同步复制就<ul>
<li>增强半同步复制就是为了解决这个问题，做了微调，即主库写数据到 BINLOG 后，就开始等待从库的应答 ACK，直到至少一个从库写入 Relay Log 后，并将数据落盘，然后返回给主库消息，通知主库可以执行 Commit 操作，然后主库开始提交到事务引擎层，应用此时可以看到数据发生了变化。</li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5_%E5%8D%8A%E5%90%8C%E6%AD%A5%E7%AD%96%E7%95%A5.jpg" alt="MySQL_主从同步_半同步策略"></li>
</ul>
</li>
</ul>
</li>
<li>半同步复制模式下，假如在传送 BINLOG 日志到从库时，从库宕机或者网络延迟，导致 BINLOG 并没有及时地传送到从库上，此时主库上的事务会等待一段时间（时间长短由参数 rpl_semi_sync_master_timeout 设置的毫秒数决定），如果 BINLOG 在这段时间内都无法成功发送到从库上，则 MySQL 自动调整复制为异步模式，事务正常返回提交结果给客户端。</li>
</ul>
</li>
<li>「异步策略」：Master 不用等待 Slave 回应就可以提交。<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/MySQL-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MySQL_%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5_%E5%BC%82%E6%AD%A5%E7%AD%96%E7%95%A5.jpg" alt="MySQL_主从同步_异步策略"></li>
</ul>
</li>
<li>「延迟策略」：Slave 要落后于 Master 指定的时间。</li>
</ul>
</li>
<li>缺点<ul>
<li>从机是通过 binlog 日志从 master 同步数据的，如果在网络延迟的情况，从机就会出现数据延迟。那么就有可能出现 master 写入数据后，slave 读取数据不一定能马上读出来。</li>
</ul>
</li>
<li>主从不同步的可能情况<ul>
<li>网络延迟<ul>
<li>由于 MySQL 主从复制是基于 binlog 的一种异步复制，通过网络传送 binlog 文件，理所当然网络延迟是主从不同步的绝大多数的原因，特别是跨机房的数据同步出现这种几率非常的大，所以做读写分离，注意从业务层进行前期设计。</li>
</ul>
</li>
<li>主从两台机器的负载不一致<ul>
<li>由于 MySQL 主从复制是主数据库上面启动 1 个 io 线程，而从上面启动 1 个 sql 线程和 1 个 io 线程，当中任何一台机器的负载很高，忙不过来，导致其中的任何一个线程出现资源不足，都将出现主从不一致的情况。</li>
</ul>
</li>
<li>max_allowed_packet 设置不一致<ul>
<li>主数据库上面设置的 max_allowed_packet 比从数据库大，当一个大的 sql 语句，能在主数据库上面执行完毕，从数据库上面设置过小，无法执行，导致的主从不一致。</li>
</ul>
</li>
<li>自增键不一致<ul>
<li>key 自增键开始的键值跟自增步长设置不一致引起的主从不一致。</li>
</ul>
</li>
<li>同步参数设置问题<ul>
<li>MySQL 异常宕机情况下，如果未设置 sync_binlog=1 或者 innodb_flush_log_at_trx_commit=1 很有可能出现 binlog 或者 relaylog 文件出现损坏，导致主从不一致。</li>
</ul>
</li>
<li>主库 binlog 格式为 Statement，同步到从库执行后可能造成主从不一致。</li>
<li>主库执行更改前有执行 <code>set sql_log_bin=0</code>，会使主库不记录 binlog，从库也无法变更这部分数据。</li>
<li>从节点未设置只读，误操作写入数据。</li>
<li>主库或从库意外宕机，宕机可能会造成 binlog 或者 relaylog 文件出现损坏，导致主从不一致</li>
<li>主从实例版本不一致，特别是高版本是主，低版本是从的情况下，主数据库上面支持的功能从数据库上面可能不支持</li>
</ul>
</li>
<li>关于事务<ul>
<li>在同一事务内，读写操作应该均走主库，用于保证数据一致性。</li>
</ul>
</li>
<li>主从一致性检查<ul>
<li>利用 <strong>percona-toolkit</strong> 工具</li>
<li>主库增加或者修改数据即往 MQ 里面放入消息，异步验证一致性</li>
</ul>
</li>
</ul>
<h2 id="语句执行顺序"><a href="#语句执行顺序" class="headerlink" title="语句执行顺序"></a>语句执行顺序</h2><ul>
<li>MySQL 的语句一共分为 11 步，最先执行的总是 FROM 操作，最后执行的是 LIMIT 操作。其中每一个操作都会产生一张虚拟的表，这个虚拟的表作为一个处理的输入，只是这些虚拟的表对用户来说是透明的，但是只有最后一个虚拟的表才会被作为结果返回。如果没有在语句中指定某一个子句，那么将会跳过相应的步骤。</li>
<li>步骤<ol>
<li>FROM: 对 FROM 的左边的表和右边的表计算笛卡尔积。产生虚表 VT1。</li>
<li>ON: 对虚表 VT1 进行 ON 筛选，只有那些符合 <code>&lt;join-condition&gt;</code> 的行才会被记录在虚表 VT2 中。</li>
<li>JOIN： 如果指定了 OUTER JOIN（比如 left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表 VT2 中，产生虚拟表 VT3, rug from 子句中包含两个以上的表的话，那么就会对上一个 join 连接产生的结果 VT3 和下一个表重复执行步骤 1~3 这三个步骤，一直到处理完所有的表为止。</li>
<li>WHERE： 对虚拟表 VT3 进行WHERE条件过滤。只有符合 <code>&lt;where-condition&gt;</code> 的记录才会被插入到虚拟表 VT4 中。</li>
<li>GROUP BY: 根据 group by 子句中的列，对 VT4 中的记录进行分组操作，产生 VT5。</li>
<li>CUBE | ROLLUP: 对表 VT5 进行 cube 或者 rollup 操作，产生表 VT6。使用聚集函数进行计算。</li>
<li>HAVING： 对虚拟表 VT6 应用 having 过滤，只有符合 <code>&lt;having-condition&gt;</code> 的记录才会被插入到虚拟表 VT7 中。</li>
<li>SELECT： 执行 select 操作，选择指定的列，插入到虚拟表 VT8 中。</li>
<li>DISTINCT： 对 VT8 中的记录进行去重。产生虚拟表 VT9。</li>
<li>ORDER BY: 将虚拟表 VT9 中的记录按照<code>&lt;order_by_list&gt;</code>进行排序操作，产生虚拟表 VT10。</li>
<li>LIMIT：取出指定行的记录，产生虚拟表 VT11, 并将结果返回。</li>
</ol>
</li>
</ul>
<h3 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h3><ul>
<li>事务<ul>
<li>MySQL 默认是开启事务的（自动提交）<ul>
<li><code>select @@autocommit;(autocommit=1)</code></li>
</ul>
</li>
<li>事务开启<ol>
<li>修改默认提交 <code>set autocommit=0;</code></li>
<li><code>begin;</code> 或 <code>start transaction;</code></li>
<li>事务手动提交：<code>commit;</code></li>
<li>事务手动回滚：<code>rollback;</code></li>
</ol>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">Redis-0-知识点汇总.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-01 12:10:14" itemprop="dateCreated datePublished" datetime="2019-09-01T12:10:14+08:00">2019-09-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Redis/" itemprop="url" rel="index"><span itemprop="name">Redis</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="基本"><a href="#基本" class="headerlink" title="基本"></a>基本</h3><ul>
<li>字符串<ul>
<li>一个 key 对应一个 value</li>
<li>原理<ul>
<li>如果一个字符串对象保存的是整数值，并且这个整数值可以用 long 类型标识，那么字符串对象会讲整数值保存在 ptr 属性中，并将 encoding 设置为 int。</li>
<li>如果字符串对象保存的是一个字符串值，Redis 的字符串底层数据结构是 sds（simple dynamic string），即简单动态字符串。<ul>
<li>具体由 embstr 编码方式和 raw 编码方式实现<ul>
<li>embstr<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_string_embstr%E7%BC%96%E7%A0%81.png" alt="Redis_string_embstr编码"></li>
</ul>
</li>
<li>raw<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_string_raw%E7%BC%96%E7%A0%81.png" alt="Redis_string_raw编码"></li>
</ul>
</li>
<li>对比<ul>
<li>embstr 编码将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次。</li>
<li>释放 embstr 编码的字符串对象只需要调用一次内存释放函数，而释放 raw 编码的字符串对象需要调用两次内存释放函数。</li>
<li>因为 embstr 编码的字符串对象的所有数据都保存在一块连续的内存里面，所以这种编码的字符串对象比起 raw ，编码的字符串对象能够更好地利用缓存带来的优势。</li>
</ul>
</li>
<li>sdshdr<ul>
<li>结构<ul>
<li>```<br>struct sdshdr{<pre><code>int len;//已使用保存的字符串长度
int free;//未使用字符串长度
char buf[];保存字符串的数组
</code></pre>
}<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">          - 版本区别</span><br><span class="line">            - Redis3.2 之前，统一使用一个版本的 sdshdr。</span><br><span class="line">            - Redis3.2 开始，对数据结构做出了修改，针对不同的长度范围定义了不同的结构。</span><br><span class="line">              - sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64，用于存储不同的长度的字符串，分别代表 $2^5=32B$，$2^8=256B$，$2^16=64KB$，$2^32=4GB$，$2^64$ 约等于无穷大，但实际官方字符串 value 最大值为 512M。</span><br><span class="line">      - 版本区别</span><br><span class="line">        - Redis 的 embstr 编码方式和 raw 编码方式在 3.0 版本之前是以 39 字节为分界的</span><br><span class="line">        - 在 3.2 版本之后，则变成了 44 字节为分界</span><br><span class="line">          - 在 44 字节以内，使用 embstr 实现</span><br><span class="line">          - 超过了 44 字节，使用 raw 存储</span><br><span class="line">  - 相关问题</span><br><span class="line">    - **Redis 字符串与 C 语言中的字符串区别？**</span><br><span class="line">      - 复杂度问题</span><br><span class="line">        - SDS 由于存储了 len 属性，所以获取字符长度的时间复杂度为 $O(1)$，而 C 字符串并不记录本身长度，故获取字符串长度需要遍历整个字符串，直到遇到空字符，时间复杂度为 $O(N)$。</span><br><span class="line">      - 内存分配释放策略</span><br><span class="line">        - SDS 是预分配+惰性释放</span><br><span class="line">        - SDS 的内存分配策略：</span><br><span class="line">          - 如果对 SDS 字符串修改后，len 的值小于 1MB，那么程序会分配和 len 同样大小的空间，此时 len 和 free 的值是相同的，例如，如果 SDS 的字符串长度修改为 15 字节，那么会分配 15 字节空间给 free，SDS 的 buf 属性长度为 15（len）+15（free）+1（空字符）= 31 字节。</span><br><span class="line">          - 如果SDS字符串修改后，len 大于等于 1MB，那么程序会分配 1MB 的空间给 free，例如，SDS 字符串长度修改为 50MB 那么程序会分配 1MB 的未使用空间给 free，SDS 的 buf 属性长度为 50MB（len）+1MB（free）+1byte（空字符）。</span><br><span class="line">        - SDS 的内存释放策略：</span><br><span class="line">          - 当需要缩短 SDS 字符串时，程序并不立刻将内存释放，而是使用 free 属性将这些空间记录下来，以备将来使用。</span><br><span class="line">      - 缓冲区溢出问题</span><br><span class="line">        - SDS 的字符串的内存预分配策略能有效避免缓冲区溢出问题</span><br><span class="line">        - C 字符串每次操作增加长度时，都要分配足够长度的内存空间，否则就会产生缓冲区溢出（buffer overflow）。</span><br><span class="line">      - 二进制安全问题</span><br><span class="line">        - SDS 字符串 API 都是以处理二进制的方式处理 buf 数组里的数据，程序不会对其中的数据进行过滤、操作等，所以 SDS 是二进制数据安全的。</span><br><span class="line">        - C 字符串的字符则必须符合某种编码（ASCII），并且字符串的中间不能包含空字符，否则字符串就会被截断，所以 C 字符串智能保存文本数据，而不能保存图片、音视频等数据类型。</span><br><span class="line">    - **为什么 Redis 的 embstr 与 raw 编码方式不再以 39 字节为界？**</span><br><span class="line">      - embstr 是一块连续的内存区域，由 redisObject 和 sdshdr 组成。其中 redisObject 占 16 个字节，当 buf 内的字符串长度是 39 时，sdshdr 的大小为 8+39+1=48，那一个字节是&#x27;\0&#x27;。加起来刚好 64。</span><br><span class="line">      - 从 2.4 版本开始，redis 开始使用 jemalloc 内存分配器。这个比 glibc 的 malloc 要好不少，还省内存。在这里可以简单理解，jemalloc 会分配 8，16，32，64 等字节的内存。embstr 最小为 16+8+8+1=33，所以最小分配 64 字节。当字符数小于 39 时，都会分配 64 字节。这个默认 39 就是这样来的。</span><br><span class="line">      - 本身就是针对短字符串的 embstr 自然会使用最小的 sdshdr8，而 sdshdr8 与之前的 sdshdr 相比正好减少了 5 个字节（sdsdr8 = uint8_t * 2 + char = 1*2+1 = 3, sdshdr = unsigned int * 2 = 4 * 2 = 8）,所以其能容纳的字符串长度增加了 5 个字节变成了 44。</span><br><span class="line">- list（列表）</span><br><span class="line">  - Redis 链表是一个双向无环链表结构，可以通过 push 和 pop 操作从列表的头部或者尾部添加或者删除元素，这样 list 即可以作为栈，也可以作为队列。很多发布订阅、慢查询、监视器功能都是使用到了链表来实现。</span><br><span class="line">  - 原理</span><br><span class="line">    - 底层有 linkedList、zipList 和 quickList 这三种存储方式。</span><br><span class="line">    - 数据结构</span><br><span class="line">      - linkedList、zipList</span><br><span class="line">        - 当列表对象中元素的长度较小或者数量较少时，通常采用 zipList 来存储；当列表中元素的长度较大或者数量比较多的时候，则会转而使用双向链表 linkedList 来存储。</span><br><span class="line">        - 双向链表 linkedList 便于在表的两端进行 push 和 pop 操作，在插入节点上复杂度很低，但是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还有额外保存两个指针；其次，双向链表的各个节点都是单独的内存块，地址不连续，容易形成内存碎片。</span><br><span class="line">        - zipList 存储在一块连续的内存上，所以存储效率很高。但是它不利于修改操作，插入和删除操作需要频繁地申请和释放内存。特别是当 zipList 长度很长时，一次 realloc 可能会导致大量的数据拷贝。</span><br><span class="line">      - quickList</span><br><span class="line">        - 在 Redis3.2 版本之后，list 的底层实现方式又多了一种，quickList。qucikList 是由 zipList 和双向链表 linkedList 组成的混合体。它将 linkedList 按段切分，每一段使用 zipList 来紧凑存储，多个 zipList 之间使用双向指针串接起来。</span><br><span class="line">        - ![Redis_quickList](Redis-0-知识点汇总/Redis_quickList.png)</span><br><span class="line">- hash（散列）</span><br><span class="line">  - hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。</span><br><span class="line">  - 原理</span><br><span class="line">    - 哈希对象的编码有两种，分别是：ziplist、dict。</span><br><span class="line">    - 数据结构</span><br><span class="line">      - ziplist</span><br><span class="line">        - 使用压缩列表实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的节点推入到压缩列表的表尾，然后再将保存了值的节点推入到压缩列表表尾。</span><br><span class="line">        - ![Redis_ziplist_2](Redis-0-知识点汇总/Redis_ziplist_2.jpg)</span><br><span class="line">      - dict</span><br><span class="line">        - 使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值来保存，跟 java 中的 HashMap 类似。</span><br><span class="line">        - ![Redis_hashtable](Redis-0-知识点汇总/Redis_hashtable.jpg)</span><br><span class="line">    - 切换条件</span><br><span class="line">      - 当哈希对象保存的键值对数量小于 512，并且所有键值对的长度都小于 64 字节时，使用压缩列表存储；否则使用 dict 存储。</span><br><span class="line">  - 扩容流程（渐进式 rehash）</span><br><span class="line">    1. 计算新表 size、掩码，为新表 ht[1] 分配空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表。</span><br><span class="line">    2. 将 rehash 索引计数器变量 rehashidx 的值设置为 0，表示 rehash 正式开始。</span><br><span class="line">    3. rehash 进行期间，每次对字典执行添加、删除、査找、更新操作时，程序除了执行指定的操作以外，还会触发额外的 rehash 操作，在源码中的 _dictRehashStep 方法。</span><br><span class="line">       - 该方法会从 ht[0] 表的 rehashidx 索引位置上开始向后查找，找到第一个不为空的索引位置，将该索引位置的所有节点 rehash 到 ht[1]，当本次 rehash 工作完成之后，将 ht[0] 索引位置为 rehashidx 的节点清空，同时将 rehashidx 属性的值加一。</span><br><span class="line">    4. 将 rehash 分摊到每个操作上确实是非常妙的方式，但是万一此时服务器比较空闲，一直没有什么操作，难道 redis 要一直持有两个哈希表吗？</span><br><span class="line">       - 答案当然不是的。我们知道，redis 除了文件事件外，还有时间事件，redis 会定期触发时间事件，这些时间事件用于执行一些后台操作，其中就包含 rehash 操作：当 redis 发现有字典正在进行 rehash 操作时，会花费 1 毫秒的时间，一起帮忙进行 rehash。</span><br><span class="line">    5. 随着操作的不断执行，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 至 ht[1]，此时 rehash 流程完成，会执行最后的清理工作：释放 ht[0] 的空间、将 ht[0] 指向 ht[1]、重置 ht[1]、重置 rehashidx 的值为 -1。</span><br><span class="line">- sets（集合）</span><br><span class="line">  - Redis 提供的 set 数据结构，可以存储一些集合性的数据。set 中的元素是没有顺序的。</span><br><span class="line">  - 原理</span><br><span class="line">    - 集合对象的编码有两种，分别是：intset、dict。</span><br><span class="line">    - 切换条件</span><br><span class="line">      - set 的底层存储 intset 和 dict 是存在编码转换的，使用 intset 存储必须满足下面两个条件，否则使用 dict，条件如下：</span><br><span class="line">        - 结合对象保存的所有元素都是整数值</span><br><span class="line">        - 集合对象保存的元素数量不超过 512 个</span><br><span class="line">- sorted set（有序集合）</span><br><span class="line">  - sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列</span><br><span class="line">  - 原理</span><br><span class="line">    - 底层数据结有序集合对象的编码有两种，分别是：ziplist、skiplist。</span><br><span class="line">    - 数据结构</span><br><span class="line">      - ziplist</span><br><span class="line">        - 当保存的元素长度都小于 64 字节，同时数量小于 128 时，使用该编码方式，否则会使用 skiplist。</span><br><span class="line">        - ![Redis_ziplist](Redis-0-知识点汇总/Redis_ziplist.jpg)</span><br><span class="line">      - skiplist</span><br><span class="line">        - zset 实现，一个 zset 同时包含一个字典（dict）和一个跳跃表（zskiplist）</span><br><span class="line">        - ![Redis_skiplist](Redis-0-知识点汇总/Redis_skiplist.jpg)</span><br><span class="line">    - 切换条件</span><br><span class="line">      - 当有序集合的长度小于 128，并且所有元素的长度都小于 64 字节时，使用压缩列表存储；否则使用 skiplist 存储。</span><br><span class="line">### 高级</span><br><span class="line">- HyperLogLog</span><br><span class="line">  - 通常用于基数统计。使用少量固定大小的内存，来统计集合中唯一元素的数量。统计结果不是精确值，而是一个带有 0.81% 标准差（standard error）的近似值。</span><br><span class="line">  - HyperLogLog 适用于一些对于统计结果精确度要求不是特别高的场景，例如网站的 UV 统计。</span><br><span class="line">  - 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。</span><br><span class="line">    - 基数</span><br><span class="line">      - 比如数据集 `&#123;1, 3, 5, 7, 5, 7, 8&#125;`，那么这个数据集的基数集为 `&#123;1, 3, 5 ,7, 8&#125;`, 基数（不重复元素）为 5。基数估计就是在误差可接受的范围内，快速计算基数。</span><br><span class="line">- Geo</span><br><span class="line">  - 可以将用户给定的地理位置信息储存起来，并对这些信息进行操作：获取 2 个位置的距离、根据给定地理位置坐标获取指定范围内的地理位置集合。</span><br><span class="line">- Bitmap</span><br><span class="line">  - 位图。</span><br><span class="line">- Stream</span><br><span class="line">  - 主要用于消息队列，类似于 kafka，可以认为是 pub/sub 的改进版。提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。</span><br><span class="line">### 原理</span><br><span class="line">- RedisObject</span><br><span class="line">  - 为了便于操作，Redis 定义了 RedisObject 结构体来表示 string、hash、list、set、zset 五种数据类型。</span><br><span class="line">  - ![Redis_RedisObject](Redis-0-知识点汇总/Redis_RedisObject.jpg)</span><br><span class="line">  - 结构</span><br><span class="line">    - 源码</span><br><span class="line">      - ```</span><br><span class="line">        /*</span><br><span class="line">         * Redis 对象</span><br><span class="line">         */</span><br><span class="line">        typedef struct redisObject &#123;</span><br><span class="line">            // 类型</span><br><span class="line">            unsigned type:4;</span><br><span class="line">            // 对齐位</span><br><span class="line">            unsigned notused:2;</span><br><span class="line">            // 编码方式</span><br><span class="line">            unsigned encoding:4;</span><br><span class="line">            // LRU 时间（相对于 server.lruclock）</span><br><span class="line">            unsigned lru:22;</span><br><span class="line">            // 引用计数</span><br><span class="line">            int refcount;</span><br><span class="line">            // 指向对象的值</span><br><span class="line">            void *ptr;</span><br><span class="line">        &#125; robj;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>type 记录了对象所保存的值的类型, 它的值可能是以下常量的其中一个<ul>
<li>REDIS_STRING  // 字符串</li>
<li>REDIS_LIST    // 列表</li>
<li>REDIS_SET     // 集合</li>
<li>REDIS_ZSET    // 有序集</li>
<li>REDIS_HASH    // 哈希表</li>
</ul>
</li>
<li>encoding 记录了对象所保存的值的编码, 它的值可能是以下常量的其中一个<ul>
<li>REDIS_ENCODING_INT            // 编码为整数</li>
<li>REDIS_ENCODING_EMBSTR         // embstr 编码</li>
<li>REDIS_ENCODING_RAW            // 编码为字符串</li>
<li>REDIS_ENCODING_HT             // 编码为哈希表</li>
<li>REDIS_ENCODING_LINKEDLIST     // 编码为双端链表</li>
<li>REDIS_ENCODING_ZIPLIST        // 编码为压缩列表</li>
<li>REDIS_ENCODING_INTSET         // 编码为整数集合</li>
<li>REDIS_ENCODING_SKIPLIST       // 编码为跳跃表</li>
</ul>
</li>
<li>ptr 是一个指针, 指向实际保存值的数据结构, 这个数据结构由 type 属性和 encoding 属性决定</li>
<li>refcount<ul>
<li>refcount 表示引用计数，由于 C 语言并不具备内存回收功能，所以 Redis 在自己的对象系统中添加了这个属性，当一个对象的引用计数为 0 时，则表示该对象已经不被任何对象引用，则可以进行垃圾回收了。</li>
</ul>
</li>
<li>lru 表示对象最后一次被命令程序访问的时间。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>底层数据结构<ul>
<li>字符串<ul>
<li>Redis 没有直接使用 C 语言传统的字符串表示，而是自己实现的叫做简单动态字符串 SDS 的抽象类型。C 语言的字符串不记录自身的长度信息，而 SDS 则保存了长度信息，这样将获取字符串长度的时间由 <code>O(N)</code> 降低到了 <code>O(1)</code>，同时可以避免缓冲区溢出和减少修改字符串长度时所需的内存重分配次数。</li>
</ul>
</li>
<li>linkedlist<ul>
<li>Redis链表特性：<ul>
<li>双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为 $O(1)$。</li>
<li>无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL，对链表的访问都是以 NULL 结束。</li>
<li>带链表长度计数器：通过 len 属性获取链表长度的时间复杂度为 $O(1)$。</li>
<li>多态：链表节点使用 <code>void*</code> 指针来保存节点值，可以保存各种不同类型的值。</li>
</ul>
</li>
</ul>
</li>
<li>dict<ul>
<li>用于保存键值对的抽象数据结构。</li>
<li>Redis 使用 hash 表作为底层实现，每个字典带有两个 hash 表，供平时使用和 rehash 时使用，hash 表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对 hash 表进行扩容或者缩容的时候，为了服务的可用性，rehash 的过程不是一次性完成的，而是渐进式的。</li>
</ul>
</li>
<li>ziplist<ul>
<li>压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。 </li>
</ul>
</li>
<li>skiplist<ul>
<li>跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。</li>
<li>结构<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_skiplist_2.png" alt="Redis_skiplist_2"></li>
</ul>
</li>
<li>特性<ul>
<li>由很多层结构组成；</li>
<li>每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；</li>
<li>最底层的链表包含了所有的元素；</li>
<li>如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；</li>
<li>链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；</li>
</ul>
</li>
<li>操作方式<ul>
<li>搜索：从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。</li>
<li>插入：首先确定插入的层数，有一种方法是假设抛一枚硬币，如果是正面就累加，直到遇见反面为止，最后记录正面的次数作为插入的层数。当确定插入的层数 k 后，则需要将新元素插入到从底层到 k 层。</li>
<li>删除：在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。</li>
</ul>
</li>
</ul>
</li>
<li>intset<ul>
<li>用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><ul>
<li>AOF<ul>
<li>Append-only file，将“操作 + 数据”以格式化指令的方式追加到操作日志文件的尾部，在 append 操作返回后（已经写入到文件或者即将写入），才进行实际的数据变更，“日志文件”保存了历史所有的操作过程；当 server 需要数据恢复时，可以直接 replay 此日志文件，即可还原所有的操作过程。</li>
<li>优点<ul>
<li>可以保持更高的数据完整性，如果设置追加 file 的时间是 1s，如果 Redis 发生故障，最多会丢失 1s 的数据；且如果日志写入不完整支持 redis-check-aof 来进行日志修复；AOF 文件没被 rewrite 之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的 flushall）。</li>
</ul>
</li>
<li>缺点<ul>
<li>AOF 文件比 RDB 文件大，且恢复速度慢。</li>
</ul>
</li>
<li>AOF 重写<ul>
<li>引入原因<ul>
<li>AOF 持久化是通过保存被执行的写命令来记录数据库状态的，随着写入命令的不断增加，AOF 文件中的内容会越来越多，文件的体积也会越来越大。</li>
<li>如果不加以控制，体积过大的 AOF 文件可能会对 Redis 服务器、甚至整个宿主机造成影响，并且 AOF 文件的体积越大，使用 AOF 文件来进行数据还原所需的时间就越多。</li>
<li>举个例子，如果你对一个计数器调用了 100 次 INCR，那么仅仅是为了保存这个计数器的当前值，AOF 文件就需要使用 100 条记录。</li>
<li>然而在实际上，只使用一条 SET 命令已经足以保存计数器的当前值了，其余 99 条记录实际上都是多余的。</li>
<li>为了处理这种情况，Redis 引入了 AOF 重写：可以在不打断服务端处理请求的情况下，对 AOF 文件进行重建（rebuild）。</li>
</ul>
</li>
<li>存在的问题<ul>
<li>AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：子进程在进行 AOF 重写期间，服务器主进程还需要继续处理命令请求，新的命令可能会对现有的数据库状态进行修改，从而使得当前的数据库状态和重写后的 AOF 文件保存的数据库状态不一致。<ul>
<li><strong>如何解决 AOF 后台重写存在的数据不一致问题?</strong><ul>
<li>为了解决上述问题，Redis 引入了 AOF 重写缓冲区（aof_rewrite_buf_blocks），这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令追加到 AOF 缓冲区和 AOF 重写缓冲区。当 aof 重写完成时，主进程在把 aof 重写缓冲区的数据写到 aof 缓冲区，最后 fsync 到 aof 文件中。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>rewrite 流程<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_aof_rewrite%E6%B5%81%E7%A8%8B.png" alt="Redis_aof_rewrite流程"></li>
</ul>
</li>
<li>触发时机<ul>
<li>触发 rewrite 的时机可以通过配置文件来声明，同时 redis 中可以通过 bgrewriteaof 指令人工干预。</li>
</ul>
</li>
</ul>
</li>
<li>触发时机<ul>
<li>redis 提供了 3 中 aof 记录同步选项：<ul>
<li>always：每一条 aof 记录都立即同步到文件，这是最安全的方式，也以为更多的磁盘操作和阻塞延迟，是 I/O 开支较大。</li>
<li>everysec：每秒同步一次，性能和安全都比较中庸的方式，也是 redis 推荐的方式。如果遇到物理服务器故障，有可能导致最近一秒内 aof 记录丢失（可能为部分丢失）。</li>
<li>no：redis 并不直接调用文件同步，而是交给操作系统来处理，操作系统可以根据 buffer 填充情况/通道空闲时间等择机触发同步；这是一种普通的文件操作方式。性能较好，在物理服务器故障时，数据丢失量会因 OS 配置有关。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>RDB<ul>
<li>RDB 是在某个时间点将数据写入一个临时文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复。</li>
<li>优点<ul>
<li>使用单独子进程来进行持久化，主进程不会进行任何 I/O 操作，保证了 Redis 的高性能</li>
</ul>
</li>
<li>缺点<ul>
<li>RDB 是间隔一段时间进行持久化，如果持久化之间 Redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候</li>
<li>每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步脏数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘 I/O 操作，可能会严重影响性能。</li>
</ul>
</li>
<li>RDB 持久化的两种方法<ul>
<li>save<ul>
<li>描述<ul>
<li>同步、阻塞</li>
</ul>
</li>
<li>缺点<ul>
<li>致命的问题，持久化的时候 redis 服务阻塞（准确的说会阻塞当前执行 save 命令的线程，但是 redis 是单线程的，所以整个服务会阻塞），不能继对外提供请求</li>
</ul>
</li>
</ul>
</li>
<li>bgsave<ul>
<li>描述<ul>
<li>异步、非阻塞</li>
</ul>
</li>
<li>原理<ul>
<li><code>fork() + copyonwrite</code><ul>
<li><code>fork()</code><ul>
<li><code>fork()</code> 是什么<ul>
<li><code>fork()</code> 是 unix 和 linux 这种操作系统的一个 api，而不是 Redis 的 api。</li>
</ul>
</li>
<li><code>fork()</code> 有什么用<ul>
<li><code>fork()</code> 用于创建一个子进程，注意是子进程，不是子线程。<code>fork()</code> 出来的进程共享其父类的内存数据。仅仅是共享 <code>fork()</code> 出子进程的那一刻的内存数据，后期主进程修改数据对子进程不可见，同理，子进程修改的数据对主进程也不可见。</li>
<li>比如：A 进程 <code>fork()</code> 了一个子进程 B，那么 A 进程就称之为主进程，这时候主进程子进程所指向的内存空间是同一个，所以他们的数据一致。但是 A 修改了内存上的一条数据，这时候 B 是看不到的，A 新增一条数据，删除一条数据，B 都是看不到的。而且子进程 B 出问题了，对我主进程 A 完全没影响，我依然可以对外提供服务，但是主进程挂了，子进程也必须跟随一起挂。这一点有点像守护线程的概念。Redis 正是巧妙的运用了 <code>fork()</code> 这个牛逼的 api 来完成 RDB 的持久化操作。</li>
</ul>
</li>
<li>Redis 中的 <code>fork()</code><ul>
<li>Redis 巧妙的运用了 <code>fork()</code>。当 bgsave 执行时，Redis 主进程会判断当前是否有 <code>fork()</code> 出来的子进程，若有则忽略，若没有则会 <code>fork()</code> 出一个子进程来执行 rdb 文件持久化的工作，子进程与 Redis 主进程共享同一份内存空间，所以子进程可以搞他的 rdb 文件持久化工作，主进程又能继续他的对外提供服务，二者互不影响。我们说了他们之后的修改内存数据对彼此不可见，但是明明指向的都是同一块内存空间，这是咋搞得？肯定不可能是 <code>fork()</code> 出来子进程后顺带复制了一份数据出来，如果是这样的话比如我有 4g 内存，那么其实最大有限空间是 2g，我要给 rdb 留出一半空间来，扯淡一样！那他咋做的？采取了 copyonwrite 技术。</li>
</ul>
</li>
</ul>
</li>
<li>copyonwrite<ul>
<li>原理<ul>
<li>主进程 <code>fork()</code> 子进程之后，内核把主进程中所有的内存页的权限都设为 read-only，然后子进程的地址空间指向主进程。这也就是共享了主进程的内存，当其中某个进程写内存时（这里肯定是主进程写，因为子进程只负责 rdb 文件持久化工作，不参与客户端的请求），CPU 硬件检测到内存页是 read-only 的，于是触发页异常中断（page-fault），陷入内核的一个中断例程。中断例程中，内核就会把触发的异常的页复制一份（这里仅仅复制异常页，也就是所修改的那个数据页，而不是内存中的全部数据），于是主子进程各自持有独立的一份。</li>
</ul>
</li>
<li>回到原问题<ul>
<li>其实就是更改数据的之前进行 copy 一份更改数据的数据页出来，比如主进程收到了 <code>set k 1</code> 请求（之前 k 的值是 2），然后这同时又有子进程在 rdb 持久化，那么主进程就会把 k 这个 key 的数据页拷贝一份，并且主进程中 k 这个指针指向新拷贝出来的数据页地址上，然后进行更改值为 1 的操作，这个主进程 k 元素地址引用的新拷贝出来的地址，而子进程引用的内存数据k还是修改之前的。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>优点<ul>
<li>他可以一边进行持久化，一边对外提供读写服务，互不影响，新写的数据对我持久化不会造成数据影响，你持久化的过程中报错或者耗时太久都对我当前对外提供请求的服务不会产生任何影响。持久化完会将新的 rdb 文件覆盖之前的。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>触发时机<ul>
<li>执行数据写入到临时文件的时间点是可以通过配置来自己确定的，通过配置 redis 在 n 秒内如果超过 m 个 key 被修改这执行一次 RDB 操作。这个操作就类似于在这个时间点来保存一次 Redis 的所有数据，一次快照数据。所有这个持久化方法也通常叫做 snapshots。</li>
<li>snapshot 触发的时机，是有“间隔时间”和“变更次数”共同决定，同时符合 2 个条件才会触发 snapshot，否则“变更次数”会被继续累加到下一个“间隔时间”上。snapshot 过程中并不阻塞客户端请求。snapshot 首先将数据写入临时文件，当成功结束后，将临时文件重名为 dump.rdb。</li>
</ul>
</li>
</ul>
</li>
<li>混合持久化<ul>
<li>混合持久化只发生于 AOF 重写过程。使用了混合持久化，重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。</li>
<li>优点：结合 RDB 和 AOF 的优点, 更快的重写和恢复。</li>
<li>缺点：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。</li>
</ul>
</li>
</ul>
<h2 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h2><ul>
<li>删除过期键的策略（Redis 使用惰性删除和定期删除。）<ul>
<li>清除策略<ul>
<li>定时删除<ul>
<li>在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。对内存最友好，对 CPU 时间最不友好。</li>
</ul>
</li>
<li>惰性删除<ul>
<li>放任键过期不管，但是每次获取键时，都检査键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。对 CPU 时间最优化，对内存最不友好。</li>
</ul>
</li>
<li>定期删除<ul>
<li>每隔一段时间，默认 100ms，程序就对数据库进行一次检査，删除里面的过期键。至于要删除多少过期键，以及要检査多少个数据库，则由算法决定。前两种策略的折中，对 CPU 时间和内存的友好程度较平衡。</li>
</ul>
</li>
</ul>
</li>
<li>Redis 具体实现<ul>
<li>比如 Redis-3.0.0 中的 hz 默认值是 10，代表每秒钟调用 10 次后台任务。<ul>
<li>典型的方式为，Redis 每秒做 10 次如下的步骤：<ol>
<li>随机测试 100 个设置了过期时间的 key</li>
<li>删除所有发现的已过期的 key</li>
<li>若删除的 key 超过 25 个则重复步骤 1</li>
</ol>
</li>
<li>这是一个基于概率的简单算法，基本的假设是抽出的样本能够代表整个 key 空间，redis 持续清理过期的数据直至将要过期的 key 的百分比降到了 25% 以下。这也意味着在任何给定的时刻已经过期但仍占据着内存空间的 key 的量最多为每秒的写操作量除以 4。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>不管是定期采样删除还是惰性删除都不是一种完全精准的删除，就还是会存在 key 没有被删除掉的场景，所以就需要内存淘汰策略进行补充。<ul>
<li>内存淘汰（驱逐）策略<ul>
<li>noeviction：默认策略，不淘汰任何 key，直接返回错误</li>
<li>allkeys-lru：在所有的 key 中，使用 LRU 算法淘汰部分 key</li>
<li>allkeys-lfu：在所有的 key 中，使用 LFU 算法淘汰部分 key，该算法于 Redis 4.0 新增</li>
<li>allkeys-random：在所有的 key 中，随机淘汰部分 key</li>
<li>volatile-lru：在设置了过期时间的 key 中，使用 LRU 算法淘汰部分 key</li>
<li>volatile-lfu：在设置了过期时间的 key 中，使用 LFU 算法淘汰部分 key，该算法于 Redis 4.0 新增</li>
<li>volatile-random：在设置了过期时间的 key 中，随机淘汰部分 key</li>
<li>volatile-ttl：在设置了过期时间的 key 中，挑选 TTL（time to live，剩余时间）短的 key 淘汰</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="主从、哨兵、集群"><a href="#主从、哨兵、集群" class="headerlink" title="主从、哨兵、集群"></a>主从、哨兵、集群</h2><ul>
<li>主从复制<ul>
<li>复制的流程（Redis6.0）<ol>
<li>开启主从复制。通常有以下三种方式：<ul>
<li>在 slave 直接执行命令：<code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code></li>
<li>在 slave 配置文件中加入：<code>slaveof &lt;masterip&gt; &lt;masterport&gt;</code></li>
<li>使用启动命令：<code>--slaveof &lt;masterip&gt; &lt;masterport&gt;</code></li>
</ul>
</li>
<li>建立套接字（socket）连接<ul>
<li>slave 将根据指定的 IP 地址和端口，向 master 发起套接字（socket）连接，master 在接受（accept） slave 的套接字连接之后，为该套接字创建相应的客户端状态，此时连接建立完成。</li>
</ul>
</li>
<li>发送 PING 命令<ul>
<li>slave 向 master 发送一个 PING 命令，以检査套接字的读写状态是否正常、 master 能否正常处理命令请求。</li>
</ul>
</li>
<li>身份验证<ul>
<li>slave 向 master 发送 AUTH password 命令来进行身份验证。</li>
</ul>
</li>
<li>发送端口信息<ul>
<li>在身份验证通过后后，slave 将向 master 发送自己的监听端口号， master 收到后记录在 slave 所对应的客户端状态的 slave_listening_port 属性中。</li>
</ul>
</li>
<li>发送 IP 地址<ul>
<li>如果配置了 slave_announce_ip，则 slave 向 master 发送 slave_announce_ip 配置的 IP 地址， master 收到后记录在 slave 所对应的客户端状态的 slave_ip 属性。<ul>
<li>该配置是用于解决服务器返回内网 IP 时，其他服务器无法访问的情况。可以通过该配置直接指定公网 IP。</li>
</ul>
</li>
</ul>
</li>
<li>发送 CAPA<ul>
<li>CAPA 全称是 capabilities，这边表示的是同步复制的能力。slave 会在这一阶段发送 capa 告诉 master 自己具备的（同步）复制能力， master 收到后记录在 slave 所对应的客户端状态的 slave_capa 属性。</li>
</ul>
</li>
<li>数据同步<ul>
<li>slave 将向 master 发送 PSYNC 命令， master 收到该命令后判断是进行部分重同步还是完整重同步，然后根据策略进行数据的同步。</li>
</ul>
</li>
<li>命令传播<ul>
<li>当完成了同步之后，就会进入命令传播阶段，这时 master 只要一直将自己执行的写命令发送给 slave ，而 slave 只要一直接收并执行 master 发来的写命令，就可以保证 master 和 slave 一直保持一致了。 </li>
</ul>
</li>
</ol>
<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E5%A4%8D%E5%88%B6%E7%9A%84%E6%B5%81%E7%A8%8B.jpg" alt="Redis_复制的流程"></li>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%96%B9%E6%A1%88.png" alt="Redis_主从复制方案"></li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>Redis 主从复制延迟问题</strong><ul>
<li>将主从模式更换为哨兵模式则无需自己去做监控</li>
</ul>
</li>
<li><strong>脑裂导致数据丢失</strong><ul>
<li>Redis 已经提供了两个配置项来限制主库的请求处理，分别是 min-slaves-to-write 和 min-slaves-max-lag。<ul>
<li>min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；</li>
<li>min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。</li>
</ul>
</li>
<li>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求了。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>哨兵<ul>
<li>哨兵（Sentinel）是 Redis 的高可用性解决方案：由一个或多个 Sentinel 实例组成的 Sentinel 系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器。</li>
<li>Sentinel 可以在被监视的主服务器进入下线状态时，自动将下线主服务器的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。</li>
<li>主要功能<ul>
<li>客户端可以通过哨兵节点 + masterName 获取主节点信息，在这里哨兵起到的作用就是配置提供者。</li>
<li>哨兵故障检测<ul>
<li>检查主观下线状态<ul>
<li>在默认情况下，Sentinel 会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器、从服务器、其他 Sentinel 在内）发送 PING 命令，并通过实例返回的 PING 命令回复来判断实例是否在线。</li>
<li>如果一个实例在 down-after-miliseconds 毫秒内，连续向 Sentinel 返回无效回复，那么 Sentinel 会修改这个实例所对应的实例结构，在结构的 flags 属性中设置 SRI_S_DOWN 标识，以此来表示这个实例已经进入主观下线状态。</li>
</ul>
</li>
<li>检查客观下线状态<ul>
<li>当 Sentinel 将一个主服务器判断为主观下线之后，为了确定这个主服务器是否真的下线了，它会向同样监视这一服务器的其他 Sentinel 进行询问，看它们是否也认为主服务器已经进入了下线状态（可以是主观下线或者客观下线）。</li>
<li>当 Sentinel 从其他 Sentinel 那里接收到足够数量（quorum，可配置）的已下线判断之后，Sentinel 就会将服务器置为客观下线，在 flags 上打上 SRI_O_DOWN 标识，并对主服务器执行故障转移操作。</li>
</ul>
</li>
</ul>
</li>
<li>哨兵故障转移流程<ol>
<li>发起一次选举，选举出领头 Sentinel</li>
<li>领头 Sentinel 在已下线主服务器的所有从服务器里面，挑选出一个从服务器，并将其升级为新的主服务器。</li>
<li>领头 Sentinel 将剩余的所有从服务器改为复制新的主服务器。</li>
<li>领头 Sentinel 更新相关配置信息，当这个旧的主服务器重新上线时，将其设置为新的主服务器的从服务器。</li>
</ol>
</li>
</ul>
</li>
<li>架构<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E5%93%A8%E5%85%B5%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Redis_哨兵架构图"></li>
</ul>
</li>
</ul>
</li>
<li>集群模式（Cluster）<ul>
<li>哨兵模式最大的缺点就是所有的数据都放在一台服务器上，无法较好的进行水平扩展。</li>
<li>为了解决哨兵模式存在的问题，集群模式应运而生。在高可用上，集群基本是直接复用的哨兵模式的逻辑，并且针对水平扩展进行了优化。</li>
<li>集群模式具备的特点<ul>
<li>采取去中心化的集群模式，将数据按槽存储分布在多个 Redis 节点上。集群共有 16384 个槽，每个节点负责处理部分槽。</li>
<li>使用 CRC16 算法来计算 key 所属的槽：<code>crc16(key,keylen) &amp; 16383</code>。</li>
<li>所有的 Redis 节点彼此互联，通过 PING-PONG 机制来进行节点间的心跳检测。<ul>
<li>交换的数据信息，由消息体和消息头组成。消息体无外乎是一些节点标识啊，IP 啊，端口号啊，发送时间啊。这与本文关系不是太大。我们来看消息头，结构如下<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E8%8A%82%E7%82%B9%E9%97%B4%E6%B6%88%E6%81%AF%E7%BB%93%E6%9E%84.jpg" alt="Redis_节点间消息结构"><ul>
<li>注意看红框的内容，type 表示消息类型。另外，消息头里面有个 myslots 的 char 数组，长度为 16383/8，这其实是一个 bitmap，每一个位代表一个槽，如果该位为 1，表示这个槽是属于这个节点的。</li>
<li>在消息头中，最占空间的是 <code>myslots[CLUSTER_SLOTS/8]</code>。这块的大小是: <code>16384÷8÷1024=2kb</code>。</li>
<li>那在消息体中，会携带一定数量的其他节点信息用于交换。那这个其他节点的信息，到底是几个节点的信息呢？<ul>
<li>约为集群总节点数量的 1/10，至少携带 3 个节点的信息。 这里的重点是：节点数量越多，消息体内容越大。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>发送规律<ol>
<li>每秒会随机选取 5 个节点，找出最久没有通信的节点发送 ping 消息</li>
<li>每 100 毫秒（1 秒 10 次）都会扫描本地节点列表，如果发现节点最近一次接受 pong 消息的时间大于 cluster-node-timeout/2 则立刻发送 ping 消息</li>
</ol>
<ul>
<li>每秒单节点发出 ping 消息数量为数量=1+10*num，num=（node.pong_received&gt;cluster_node_timeout/2）的数量</li>
</ul>
</li>
</ul>
</li>
<li>分片内采用一主多从保证高可用，并提供复制和故障恢复功能。在实际使用中，通常会将主从分布在不同机房，避免机房出现故障导致整个分片出问题。</li>
<li>客户端与 Redis 节点直连，不需要中间代理层（proxy）。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。</li>
</ul>
</li>
<li>架构<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="Redis_集群架构图"></li>
</ul>
</li>
<li>集群选举<ol>
<li>当从节点发现自己正在复制的主节点进入已下线状态时，会发起一次选举：将 currentEpoch（配置纪元）加 1，然后向集群广播一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息，要求所有收到这条消息、并且具有投票权的主节点向这个从节点投票。</li>
<li>其他节点收到消息后，会判断是否要给发送消息的节点投票，判断流程如下：<ol>
<li>当前节点是 slave，或者当前节点是 master，但是不负责处理槽，则当前节点没有投票权，直接返回。</li>
<li>请求节点的 currentEpoch 小于当前节点的 currentEpoch，校验失败返回。因为发送者的状态与当前集群状态不一致，可能是长时间下线的节点刚刚上线，这种情况下，直接返回即可。</li>
<li>当前节点在该 currentEpoch 已经投过票，校验失败返回。</li>
<li>请求节点是 master，校验失败返回。</li>
<li>请求节点的 master 为空，校验失败返回。</li>
<li>请求节点的 master 没有故障，并且不是手动故障转移，校验失败返回。因为手动故障转移是可以在 master 正常的情况下直接发起的。</li>
<li>上一次为该 master 的投票时间，在 cluster_node_timeout 的 2 倍范围内，校验失败返回。这个用于使获胜从节点有时间将其成为新主节点的消息通知给其他从节点，从而避免另一个从节点发起新一轮选举又进行一次没必要的故障转移</li>
<li>请求节点宣称要负责的槽位，是否比之前负责这些槽位的节点，具有相等或更大的 configEpoch，如果不是，校验失败返回。</li>
<li>如果通过以上所有校验，那么主节点将向要求投票的从节点返回一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，表示这个主节点支持从节点成为新的主节点。</li>
</ol>
</li>
<li>每个参与选举的从节点都会接收 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，并根据自己收到了多少条这种消息来统计自己获得了多少个主节点的支持。</li>
<li>如果集群里有 N 个具有投票权的主节点，那么当一个从节点收集到大于等于 N/2+1 张支持票时，这个从节点就会当选为新的主节点。因为在每一个配置纪元里面，每个具有投票权的主节点只能投一次票，所以如果有 N个主节点进行投票，那么具有大于等于 N/2+1 张支持票的从节点只会有一个，这确保了新的主节点只会有一个。</li>
<li>如果在一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点为止。</li>
</ol>
<ul>
<li>这个选举新主节点的方法和选举领头 Sentinel 的方法非常相似，因为两者都是基于 Raft 算法的领头选举（leader election）方法来实现的。</li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>如何保证集群在线扩容的安全性？（Redis 集群要增加分片，槽的迁移怎么保证无损）</strong><ul>
<li>Redis 使用了 ASK 错误来保证在线扩容的安全性。</li>
<li>在槽的迁移过程中若有客户端访问，依旧先访问源节点，源节点会先在自己的数据库里面査找指定的键，如果找到的话，就直接执行客户端发送的命令。</li>
<li>如果没找到，说明该键可能已经被迁移到目标节点了，源节点将向客户端返回一个 ASK 错误，该错误会指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令，从而获取到结果。<ul>
<li>ASK 错误<ul>
<li>在进行重新分片期间，源节点向目标节点迁移一个槽的过程中，可能会出现这样一种情况：属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对则保存在目标节点里面。</li>
<li>当客户端向源节点发送一个与数据库键有关的命令，并且命令要处理的数据库键恰好就属于正在被迁移的槽时。源节点会先在自己的数据库里面査找指定的键，如果找到的话，就直接执行客户端发送的命令。</li>
<li>否则，这个键有可能已经被迁移到了目标节点，源节点将向客户端返回一个 ASK 错误，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令，从而获取到结果。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>为什么 Redis 集群有 16384 个槽？</strong><ol>
<li>如果槽位为 65536，发送心跳信息的消息头达 8k，发送的心跳包过于庞大。<ul>
<li>在消息头中，最占空间的是 <code>myslots[CLUSTER_SLOTS/8]</code>。 当槽位为 65536 时，这块的大小是: 65536÷8÷1024=8kb 因为每秒钟，redis 节点需要发送一定数量的 ping 消息作为心跳包，如果槽位为 65536，这个 ping 消息的消息头太大了，浪费带宽。</li>
</ul>
</li>
<li>Redis 的集群主节点数量基本不可能超过 1000 个。<ul>
<li>集群节点越多，心跳包的消息体内携带的数据越多。如果节点过 1000 个，也会导致网络拥堵。因此 Redis 作者，不建议 redis cluster 节点数量超过 1000 个。那么，对于节点数在 1000 以内的 redis cluster 集群，16384 个槽位够用了。没有必要拓展到 65536 个。</li>
</ul>
</li>
<li>槽位越小，节点少的情况下，压缩比高<ul>
<li>Redis 主节点的配置信息中，它所负责的哈希槽是通过一张 bitmap 的形式来保存的，在传输过程中，会对 bitmap 进行压缩，但是如果 bitmap 的填充率<code>slots / N</code>很高的话（N 表示节点数），bitmap 的压缩率就很低。如果节点数很少，而哈希槽数量很多的话，bitmap 的压缩率就很低。<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2></li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li>Redis 的事务并不推荐在实际中使用，如果要使用事务，推荐使用 Lua 脚本，Redis 会保证一个 Lua 脚本里的所有命令的原子性。</li>
</ul>
<h2 id="常用方式"><a href="#常用方式" class="headerlink" title="常用方式"></a>常用方式</h2><ul>
<li>缓存<ul>
<li>可能遇到的问题：<ul>
<li>缓存雪崩<ul>
<li>同一时刻大量缓存失效</li>
<li>处理方法<ul>
<li>缓存数据增加过期标记</li>
<li>设置不同的缓存失效时间</li>
<li>双层缓存策略 C1 为短期，C2 为⻓期</li>
<li>定时更新策略</li>
</ul>
</li>
</ul>
</li>
<li>缓存穿透<ul>
<li>频繁请求查询系统中不存在的数据导致</li>
<li>处理方法<ul>
<li>对请求参数进行校验，不合理直接返回</li>
<li>查询不到的数据也放到缓存，value 为空，如 set -999 “”</li>
<li>使用布隆过滤器，快速判断 key 是否在数据库中存在，不存在直接返回<ul>
<li>布隆过滤器<ul>
<li>布隆过滤器的特点是判断不存在的，则一定不存在；判断存在的，大概率存在，但也有小概率不存在。并且这个概率是可控的，我们可以让这个概率变小或者变高，取决于用户本身的需求。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>缓存击穿<ul>
<li>设置了过期时间的 key，承载着高并发，是一种热点数据。从这个 key 过期到重新从 MySQL 加载数据放到缓存的一段时间，大量的请求有可能把数据库打死。缓存雪崩是指大量缓存失效，缓存击穿是指热点数据的缓存失效</li>
<li>处理方法<ul>
<li>设置 key 永远不过期，或者快过期时，通过另一个异步线程重新设置 key</li>
<li>当从缓存拿到的数据为 null，重新从数据库加载数据的过程上锁</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>分布式锁<ul>
<li>涉及操作<ul>
<li>set + lua 脚本</li>
</ul>
</li>
<li>看门狗策略<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81_%E7%9C%8B%E9%97%A8%E7%8B%97%E7%AD%96%E7%95%A5.jpg" alt="Redis_分布式锁_看门狗策略"></li>
</ul>
</li>
<li>存在的问题<ul>
<li>步骤<ol>
<li>线程 1 首先获取锁成功，将键值对写入 redis 的 master 节点</li>
<li>在 redis 将该键值对同步到 slave 节点之前，master 发生了故障</li>
<li>redis 触发故障转移，其中一个 slave 升级为新的 master</li>
<li>此时新的 master 并不包含线程 1 写入的键值对，因此线程2尝试获取锁也可以成功拿到锁</li>
<li>此时相当于有两个线程获取到了锁，可能会导致各种预期之外的情况发生，例如最常见的脏数据</li>
</ol>
</li>
<li>解决方法和思路<ul>
<li>Zookeeper 实现的分布式锁</li>
<li>Redlock<ul>
<li>方案思路<ul>
<li>假设我们有 N 个 Redis 主节点，例如 N = 5，这些节点是完全独立的，我们不使用复制或任何其他隐式协调系统，为了取到锁，客户端应该执行以下操作：<ol>
<li>获取当前时间，以毫秒为单位。</li>
<li>依次尝试从 5 个实例，使用相同的 key 和随机值（例如UUID）获取锁。当向 Redis 请求获取锁时，客户端应该设置一个超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为10秒，则超时时间应该在 5-50 毫秒之间。这样可以防止客户端在试图与一个宕机的 Redis 节点对话时长时间处于阻塞状态。如果一个实例不可用，客户端应该尽快尝试去另外一个 Redis 实例请求获取锁。</li>
<li>客户端通过当前时间减去步骤 1 记录的时间来计算获取锁使用的时间。当且仅当从大多数（N/2+1，这里是3个节点）的 Redis 节点都取到锁，并且获取锁使用的时间小于锁失效时间时，锁才算获取成功。</li>
<li>如果取到了锁，其真正有效时间等于初始有效时间减去获取锁所使用的时间（步骤3计算的结果）。</li>
<li>如果由于某些原因未能获得锁（无法在至少 N/2+1 个 Redis 实例获取锁、或获取锁的时间超过了有效时间），客户端应该在所有的 Redis 实例上进行解锁（即便某些 Redis 实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。</li>
</ol>
</li>
</ul>
</li>
<li>存在的问题<ul>
<li>该方案的成本似乎有点高，需要使用5个实例；</li>
<li>严重依赖系统时钟。如果线程 1 从 3 个实例获取到了锁，但是这 3 个实例中的某个实例的系统时间走的稍微快一点，则它持有的锁会提前过期被释放，当他释放后，此时又有 3 个实例是空闲的，则线程 2 也可以获取到锁，则可能出现两个线程同时持有锁了。</li>
<li>如果线程 1 从 3 个实例获取到了锁，但是万一其中有 1 台重启了，则此时又有 3 个实例是空闲的，则线程 2 也可以获取到锁，此时又出现两个线程同时持有锁了。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>排行榜<ul>
<li>涉及操作<ul>
<li>zset</li>
</ul>
</li>
</ul>
</li>
<li>计数<ul>
<li>涉及操作<ul>
<li>incrby</li>
</ul>
</li>
</ul>
</li>
<li>消息队列<ul>
<li>涉及操作<ul>
<li>stream</li>
</ul>
</li>
</ul>
</li>
<li>地理位置<ul>
<li>涉及操作<ul>
<li>geo</li>
</ul>
</li>
</ul>
</li>
<li>访客统计<ul>
<li>涉及操作<ul>
<li>hyperloglog</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><ul>
<li>缩短键值对的存储长度<ul>
<li>键值对的长度是和性能成反比</li>
</ul>
</li>
<li>使用 lazy free 特性</li>
<li>设置键值的过期时间</li>
<li>禁用长耗时的查询命令<ul>
<li>Redis 绝大多数读写命令的时间复杂度都在 $O(1)$ 到 $O(N)$ 之间</li>
<li>要避免 $O(N)$ 命令对 Redis造 成影响，可以从以下几个方面入手改造：<ul>
<li>禁止使用 keys 命令；</li>
<li>避免一次查询所有的成员，要使用 scan 命令进行分批的、游标式的遍历；</li>
<li>通过机制严格控制 Hash、Set、Sorted Set 等结构的数据大小；</li>
<li>将排序、并集、交集等操作放在客户端执行，以减少 Redis 服务器运行压力；</li>
<li>删除一个大数据的时候，可能会需要很长时间，所以建议用异步删除的方式 unlink，它会启动一个新的线程来删除目标数据，而不阻塞 Redis 的主线程。</li>
</ul>
</li>
<li>使用 slowlog 优化耗时命令</li>
<li>使用 Pipeline 批量操作数据<ul>
<li>Pipeline（管道技术）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。</li>
</ul>
</li>
<li>避免大量数据同时失效<ul>
<li>如果在大型系统中有大量缓存在同一时间同时过期，那么会导致 Redis 循环多次持续扫描过期字典，直到过期字典中过期键值被删除的比较稀疏为止，而在整个执行过程中会导致 Redis 的读写出现明显的卡顿，卡顿的另一种原因是内存管理器需要频繁回收内存页，因此也会消耗一定的 CPU。</li>
<li>为了避免这种卡顿现象的产生，我们需要预防大量的缓存在同一时刻一起过期，最简单的解决方案就是在过期时间的基础上添加一个指定范围的随机数。</li>
</ul>
</li>
<li>客户端使用优化<ul>
<li>在客户端的使用上我们除了要尽量使用 Pipeline 的技术外，还需要注意尽量使用 Redis 连接池，而不是频繁创建销毁 Redis 连接，这样就可以减少网络传输次数和减少了非必要调用指令。</li>
</ul>
</li>
<li>限制 Redis 内存大小</li>
<li>使用物理机而非虚拟机</li>
<li>检查数据持久化策略</li>
<li>禁用 THP 特性<ul>
<li>Linux kernel 在 2.6.38 内核增加了 Transparent Huge Pages（THP）特性，支持大内存页 2MB 分配，默认开启。</li>
<li>当开启了 THP 时，fork 的速度会变慢，fork 之后每个内存页从原来 4KB 变为 2MB，会大幅增加重写期间父进程内存消耗。同时每次写命令引起的复制内存页单位放大了 512 倍，会拖慢写操作的执行时间，导致大量写操作慢查询。</li>
</ul>
</li>
<li>使用分布式架构来增加读写速度<ul>
<li>主从同步</li>
<li>哨兵模式</li>
<li>Redis Cluster 集群</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h2><ul>
<li><strong>Redis 单线程为什么执行速度这么快?</strong><ul>
<li>纯内存操作，避免大量访问数据库，减少直接读取磁盘数据，Redis 将数据储存在内存里面，读写数据的时候都不会受到硬盘 I/O 速度的限制，所以速度快</li>
<li>单线程操作，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换 而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗</li>
<li>采用了非阻塞 I/O 多路复用机制</li>
</ul>
</li>
<li><strong>Redis 是单线程还是多线程？</strong><ul>
<li>redis 4.0 之前，redis 是完全单线程的。</li>
<li>redis 4.0 时，redis 引入了多线程，但是额外的线程只是用于后台处理，例如：删除对象。核心流程还是完全单线程的。这也是为什么有些人说 4.0 是单线程的，因为他们指的是核心流程是单线程的。<ul>
<li>这边的核心流程指的是 redis 正常处理客户端请求的流程，通常包括：接收命令、解析命令、执行命令、返回结果等。</li>
</ul>
</li>
<li>redis 6.0 版本又一次引入了多线程概念，与 4.0 不同的是，这次的多线程会涉及到上述的核心流程。<ul>
<li>redis 6.0 中，多线程主要用于网络 I/O 阶段，也就是接收命令和写回结果阶段，而在执行命令阶段，还是由单线程串行执行。由于执行时还是串行，因此无需考虑并发安全问题。</li>
<li>值得注意的时，redis 中的多线程组不会同时存在“读”和“写”，这个多线程组只会同时“读”或者同时“写”。</li>
<li>处理流程<ol>
<li>当有读事件到来时，主线程将该客户端连接放到全局等待读队列</li>
<li>读取数据：<ol>
<li>主线程将等待读队列的客户端连接通过轮询调度算法分配给 I/O 线程处理；</li>
<li>同时主线程也会自己负责处理一个客户端连接的读事件；</li>
<li>当主线程处理完该连接的读事件后，会自旋等待所有 I/O 线程处理完毕</li>
</ol>
</li>
<li>命令执行：主线程按照事件被加入全局等待读队列的顺序（这边保证了执行顺序是正确的），串行执行客户端命令，然后将客户端连接放到全局等待写队列</li>
<li>写回结果：跟等待读队列处理类似，主线程将等待写队列的客户端连接使用轮询调度算法分配给 I/O 线程处理，同时自己也会处理一个，当主线程处理完毕后，会自旋等待所有 I/O 线程处理完毕，最后清空队列。</li>
</ol>
<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis6_%E5%A4%9A%E7%BA%BF%E7%A8%8B.jpg" alt="Redis6_多线程"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>服务重启时如何加载？</strong><ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E6%95%B0%E6%8D%AE%E8%BD%BD%E5%85%A5%E6%B5%81%E7%A8%8B.jpg" alt="Redis_数据载入流程"></li>
</ul>
</li>
<li><strong>Redis 怎么保证高可用、有哪些集群模式？</strong><ul>
<li>主从复制</li>
<li>哨兵模式</li>
<li>集群模式</li>
</ul>
</li>
<li><strong>Redis 和 Memcached 的比较</strong><ol>
<li>数据结构：memcached 支持简单的 key-value 数据结构，而 redis 支持丰富的数据结构：String、List、Set、Hash、SortedSet 等。</li>
<li>数据存储：memcached 和 redis 的数据都是全部在内存中。</li>
<li>持久化：memcached 不支持持久化，redis 支持将数据持久化到磁盘。</li>
<li>灾难恢复：实例挂掉后，memcached 数据不可恢复，redis 可通过 RDB、AOF 恢复，但是还是会有数据丢失问题。</li>
<li>事件库：memcached 使用 Libevent 事件库，redis 自己封装了简易事件库 AeEvent。</li>
<li>过期键删除策略：memcached 使用惰性删除，redis 使用惰性删除+定期删除。</li>
<li>内存驱逐（淘汰）策略：memcached 主要为 LRU 算法，redis 当前支持 8 种淘汰策略。</li>
<li>性能比较<ul>
<li>按“CPU 单核” 维度比较：由于 Redis 只使用单核，而 Memcached 可以使用多核，所以在比较上：在处理小数据时，平均每一个核上 Redis 比 Memcached 性能更高，而在 100k 左右的大数据时， Memcached 性能要高于 Redis。</li>
<li>按“实例”维度进行比较：由于 Memcached 多线程的特性，在 Redis 6.0 之前，通常情况下 Memcached 性能是要高于 Redis 的，同时实例的 CPU 核数越多，Memcached 的性能优势越大。</li>
</ul>
</li>
</ol>
</li>
<li><strong>如何保证数据库和缓存的数据一致性？</strong><ul>
<li>无论是先操作数据库，还是先操作缓存，都会存在脏数据的情况<ul>
<li>先操作数据库<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7_%E5%85%88%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93.jpg" alt="Redis_缓存一致性_先操作数据库"></li>
<li>可能存在的脏数据时间范围：更新数据库后，失效缓存前。这个时间范围很小，通常不会超过几毫秒。</li>
</ul>
</li>
<li>先操作缓存<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7_%E5%85%88%E6%93%8D%E4%BD%9C%E7%BC%93%E5%AD%98.jpg" alt="Redis_缓存一致性_先操作缓存"></li>
<li>​可能存在的脏数据时间范围：更新数据库后，下一次对该数据的更新前。这个时间范围不确定性很大，情况如下：<ul>
<li>如果下一次对该数据的更新马上就到来，那么会失效缓存，脏数据的时间就很短。</li>
<li>如果下一次对该数据的更新要很久才到来，那这期间缓存保存的一直是脏数据，时间范围很长。</li>
</ul>
</li>
</ul>
</li>
<li>通过上述案例可以看出，先操作数据库和先操作缓存都会存在脏数据的情况。但是相比之下，先操作数据库，再操作缓存是更优的方式，即使在并发极端情况下，也只会出现很小量的脏数据。</li>
<li><strong>为什么是让缓存失效，而不是更新缓存？</strong><ul>
<li>更新缓存<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7_%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98.jpg" alt="Redis_缓存一致性_更新缓存"></li>
<li>数据库中的数据是请求B的，缓存中的数据是请求A的，数据库和缓存存在数据不一致。</li>
</ul>
</li>
<li>失效（删除）缓存<ul>
<li><img src="/2019/09/01/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Redis_%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7_%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98.jpg" alt="Redis_缓存一致性_删除缓存"></li>
<li>由于是删除缓存，所以不存在数据不一致的情况。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>由于数据库和缓存是两个不同的数据源，要保证其数据一致性，其实就是典型的分布式事务场景，可以引入分布式事务来解决，常见的有：2PC、TCC、MQ 事务消息等。</li>
<li>但是引入分布式事务必然会带来性能上的影响，这与我们当初引入缓存来提升性能的目的是相违背的。</li>
<li>所以在实际使用中，通常不会去保证缓存和数据库的强一致性，而是做出一定的牺牲，保证两者数据的最终一致性。</li>
<li>保证数据库和缓存数据最终一致性的常用方案如下：<ol>
<li>更新数据库，数据库产生 binlog。</li>
<li>监听和消费 binlog，执行失效缓存操作。</li>
<li>如果步骤 2 失效缓存失败，则引入重试机制，将失败的数据通过MQ方式进行重试，同时考虑是否需要引入幂等机制。</li>
</ol>
</li>
</ul>
</li>
<li><strong>Redis 热 key 查找与处理</strong><ul>
<li>查找<ul>
<li>使用 Redis 内置功能发现大 Key 及热 Key<ul>
<li>通过 Redis 内置命令对目标 Key 进行分析<ul>
<li>使用 debug object 命令对 Key 进行分析。</li>
<li>Redis 自 4.0 起提供了 MEMORY USAGE 命令来帮助分析 Key 的内存占用，相对 debug object 它的执行代价更低，但由于其时间复杂度为 $O(N)$ 因此在分析大 Key 时仍有阻塞风险。</li>
</ul>
</li>
<li>通过 Redis 官方客户端 redis-cli 的 bigkeys 参数发现大 Key</li>
<li>通过业务层定位热 Key<ul>
<li>可以通过在业务层增加相应的代码对 Redis 的访问进行记录并异步汇总分析</li>
</ul>
</li>
<li>使用 monitor 命令在紧急情况时找出热 Key<ul>
<li>Redis 的 monitor 命令能够忠实的打印 Redis 中的所有请求，包括时间信息、Client 信息、命令以及 Key 信息。在发生紧急情况时，我们可以通过短暂执行 monitor 命令并将输出重定向至文件，在关闭 monitor 命令后通过对文件中请求进行归类分析即可找出这段时间中的热 Key。</li>
<li>由于 monitor 命令对 Redi s的 CPU、内存、网络资源均有一定的占用。因此，对于一个已处于高压状态的 Redis，monitor 可能会起到雪上加霜的作用。同时，这种异步收集并分析的方案的时效性较差，并且由于分析的精确度取决于 monitor 的执行时间，因此在多数无法长时间执行该命令的线上场景中本方案的精确度也不够好。</li>
</ul>
</li>
<li>hotkeys 参数，redis 4.0.3 提供了 redis-cli 的热点 key 发现功能，执行 redis-cli 时加上 -hotkeys 选项即可。但是该参数在执行的时候，如果 key 比较多，执行起来比较慢。</li>
</ul>
</li>
<li>使用开源工具发现大 Key<ul>
<li>使用 redis-rdb-tools 工具以定制化方式找出大 Key<ul>
<li>该工具能够对 Redis 的 RDB 文件进行定制化的分析，但由于分析 RDB 文件为离线工作，因此对线上服务不会有任何影响，这是它的最大优点但同时也是它的最大缺点：离线分析代表着分析结果的较差时效性。对于一个较大的 RDB 文件，它的分析可能会持续很久很久。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>处理<ul>
<li>大 Key 的常见处理办法<ul>
<li>对大 Key 进行拆分<ul>
<li>如将一个含有数万成员的 HASH Key 拆分为多个 HASH Key，并确保每个 Key 的成员数量在合理范围，在 Redis Cluster 结构中，大 Key 的拆分对 node 间的内存平衡能够起到显著作用。</li>
</ul>
</li>
<li>对大 Key 进行清理<ul>
<li>将不适合 Redis 能力的数据存放至其它存储，并在 Redis 中删除此类数据。<ul>
<li>Redis 自 4.0 起提供了 UNLINK 命令，该命令能够以非阻塞的方式缓慢逐步的清理传入的 Key，通过 UNLINK，你可以安全的删除大 Key 甚至特大 Key。</li>
</ul>
</li>
</ul>
</li>
<li>时刻监控 Redis 的内存水位<ul>
<li>在大 Key 产生问题前发现它并进行处理是保持服务稳定的重要手段。我们可以通过监控系统并设置合理的 Redis 内存报警阈值来提醒我们此时可能有大 Key 正在产生，如：Redis 内存使用率超过 70%，Redis 内存 1 小时内增长率超过 20% 等。</li>
</ul>
</li>
<li>对失效数据进行定期清理<ul>
<li>例如我们会在 HASH 结构中以增量的形式不断写入大量数据而忽略了这些数据的时效性，这些大量堆积的失效数据会造成大 Key 的产生，可以通过定时任务的方式对失效数据进行清理。在此类场景中，建议使用 HSCAN 并配合 HDEL 对失效数据进行清理，这种方式能够在不阻塞的前提下清理无效数据。</li>
</ul>
</li>
</ul>
</li>
<li>热 Key 的常见处理办法<ul>
<li>在 Redis Cluster 结构中对热 Key 进行复制<ul>
<li>在 Redis Cluster 中，热 Key 由于迁移粒度问题造成请求无法打散使单一node 的压力无法下降。此时可以将对应热 Key 进行复制并迁移至其他 node，例如为热 Key foo 复制出 3 个内容完全一样的 Key 并名为 foo2，foo3，foo4，然后将这三个 Key 迁移到其他 node 来解决单一 node 的热 Key 压力。</li>
<li>该方案的缺点在于代码需要联动修改，同时，Key 一变多带来了数据一致性挑战：由更新一个 Key 演变为需要同时更新多个 Key，在很多时候，该方案仅建议用来临时解决当前的棘手问题。</li>
</ul>
</li>
<li>使用读写分离架构<ul>
<li>如果热 Key 的产生来自于读请求，那么读写分离是一个很好的解决方案。在使用读写分离架构时可以通过不断的增加从节点来降低每个 Redis 实例中的读请求压力。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">中间件-0-知识点汇总.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-01 09:15:30" itemprop="dateCreated datePublished" datetime="2019-09-01T09:15:30+08:00">2019-09-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">中间件</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h1><h2 id="路由与-web-服务器"><a href="#路由与-web-服务器" class="headerlink" title="路由与 web 服务器"></a>路由与 web 服务器</h2><ul>
<li>阿里基于 Nginx 研发的 Tengine</li>
<li>阿里内部的集中式路由服务 VipServer</li>
</ul>
<h2 id="RPC-框架"><a href="#RPC-框架" class="headerlink" title="RPC 框架"></a>RPC 框架</h2><ul>
<li>grpc</li>
<li>Thrift</li>
<li>阿里的 HSF</li>
<li>Dubbo<ul>
<li>节点说明<ul>
<li>Consumer<ul>
<li>需要调用远程服务的服务消费方 Registry 注册中心</li>
</ul>
</li>
<li>Provider<ul>
<li>服务提供方</li>
</ul>
</li>
<li>Container<ul>
<li>服务运行的容器</li>
</ul>
</li>
<li>Monitor<ul>
<li>监控中心</li>
</ul>
</li>
</ul>
</li>
<li>大致流程：<ul>
<li>首先服务提供者 Provider 启动然后向注册中心注册自己所能提供的服务。</li>
<li>服务消费者 Consumer 启动向注册中心订阅自己所需的服务。</li>
<li>然后注册中心将提供者元信息通知给 Consumer， 之后 Consumer 因为已经从注册中心获取提供者的地址，因此可以通过负载均衡选择一个 Provider 直接调用。</li>
<li>之后服务提供方元数据变更的话注册中心会把变更推送给服务消费者。</li>
<li>服务提供者和消费者都会在内存中记录着调用的次数和时间，然后定时的发送统计数据到监控中心。</li>
</ul>
</li>
<li>注意：<ul>
<li>注册中心和监控中心是可选的，可以直接在配置文件里面写然后提供方和消费方直连。</li>
<li>注册中心、提供方和消费方之间都是⻓连接，和监控方不是⻓连接，并且消费方是直接调用提供方，不经过注册中心。</li>
<li>注册中心和监控中心宕机了也不会影响到已经正常运行的提供者和消费者，因为消费者有本地缓存提供者的信息。</li>
</ul>
</li>
<li>分层：<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/dubbo_1.jpg" alt="dubbo_1"></li>
<li>Service，业务层，就是咱们开发的业务逻辑层。</li>
<li>Config，配置层，主要围绕 ServiceConfig 和 ReferenceConfig，初始化配置信息。</li>
<li>Proxy，代理层，服务提供者还是消费者都会生成一个代理类，使得服务接口透明化，代理层做远程调用和返回结果。</li>
<li>Register，注册层，封装了服务注册和发现。</li>
<li>Cluster，路由和集群容错层，负责选取具体调用的节点，处理特殊的调用要求和负责远程调用失败的容错措施。</li>
<li>Monitor，监控层，负责监控统计调用时间和次数。</li>
<li>Portocol，远程调用层，主要是封装 RPC 调用，主要负责管理 Invoker，Invoker 代表一个抽象封装了的执行体。</li>
<li>Exchange，信息交换层，用来封装请求响应模型，同步转异步。</li>
<li>Transport，网络传输层，抽象了网络传输的统一接口，这样用户想用 Netty 就用 Netty，想用 Mina 就用 Mina。</li>
<li>Serialize，序列化层，将数据序列化成二进制流，当然也做反序列化。</li>
</ul>
</li>
<li>调用过程：<ul>
<li>服务暴露过程<ol>
<li>首先 Provider 启动，通过 Proxy 组件根据具体的协议 Protocol 将需要暴露出去的接口封装成 Invoker， Invoker 是 Dubbo 一个很核心的组件，代表一个可执行体。</li>
<li>然后再通过 Exporter 包装一下，这是为了在注册中心暴露自己套的一层，然后将 Exporter 通过 Registry 注册到注册中心。 这就是整体服务暴露过程。</li>
</ol>
</li>
<li>消费过程<ol>
<li>首先消费者启动会向注册中心拉取服务提供者的元信息，然后调用流程也是从 Proxy 开始，毕竟都需要代理才能无感知。</li>
<li>Proxy 持有一个 Invoker 对象，调用 invoke 之后需要通过 Cluster 先从 Directory 获取所有可调用的远程服务的 Invoker 列表，如果配置了某些路由规则，比如某个接口只能调用某个节点的那就再过滤一遍 Invoker 列表。</li>
<li>剩下的 Invoker 再通过 LoadBalance 做负载均衡选取一个。然后再经过 Filter 做一些统计什么的，再通过 Client 做数据传输，比如用 Netty 来传输。</li>
<li>传输需要经过 Codec 接口做协议构造，再序列化。最终发往对应的服务提供者。</li>
<li>服务提供者接收到之后也会进行 Codec 协议处理，然后反序列化后将请求扔到线程池处理。某个线程会根据请求找到对应的 Exporter ，而找到 Exporter 其实就是找到了 Invoker，但是还会有一层层 Filter，经过一层层过滤链之后最终调用实现类然后原路返回结果。</li>
</ol>
</li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/dubbo_2.jpg" alt="dubbo_2"></li>
</ul>
</li>
<li>负载均衡策略<ul>
<li>随机 Random LoadBalance<ul>
<li>按照权重设置的大小，随机</li>
</ul>
</li>
<li>轮询 RoundRobin LoadBalance<ul>
<li>例如：a b c，a 执行完 b 执行然后c，然后在到 a</li>
</ul>
</li>
<li>最少活跃调用数（权重）LeastActive LoadBalance<ul>
<li>活跃数指调用前后计数差，优先调用高的，相同活跃数的随机。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。</li>
</ul>
</li>
<li>一致性 Hash ConsistentHash LoadBalance<ul>
<li>相同参数总是发送到同一个提供者，如果这个提供者挂掉了，它会根据它的虚拟节点，平摊到其它服务者，不会引起巨大的变动</li>
</ul>
</li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>Dubbo 和 Spring Cloud 有什么区别？</strong><ul>
<li>通信方式不同<ul>
<li>Dubbo 使用的是 RPC 通信，而 Spring Cloud 使用的是 HTTP RESTFul 方式。</li>
</ul>
</li>
<li>组成部分不同</li>
</ul>
</li>
<li><strong>当一个服务接口有多种实现时怎么做？</strong><ul>
<li>当一个接口有多种实现时，可以用 group 属性来分组，服务提供方和消费方都指定同一个 group 即可。</li>
</ul>
</li>
<li><strong>服务上线怎么兼容旧版本？</strong><ul>
<li>可以用版本号（version）过渡，多个不同版本的服务注册到注册中心，版本号不同的服务相互间不引用。这个和服务分组的概念有一点类似。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>SOFA-RPC</li>
</ul>
<h2 id="消息中间件"><a href="#消息中间件" class="headerlink" title="消息中间件"></a>消息中间件</h2><ul>
<li>消息队列通信的模式<ul>
<li>点对点模式<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97_%E7%82%B9%E5%AF%B9%E7%82%B9%E6%A8%A1%E5%BC%8F.jpg" alt="消息队列_点对点模式"></li>
<li>点对点模式通常是基于拉取或者轮询的消息传送模型，这个模型的特点是发送到队列的消息被一个且只有一个消费者进行处理。生产者将消息放入消息队列后，由消费者主动的去拉取消息进行消费。点对点模型的的优点是消费者拉取消息的频率可以由自己控制。但是消息队列是否有消息需要消费，在消费者端无法感知，所以在消费者端需要额外的线程去监控。</li>
</ul>
</li>
<li>发布订阅模式<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97_%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F.jpg" alt="消息队列_发布订阅模式"></li>
<li>发布订阅模式是一个基于消息送的消息传送模型，该模型可以有多种不同的订阅者。生产者将消息放入消息队列后，队列会将消息推送给订阅过该类消息的消费者（类似微信公众号）。由于是消费者被动接收推送，所以无需感知消息队列是否有待消费的消息！但是 consumer1、consumer2、consumer3 由于机器性能不一样，所以处理消息的能力也会不一样，但消息队列却无法感知消费者消费的速度！所以推送的速度成了发布订阅模模式的一个问题！假设三个消费者处理速度分别是 8M/s、5M/s、2M/s，如果队列推送的速度为 5M/s，则 consumer3 无法承受！如果队列推送的速度为 2M/s，则 consumer1、consumer2 会出现资源的极大浪费！</li>
</ul>
</li>
</ul>
</li>
<li>消息队列使用场景<ul>
<li>解耦<ul>
<li>解耦是消息队列要解决的最本质问题。</li>
</ul>
</li>
<li>最终一致性<ul>
<li>最终一致性指的是两个系统的状态保持一致，要么都成功，要么都失败。</li>
<li>最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。</li>
</ul>
</li>
<li>广播<ul>
<li>消息队列的基本功能之一是进行广播。</li>
<li>有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。</li>
</ul>
</li>
<li>错峰与流控<ul>
<li>典型的使用场景就是秒杀业务用于流量削峰场景。</li>
</ul>
</li>
</ul>
</li>
<li>常用的消息队列<ul>
<li>Apache Kafka<ul>
<li>Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据，具有高性能、持久化、多副本备份、横向扩展能力。</li>
<li>架构<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97_%E6%9E%B6%E6%9E%84.jpg" alt="消息队列_架构"></li>
<li>Producer<ul>
<li>Producer 即生产者，消息的产生者，是消息的入口。</li>
</ul>
</li>
<li>Kafka cluster<ul>
<li>Broker<ul>
<li>Broker 是 Kafka 实例，每个服务器上有一个或多个 Kafka 的实例，我们姑且认为每个 broker 对应一台服务器。每个 Kafka 集群内的 broker 都有一个不重复的编号，如图中的 broker-0、broker-1 等……</li>
<li>Controller Broker<ul>
<li>在 Kafka 早期版本，对于分区和副本的状态的管理依赖于 zookeeper 的 Watcher 和队列：每一个 broker 都会在 zookeeper 注册 Watcher，所以 zookeeper 就会出现大量的 Watcher, 如果宕机的 broker 上的 partition 很多比较多，会造成多个 Watcher 触发，造成集群内大规模调整；每一个 replica 都要去再次 zookeeper 上注册监视器，当集群规模很大的时候，zookeeper 负担很重。这种设计很容易出现脑裂和羊群效应以及 zookeeper 集群过载。</li>
<li>新版本该变了这种设计，使用 Kafka Controller，Leader 会向 zookeeper 上注册 Watcher，其他 broker 几乎不用监听 zookeeper 的状态变化。</li>
<li>Kafka 集群中多个 broker，有一个会被选举为 controller leader，负责管理整个集群中分区和副本的状态，比如 partition 的 leader 副本故障，由 controller 负责为该 partition 重新选举新的 leader 副本；当检测到 ISR 列表发生变化，由 controller 通知集群中所有 broker 更新其 MetadataCache 信息；或者增加某个 topic 分区的时候也会由 controller 管理分区的重新分配工作。</li>
<li>当 broker 启动的时候，都会创建 KafkaController 对象，但是集群中只能有一个 leader 对外提供服务，这些每个节点上的 KafkaController 会在指定的 zookeeper 路径下创建临时节点，只有第一个成功创建的节点的 KafkaController 才可以成为 leader，其余的都是 follower。当 leader 故障后，所有的 follower 会收到通知，再次竞争在该路径下创建节点从而选举新的 leader。</li>
<li>Controller Broker 的具体作用<ul>
<li>创建、删除主题，增加分区并分配 leader 分区</li>
<li>集群 Broker 管理（新增 Broker、Broker 主动关闭、Broker 故障）</li>
<li>preferred leader 选举</li>
<li>分区重分配</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Topic<ul>
<li>消息的主题，可以理解为消息的分类，Kafka 的数据就保存在 topic。在每个 broker 上都可以创建多个 topic。</li>
</ul>
</li>
<li>Partition<ul>
<li>Topic 的分区，每个 topic 可以有多个分区，分区的作用是做负载，提高 Kafka 的吞吐量。同一个 topic 在不同的分区的数据是不重复的，partition 的表现形式就是一个一个的文件夹！</li>
<li>分区的主要目的<ul>
<li>方便扩展<ul>
<li>因为一个 topic 可以有多个 partition，所以我们可以通过扩展机器去轻松的应对日益增长的数据量。</li>
</ul>
</li>
<li>提高并发<ul>
<li>以 partition 为读写单位，可以多个消费者同时消费数据，提高了消息的处理效率。</li>
</ul>
</li>
</ul>
</li>
<li>Partition 结构<ul>
<li>Partition 在服务器上的表现形式就是一个一个的文件夹，每个 partition 的文件夹下面会有多组 segment 文件，每组 segment 文件又包含 .index 文件、.log 文件、.timeindex 文件（早期版本中没有）三个文件，<ul>
<li>log 文件就实际是存储 message 的地方</li>
<li>index 和 timeindex 文件为索引文件，用于检索消息。</li>
</ul>
</li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_partition%E7%BB%93%E6%9E%84.jpg" alt="Kafka_partition结构"><ul>
<li>这个 partition 有三组 segment 文件，每个 log 文件的大小是一样的，但是存储的 message 数量是不一定相等的（每条的 message 大小不一致）。文件的命名是以该 segment 最小 offset 来命名的，如 000.index 存储 offset 为 0~368795 的消息，kafka 就是利用分段+索引的方式来解决查找效率的问题。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Replication<ul>
<li>每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为 Leader。在 Kafka 中默认副本的最大数量是 10 个，且副本的数量不能大于 Broker 的数量，follower 和 leader 绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。</li>
</ul>
</li>
</ul>
</li>
<li>Message<ul>
<li>每一条发送的消息主体。</li>
<li>Message 结构<ul>
<li>消息主要包含消息体、消息大小、offset、压缩类型等等<ul>
<li>offset<ul>
<li>offset 是一个占 8byte 的有序 id 号，它可以唯一确定每条消息在 parition 内的位置！</li>
</ul>
</li>
<li>消息大小<ul>
<li>消息大小占用 4byte，用于描述消息的大小。</li>
</ul>
</li>
<li>消息体<ul>
<li>消息体存放的是实际的消息数据（被压缩过），占用的空间根据具体的消息而不一样。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Consumer<ul>
<li>消费者，即消息的消费方，是消息的出口。</li>
</ul>
</li>
<li>Consumer Group<ul>
<li>我们可以将多个消费组组成一个消费者组，在 Kafka 的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个 topic 的不同分区的数据，这也是为了提高 Kafka 的吞吐量！</li>
<li>GroupCoordinator<ul>
<li>每个 consumer group 都会选择一个 broker 作为自己的 coordinator，他是负责监控整个消费组里的各个分区的心跳，以及判断是否宕机，和开启 rebalance 的。</li>
<li>如何选择 coordinator 机器<ul>
<li>首先对 group id 进行 hash，接着对 __consumer_offsets 的分区数量进行取模，默认分区数量是 50</li>
<li>__consumer_offsets 的分区数量可以通过 offsets.topic.num.partitions 来设置，找到分区以后，这个分区所在的 broker 机器就是 coordinator 机器。<ul>
<li>__consumer_offsets topic 了，它是 Kafka 内部使用的一个 topic，专门用来存储 group 消费的情况，默认情况下有50个 partition，每个 partition 默认有三个副本，而具体的一个 group 的消费情况要存储到哪一个 partition 上，是根据 $abs(GroupId.hashCode()) % NumPartitions$ 来计算的（其中，NumPartitions 是 __consumer_offsets 的 partition 数，默认是50个）。</li>
</ul>
</li>
<li>对于 consumer group 而言，是根据其 group.id 进行 hash 并计算得到其具对应的 partition 值，该 partition leader 所在 Broker 即为该 Group 所对应的 GroupCoordinator，GroupCoordinator 会存储与该 group 相关的所有的 Meta 信息。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Zookeeper<ul>
<li>Kafka 集群依赖 zookeeper 来保存集群的的元信息，来保证系统的可用性。</li>
<li>具体功能<ul>
<li>对于 broker<ul>
<li>记录状态<ul>
<li>zookeeper 记录了所有 broker 的存活状态，broker 会向 zookeeper 发送心跳请求来上报自己的状态。</li>
<li>zookeeper 维护了一个正在运行并且属于集群的 broker 列表。</li>
</ul>
</li>
<li>控制器选举<ul>
<li>kafka 集群中有多个 broker，其中有一个会被选举为控制器。</li>
<li>控制器负责管理整个集群所有分区和副本的状态，例如某个分区的 leader 故障了，控制器会选举新的 leader。</li>
<li>从多个 broker 中选出控制器，这个工作就是 zookeeper 负责的。</li>
</ul>
</li>
<li>限额权限<ul>
<li>kafka 允许一些 client 有不同的生产和消费的限额。</li>
<li>这些限额配置信息是保存在 zookeeper 里面的。</li>
<li>所有 topic 的访问控制信息也是由 zookeeper 维护的。</li>
</ul>
</li>
<li>记录 ISR<ul>
<li>ISR（in-sync replica） 是 partition 的一组同步集合，就是所有 follower 里面同步最积极的那部分。</li>
<li>一条消息只有被 ISR 中的成员都接收到，才被视为“已同步”状态。</li>
<li>只有处于 ISR 集合中的副本才有资格被选举为 leader。</li>
<li>zookeeper 记录着 ISR 的信息，而且是实时更新的，只要发现其中有成员不正常，马上移除。</li>
</ul>
</li>
<li>node 和 topic 注册<ul>
<li>zookeeper 保存了所有 node 和 topic 的注册信息，可以方便的找到每个 broker 持有哪些 topic。</li>
<li>node 和 topic 在 zookeeper 中是以临时节点的形式存在的，只要与 zookeeper 的 session 一关闭，他们的信息就没有了。</li>
</ul>
</li>
<li>topic 配置<ul>
<li>zookeeper 保存了 topic 相关配置，例如 topic 列表、每个 topic 的 partition 数量、副本的位置等等。</li>
</ul>
</li>
</ul>
</li>
<li>对于 consumer<ul>
<li>offset<ul>
<li>kafka 老版本中，consumer 的消费偏移量是默认存储在 zookeeper 中的。</li>
<li>新版本中，这个工作由 kafka 自己做了，kafka 专门做了一个 offset manager。</li>
</ul>
</li>
<li>注册<ul>
<li>和 broker 一样，consumer 也需要注册。</li>
<li>consumer 会自动注册，注册的方式也是创建一个临时节点，consumer down 了之后就会自动销毁。</li>
</ul>
</li>
<li>分区注册<ul>
<li>kafka 的每个 partition 只能被消费组中的一个 consumer 消费，kafka 必须知道所有 partition 与 consumer 的关系。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>Kafka 为什么要放弃 Zookeeper？</strong><ul>
<li>confluent 社区发表了一篇文章，主要讲述了 Kafka 未来的 2.8 版本将要放弃 Zookeeper，这对于 Kafka 用户来说，是一个重要的改进。之前部署 Kafka 就必须得部署 Zookeeper，而之后就只要单独部署 Kafka 就行了。</li>
<li>Kafka 本身就是一个分布式系统，但是需要另一个分布式系统来管理，复杂性无疑增加了。<ul>
<li>运维复杂度</li>
<li>Controller 故障处理<ul>
<li>Kafaka 依赖一个单一 Controller 节点跟 Zookeeper 进行交互，如果这个 Controller 节点发生了故障，就需要从 broker 中选择新的 Controller。</li>
<li>新的 Controller 选举成功后，会重新从 Zookeeper 拉取元数据进行初始化，并且需要通知其他所有的 broker 更新 ActiveControllerId。老的 Controller 需要关闭监听、事件处理线程和定时任务。分区数非常多时，这个过程非常耗时，而且这个过程中 Kafka 集群是不能工作的。</li>
</ul>
</li>
<li>分区瓶颈<ul>
<li>当分区数增加时，Zookeeper 保存的元数据变多，Zookeeper 集群压力变大，达到一定级别后，监听延迟增加，给 Kafaka 的工作带来了影响。</li>
</ul>
</li>
</ul>
</li>
<li>升级<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E5%8F%96%E6%B6%88zookeeper%E5%90%8E%E7%9A%84%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="Kafka_取消zookeeper后的架构图"></li>
<li>KIP-500 用 Quorum Controller 代替之前的 Controller，Quorum 中每个 Controller 节点都会保存所有元数据，通过 KRaft 协议保证副本的一致性。这样即使 Quorum Controller 节点出故障了，新的 Controller 迁移也会非常快。</li>
<li>官方介绍，升级之后，Kafka 可以轻松支持百万级别的分区。</li>
</ul>
</li>
<li>Kafaka 计划在 3.0 版本会兼容 Zookeeper Controller 和 Quorum Controller，这样用户可以进行灰度测试。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>重平衡机制<ul>
<li>重平衡其实就是一个协议，它规定了如何让消费者组下的所有消费者来分配 topic 中的每一个分区。比如一个 topic 有 100 个分区，一个消费者组内有 20 个消费者，在协调者的控制下让组内每一个消费者分配到 5 个分区，这个分配的过程就是重平衡。</li>
<li>重平衡的触发条件<ul>
<li>消费者组内成员发生变更，这个变更包括了增加和减少消费者。注意这里的减少有很大的可能是被动的，就是某个消费者崩溃退出了</li>
<li>主题的分区数发生变更，kafka 目前只支持增加分区，当增加的时候就会触发重平衡</li>
<li>订阅的主题发生变化，当消费者组使用正则表达式订阅主题，而恰好又新建了对应的主题，就会触发重平衡</li>
</ul>
</li>
<li>重平衡策略<ul>
<li>Range<ul>
<li>具体实现位于，package org.apache.kafka.clients.consumer.RangeAssignor。</li>
<li>把若干个连续的分区分配给消费者，如存在分区 1-5，假设有 3 个消费者，则消费者 1 负责分区 1-2,消费者 2 负责分区 3-4，消费者 3 负责分区 5。</li>
</ul>
</li>
<li>RoundRobin<ul>
<li>具体实现位于，package org.apache.kafka.clients.consumer.RoundRobinAssignor。</li>
<li>就是把所有分区逐个分给消费者，如存在分区 1-5，假设有 3 个消费者，则分区 1-&gt;消费 1，分区 2-&gt;消费者 2，分区 3&gt;消费者 3，分区 4&gt;消费者 1，分区 5-&gt;消费者 2。</li>
</ul>
</li>
<li>Sticky<ul>
<li>Sticky 分配策略是最新的也是最复杂的策略，其具体实现位于 package org.apache.kafka.clients.consumer.StickyAssignor。</li>
<li>这种分配策略是在 0.11.0 才被提出来的，主要是为了一定程度解决上面提到的重平衡非要重新分配全部分区的问题。称为粘性分配策略。</li>
</ul>
</li>
</ul>
</li>
<li>重平衡过程<ul>
<li>消费端重平衡流程<ul>
<li>Rebalance 是通过消费者群组中的称为“群主”消费者客户端进行的。<ul>
<li>“群主”就是第一个加入群组的消费者。消费者第一次加入群组时，它会向群组协调器发送一个 JoinGroup 的请求，如果是第一个，则此消费者被指定为“群主”。<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E9%87%8D%E5%B9%B3%E8%A1%A1_JoinGroup.png" alt="Kafka_重平衡_JoinGroup"></li>
</ul>
</li>
</ul>
</li>
</ul>
<ol>
<li>群主从群组协调器获取群组成员列表，然后给每一个消费者进行分配分区 Partition。<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E6%B6%88%E8%B4%B9%E7%AB%AF%E9%87%8D%E5%B9%B3%E8%A1%A1_1.jpg" alt="Kafka_消费端重平衡_1"></li>
</ul>
</li>
<li>群主分配完成之后，把分配情况发送给群组协调器。<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E6%B6%88%E8%B4%B9%E7%AB%AF%E9%87%8D%E5%B9%B3%E8%A1%A1_2.jpg" alt="Kafka_消费端重平衡_2"></li>
</ul>
</li>
<li>群组协调器再把这些信息发送给消费者。<strong>每一个消费者只能看到自己的分配信息，只有群主知道所有消费者的分配信息。</strong></li>
</ol>
</li>
<li>Broker 端重平衡<ul>
<li>新成员加入组<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E6%96%B0%E6%88%90%E5%91%98%E5%8A%A0%E5%85%A5%E7%BB%84.jpg" alt="Kafka_新成员加入组"></li>
</ul>
</li>
<li>组成员主动离组<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E7%BB%84%E6%88%90%E5%91%98%E4%B8%BB%E5%8A%A8%E7%A6%BB%E7%BB%84.jpg" alt="Kafka_组成员主动离组"></li>
</ul>
</li>
<li>组成员崩溃离组<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E7%BB%84%E6%88%90%E5%91%98%E5%B4%A9%E6%BA%83%E7%A6%BB%E7%BB%84.jpg" alt="Kafka_组成员崩溃离组"></li>
</ul>
</li>
<li>组成员提交位移<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E7%BB%84%E6%88%90%E5%91%98%E6%8F%90%E4%BA%A4%E4%BD%8D%E7%A7%BB.jpeg" alt="Kafka_组成员提交位移"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>避免重平衡<ul>
<li>未及时发送心跳<ul>
<li>第一类非必要 Rebalance 是因为未能及时发送心跳，导致 Consumer 被“踢出” Group 而引发的。因此，你需要仔细地设置 session.timeout.ms 和 heartbeat.interval.ms 的值。</li>
</ul>
</li>
<li>Consumer 消费时间过长<ul>
<li>第二类非必要 Rebalance 是 Consumer 消费时间过长导致的。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>ISR 机制<ul>
<li>Kafka 提供了数据复制算法保证，如果 leader 发生故障或挂掉，一个新 leader 被选举并被接受客户端的消息成功写入。Kafka 确保从同步副本列表中选举一个副本为 leader，或者说 follower 追赶 leader 数据。leader 负责维护和跟踪 ISR（In-Sync Replicas 的缩写，表示副本同步队列）中所有 follower 滞后的状态。当 producer 发送一条消息到 broker 后，leader 写入消息并复制到所有 follower。消息提交之后才被成功复制到所有的同步副本。消息复制延迟受最慢的 follower 限制，重要的是快速检测慢副本，如果 follower “落后”太多或者失效，leader 将会把它从 ISR 中删除。</li>
<li>相关概念<ul>
<li>AR：所有的副本（replicas）统称为 Assigned Replicas</li>
<li>ISR：in-Sync Replicas，这个是指副本同步队列</li>
<li>OSR：follower 从 leader 同步数据有一些延迟，任意一个超过阈值都会把 follower 剔除出 ISR, 存入 OSR（Outof-Sync Replicas）列表，新加入的 follower 也会先存放在 OSR 中</li>
<li>HW：HighWatermark，是指 consumer 能够看到的此 partition 的位置</li>
<li>LEO：LogEndOffset，表示每个 partition 的 log 最后一条 Message 的位置</li>
</ul>
</li>
<li>机制原理<ul>
<li>每个 replica 都有自己的 HW，leader 和 follower 各自负责更新自己的 HW 的状态。对于 leader 新写入的消息，consumer 不能立刻消费，leader 会等待该消息被所有 ISR 中的 replicas 同步后更新 HW，此时消息才能被 consumer 消费。这样就保证了如果 leader 所在的 broker 失效，该消息仍然可以从新选举的 leader 中获取。对于来自内部 broker 的读取请求，没有 HW 的限制。<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_ISR%E4%BB%A5%E5%8F%8AHW%E5%92%8CLEO%E7%9A%84%E6%B5%81%E8%BD%AC%E8%BF%87%E7%A8%8B.png" alt="Kafka_ISR以及HW和LEO的流转过程"></li>
</ul>
</li>
<li><strong>Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。</strong><ul>
<li>同步复制要求所有能工作的 follower 都复制完，这条消息才会被 commit，这种复制方式极大的影响了吞吐率。</li>
<li>异步复制方式下，follower 异步的从 leader 复制数据，数据只要被 leader 写入 log 就被认为已经 commit，这种情况下如果 follower 都还没有复制完，落后于 leader 时，突然 leader 宕机，则会丢失数据。</li>
</ul>
</li>
<li>流程<ul>
<li>自动给每个 Partition 维护一个 ISR 列表，这个列表里一定会有 Leader，然后还会包含跟 Leader 保持同步的 Follower。也就是说，只要 Leader 的某个 Follower 一直跟他保持数据同步，那么就会存在于 ISR 列表里。</li>
<li>但是如果 Follower 因为自身发生一些问题，导致不能及时的从 Leader 同步数据过去，那么这个 Follower 就会被认为是“out-of-sync”，从 ISR 列表里踢出去。</li>
</ul>
</li>
</ul>
</li>
<li>生效时机<ul>
<li>当 acks 参数设置为 all 时，producer 需要等待 ISR 中的所有 follower 都确认接收到数据后才算一次发送完成，可靠性最高。</li>
</ul>
</li>
</ul>
</li>
<li>工作流程<ul>
<li>发送数据<ul>
<li>Producer 在写入数据的时候永远的找 leader，不会直接将数据写入 follower。</li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E5%8F%91%E9%80%81%E6%95%B0%E6%8D%AE.jpg" alt="Kafka_发送数据"></li>
<li><strong>消息写入 leader 后，follower 是主动的去 leader 进行同步的！producer 采用 push 模式将数据发布到 broker，每条消息追加到分区中，顺序写入磁盘，所以保证同一分区内的数据是有序的！</strong></li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_producer_partition.jpg" alt="Kafka_producer_partition"></li>
<li>相关问题<ul>
<li><strong>如果某个 topic 有多个 partition，producer 又怎么知道该将数据发往哪个 partition 呢？</strong><ol>
<li>partition 在写入的时候可以指定需要写入的 partition，如果有指定，则写入对应的 partition。</li>
<li>如果没有指定 partition，但是设置了数据的 key，则会根据 key 的值 hash 出一个 partition。</li>
<li>如果既没指定 partition，又没有设置 key，则会轮询选出一个 partition。</li>
</ol>
</li>
<li><strong>producer 在向 kafka 写入消息的时候，怎么保证消息不丢失呢？</strong><ul>
<li>通过 ACK 应答机制！在生产者向队列写入数据的时候可以设置参数来确定是否确认 Kafka 接收到数据，这个参数可设置的值为 0、1、-1。<ul>
<li>0 代表 producer 往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最高。</li>
<li>1 代表 producer 往集群发送数据只要 leader 应答就可以发送下一条，只确保 leader 发送成功。<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E5%BA%94%E7%AD%94%E6%9C%BA%E5%88%B6_acks_1.png" alt="Kafka_应答机制_acks_1"></li>
</ul>
</li>
<li>-1 代表只有当 ISR 中的副本全部收到消息时，生产者才会认为消息生产成功了。这种配置是最安全的，因为如果 leader 副本挂了，当 follower 副本被选为 leader 副本时，消息也不会丢失。但是系统吞吐量会降低，因为生产者要等待所有副本都收到消息后才能再次发送消息。</li>
</ul>
</li>
</ul>
</li>
<li><strong>如果往不存在的 topic 写数据，能不能写入成功呢？</strong><ul>
<li>Kafka 会自动创建 topic，分区和副本的数量根据默认配置都是 1。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>保存数据<ul>
<li>Kafka 将数据保存在磁盘，可能在我们的一般的认知里，写入磁盘是比较耗时的操作，不适合这种高并发的组件。Kafka 初始会单独开辟一块磁盘空间，顺序写入数据（效率比随机写入高）。</li>
<li>存储策略<ol>
<li>基于时间，默认配置是 168 小时（7 天）。</li>
<li>基于大小，默认配置是 1073741824（1G）。</li>
</ol>
<ul>
<li>需要注意的是，kafka 读取特定消息的时间复杂度是 <code>O(1)</code>，所以这里删除过期的文件并不会提高 kafka 的性能！</li>
</ul>
</li>
</ul>
</li>
<li>消费数据<ul>
<li>Kafka 采用的是点对点的模式，消费者主动的去 kafka 集群拉取消息，与 producer 相同的是，消费者在拉取消息的时候也是找 leader 去拉取。</li>
<li>同一个消费组的消费者可以消费同一 topic 下不同分区的数据，但是不会组内多个消费者消费同一分区的数据！<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E6%B6%88%E8%B4%B9%E6%95%B0%E6%8D%AE.jpg" alt="Kafka_消费数据"></li>
<li>消费者组内的消费者小于 partition 数量的情况，所以会出现某个消费者消费多个 partition 数据的情况，消费的速度也就不及只处理一个 partition 的消费者的处理速度！</li>
</ul>
</li>
<li><strong>建议消费者组的 consumer 的数量与 partition 的数量一致！</strong></li>
<li>相关问题<ul>
<li><strong>查找消息的时候是怎么利用 segment+offset 配合查找的呢？假如现在需要查找一个 offset 为 368801 的 message 是什么样的过程呢？</strong><ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_%E6%9F%A5%E6%95%B0%E6%8D%AE.jpg" alt="Kafka_查数据"></li>
</ul>
<ol>
<li>先找到 offset 的 368801 的 message 所在的 segment 文件（利用二分法查找），这里找到的就是在第二个 segment 文件。</li>
<li>打开找到的 segment 中的 .index 文件（也就是 368796.index 文件，该文件起始偏移量为 368796+1，我们要查找的 offset 为 368801 的 message 在该 index 内的偏移量为 368796+5=368801，所以这里要查找的相对 offset 为 5）。由于该文件采用的是稀疏索引的方式存储着相对 offset 及对应 message 物理偏移量的关系，所以直接找相对 offset 为 5 的索引找不到，这里同样利用二分法查找相对 offset 小于或者等于指定的相对 offset 的索引条目中最大的那个相对 offset，所以找到的是相对 offset 为 4 的这个索引。</li>
<li>根据找到的相对 offset 为 4 的索引确定 message 存储的物理偏移位置为 256。打开数据文件，从位置为 256 的那个地方开始顺序扫描直到找到 offset 为 368801 的那条 Message。</li>
</ol>
<ul>
<li>这套机制是建立在 offset 为有序的基础上，利用 segment+有序 offset+稀疏索引+二分查找+顺序查找等多种手段来高效的查找数据！</li>
</ul>
</li>
<li><strong>从 kafka 读取数据后，数据会自动删除吗？</strong><ul>
<li>不会，kafka 中数据的删除跟有没有消费者消费完全无关。数据的删除，只跟 kafka broker 上面上面的这两个配置有关：<ul>
<li><blockquote>
<p>log.retention.hours=48 #数据最多保存48小时</p>
</blockquote>
</li>
<li><blockquote>
<p>log.retention.bytes=1073741824 #数据最多1G</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>log 的清除策略以及压缩策略<ul>
<li>日志的分段存储，一方面能够减少单个文件内容的大小，另一方面，方便 kafka 进行日志清理。</li>
<li>清理策略有两个：<ol>
<li>根据消息的保留时间，当消息在 kafka 中保存的时间超过了指定的时间，就会触发清理过程</li>
<li>根据 topic 存储的数据大小，当 topic 所占的日志文件大小大于一定的阀值，则可以开始删除最旧的消息。kafka 会启动一个后台线程，定期检查是否存在可以删除的消息</li>
</ol>
<ul>
<li>当其中任意一个达到要求，都会执行删除。</li>
</ul>
</li>
<li>日志压缩策略：<ul>
<li>通过这个功能可以有效的减少日志文件的大小，缓解磁盘紧张的情况，在很多实际场景中，消息的 key 和 value 的值之间的对应关系是不断变化的，就像数据库中的数据会不断被修改一样，消费者只关心 key 对应的最新的 value。因此，我们可以开启 kafka 的日志压缩功能，服务端会在后台启动启动 Cleaner 线程池，定期将相同的 key 进行合并，只保留最新的 value 值。</li>
</ul>
</li>
</ul>
</li>
<li>原理<ul>
<li>producer<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_producer%E6%9E%B6%E6%9E%84.png" alt="Kafka_producer架构"></li>
<li>整个生产者客户端由两个线程协调运行，这两个线程分别为主线程和发送线程。在主线程中由 KafkaProducer 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息收集器（RecordAccumulator，也称为消息累加器）中。发送线程负责从消息收集器中获取消息并将其发送到 Kafka 中。</li>
<li>主线程中发送过来的消息都会被追加到消息收集器的某个双端队列（Deque）中，在其的内部为每个分区都维护了一个双端队列，队列中的内容就是ProducerBatch，即 Deque。消息写入缓存时，追加到双端队列的尾部；Sender 读取消息时，从双端队列的头部读取。注意 ProducerBatch 不是 ProducerRecord，ProducerBatch 中可以包含一至多个 ProducerRecord。<ul>
<li>ProducerRecord 是生产者中创建的消息，而 ProducerBatch 是指一个消息批次，ProducerRecord 会被包含在 ProducerBatch 中，这样可以使字节的使用更加紧凑。与此同时，将较小的 ProducerRecord 拼凑成一个较大的 ProducerBatch，也可以减少网络请求的次数以提升整体的吞吐量。</li>
</ul>
</li>
</ul>
</li>
<li>broker<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_broker%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="Kafka_broker架构图"></li>
</ul>
</li>
<li>consumer<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Kafka_consumer_%E6%8B%89%E5%8F%96%E6%B6%88%E6%81%AF%E5%8E%9F%E7%90%86.png" alt="Kafka_consumer_拉取消息原理"></li>
</ul>
</li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>为什么要使用 kafka？</strong><ul>
<li>缓冲和削峰</li>
<li>解耦和扩展性</li>
<li>冗余</li>
<li>健壮性</li>
<li>异步通信</li>
</ul>
</li>
<li><strong>Kafka 是如何做到消息不丢失或不重复的？</strong><ul>
<li>生产者数据的不丢失<ul>
<li>要使用带回调方法的 API。</li>
<li>在 kafka 发送数据的时候，每次发送消息都会有一个确认反馈机制，确保消息正常的能够被收到。<ul>
<li>设置参数 acks=-1。</li>
</ul>
</li>
<li>设置参数 retries=3。<ul>
<li>参数 retries 表示生产者生产消息的重试次数。</li>
<li>这里 retries=3 是一个建议值，一般情况下能满足足够的重试次数就能重试成功。但是如果重试失败了，对异常处理时就可以把消息保存到其他可靠的地方，如磁盘、数据库、远程缓存等，然后等到服务正常了再继续发送消息。</li>
</ul>
</li>
<li>设置参数 retry.backoff.ms=300。<ul>
<li>retry.backoff.ms 指消息生产超时或失败后重试的间隔时间，单位是毫秒。</li>
</ul>
</li>
</ul>
</li>
<li>消费者数据的不丢失<ul>
<li>从 kafka 拉取消息下来，由于自动的提交模式已经提交了 offset，但消费者是没有真正消费成功的，并且消费者可能日常发布重启或者挂掉了，那这条消息就丢了。<ul>
<li><strong>如何费者数据的不丢失解决？</strong><ul>
<li>关闭自动提交，改成手动提交，每次数据处理完后，再提交。</li>
</ul>
</li>
</ul>
</li>
<li>kafka 自己记录了每次消费的 offset 数值，下次继续消费的时候，会接着上次的 offset 进行消费。</li>
<li>而 offset 的信息在 kafka0.8 版本之前保存在 zookeeper 中，在 0.8 版本之后保存到 topic 中，即使消费者在运行过程中挂掉了，再次启动的时候会找到 offset 的值，找到之前消费消息的位置，接着消费，由于 offset 的信息写入的时候并不是每条消息消费完成后都写入的，所以这种情况有可能会造成重复消费，但是不会丢失消息。<ul>
<li><strong>如何解决重复消费问题？</strong><ul>
<li>关闭自动提交，改成手动提交，每次数据处理完后，再提交。消费的接口幂等处理。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>broker 的数据不丢失<ul>
<li>每个 broker 中的 partition 我们一般都会设置有 replication（副本）的个数，生产者写入的时候首先根据分发策略（有 partition 按 partition，有 key 按 key，都没有就轮询）写入到 leader 中，follower（副本）再跟 leader 同步数据，这样有了备份，也可以保证消息数据的不丢失。<ul>
<li>设置 replication.factor &gt;1。<ul>
<li>replication.factor 这个参数表示分区副本的个数，这里我们要将其设置为大于 1 的数，这样当 leader 副本挂了，follower 副本还能被选为 leader 副本继续接收消息。</li>
</ul>
</li>
<li>设置 min.insync.replicas &gt;1。<ul>
<li>min.insync.replicas 指的是 ISR 最少的副本数量，原理同上，也需要大于 1 的副本数量来保证消息不丢失。</li>
</ul>
</li>
<li>设置 unclean.leader.election.enable = false。<ul>
<li>unclean.leader.election.enable 指是否能把非 ISR 集合中的副本选举为 leader 副本。unclean.leader.election.enable = true，也就是说允许非 ISR 集合中的 follower 副本成为 leader 副本。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从而实现的是一种主写主读的生产消费模型。</li>
<li>Kafka 并不支持主写从读，因为主写从读有 2 个很明显的缺点：<ul>
<li>数据一致性问题<ul>
<li>数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X，之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。</li>
</ul>
</li>
<li>延时问题<ul>
<li>类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历 <em>网络→主节点内存→网络→从节点内存</em> 这几个阶段，整个过程会耗费一定的时间。而在 Kafka 中，主从同步会比 Redis 更加耗时，它需要经历 <em>网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘</em> 这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</li>
</ul>
</li>
</ul>
</li>
<li>而 kafka 的主写主读的优点就很多了：<ul>
<li>可以简化代码的实现逻辑，减少出错的可能；</li>
<li>将负载粒度细化均摊，与主写从读相比，不仅负载效能更好，而且对用户可控；</li>
<li>没有延时的影响；</li>
<li>在副本稳定的情况下，不会出现数据不一致的情况。</li>
</ul>
</li>
</ul>
</li>
<li><strong>磁盘存储的性能问题</strong><ul>
<li>为了规避随机读写带来的时间消耗，kafka 采用顺序写的方式存储数据。<ul>
<li>磁盘读取时间：<ul>
<li>寻道时间，表示磁头在不同磁道之间移动的时间。</li>
<li>旋转延迟，表示在磁道找到时，中轴带动盘面旋转到合适的扇区开头处。</li>
<li>传输时间，表示盘面继续转动，实际读取数据的时间。</li>
</ul>
</li>
<li>顺序读写，磁盘会预读，预读即在读取的起始地址连续读取多个页面，主要时间花费在了传输时间，而这个时间两种读写可以认为是一样的。</li>
<li>随机读写，因为数据没有在一起，将预读浪费掉了。需要多次寻道和旋转延迟。而这个时间可能是传输时间的许多倍。</li>
</ul>
</li>
<li>零拷贝<ul>
<li>消息从发送到落地保存，broker 维护的消息日志本身就是文件目录，每个文件都是二进制保存，生产者和消费者使用相同的格式来处理。在消费者获取消息时，服务器先从硬盘读取数据到内存，然后把内存中的数据原封不动的通过 socket 发送给消费者。虽然这个操作描述起来很简单，但实际上经历了很多步骤。<ul>
<li>操作系统将数据从磁盘读入到内核空间的页缓存：<ul>
<li>应用程序将数据从内核空间读入到用户空间缓存中</li>
<li>应用程序将数据写回到内核空间到 socket 缓存中</li>
<li>操作系统将数据从 socket 缓冲区复制到网卡缓冲区，以便将数据经网络发出</li>
</ul>
</li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E9%9B%B6%E6%8B%B7%E8%B4%9D_1.jpeg" alt="零拷贝_1"></li>
</ul>
</li>
<li>通过“零拷贝”技术，可以去掉这些没必要的数据复制操作，同时也会减少上下文切换次数。现代的unix操作系统提供一个优化的代码路径，用于将数据从页缓存传输到 socket；在 Linux 中，是通过 sendfile 系统调用来完成的。Java 提供了访问这个系统调用的方法：FileChannel.transferTo API</li>
<li>使用 sendfile，只需要一次拷贝就行，允许操作系统将数据直接从页缓存发送到网络上。所以在这个优化的路径中，只有最后一步将数据拷贝到网卡缓存中是需要的</li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E9%9B%B6%E6%8B%B7%E8%B4%9D_2.jpeg" alt="零拷贝_2"></li>
</ul>
</li>
<li>页缓存<ul>
<li>页缓存是操作系统实现的一种主要的磁盘缓存，但凡设计到缓存的，基本都是为了提升 I/O 性能，所以页缓存是用来减少磁盘 I/O 操作的。</li>
<li>磁盘高速缓存有两个重要因素：<ul>
<li>访问磁盘的速度要远低于访问内存的速度，若从处理器 L1 和 L2 高速缓存访问则速度更快。</li>
<li>数据一旦被访问，就很有可能短时间内再次访问。正是由于基于访问内存比磁盘快的多，所以磁盘的内存缓存将给系统存储性能带来质的飞越。</li>
</ul>
</li>
<li>当一个进程准备读取磁盘上的文件内容时，操作系统会先查看待读取的数据所在的页（page）是否在页缓存（pagecache）中，如果存在（命中）则直接返回数据，从而避免了对物理磁盘的 I/O 操作；如果没有命中，则操作系统会向磁盘发起读取请求并将读取的数据页存入页缓存，之后再将数据返回给进程。</li>
<li>同样，如果一个进程需要将数据写入磁盘，那么操作系统也会检测数据对应的页是否在页缓存中，如果不存在，则会先在页缓存中添加相应的页，最后将数据写入对应的页。被修改过后的页也就变成了脏页，操作系统会在合适的时间把脏页中的数据写入磁盘，以保持数据的一致性。</li>
<li>Kafka 中大量使用了页缓存，这是 Kafka 实现高吞吐的重要因素之一。虽然消息都是先被写入页缓存，然后由操作系统负责具体的刷盘任务的，但在 Kafka 中同样提供了同步刷盘及间断性强制刷盘（fsync）,可以通过 log.flush.interval.messages 和 log.flush.interval.ms 参数来控制。<ul>
<li>同步刷盘能够保证消息的可靠性，避免因为宕机导致页缓存数据还未完成同步时造成的数据丢失。<ul>
<li>但是实际使用上，我们没必要去考虑这样的因素以及这种问题带来的损失，消息可靠性可以由多副本来解决，同步刷盘会带来性能的影响。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>Kafka 为何兵法吞吐量高？</strong><ul>
<li>生产端<ul>
<li>通过消息压缩、消息批量缓存发送、异步解耦等方面提升吞吐量</li>
</ul>
</li>
<li>服务端<ul>
<li>采用的优化技术比较多，比如网络层的 Reactor 设计提升了网络层的吞吐；顺序写、页缓存、零拷贝时利用操作系统的优化点来实现存储层读写的吞吐量</li>
</ul>
</li>
<li>消费端<ul>
<li>通过线程异步解耦的方式提升了拉取消息的效率，进而提升消费者的吞吐量</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Apache RabbitMQ<ul>
<li>概念<ul>
<li>broker：每个节点运行的服务程序，功能为维护该节点的队列的增删以及转发队列操作请求。</li>
<li>master queue：每个队列都分为一个主队列和若干个镜像队列。</li>
<li>mirror queue：镜像队列，作为 master queue 的备份。在 master queue 所在节点挂掉之后，系统把 mirror queue 提升为 master queue，负责处理客户端队列操作请求。注意，mirror queue 只做镜像，设计目的不是为了承担客户端读写压力。</li>
</ul>
</li>
<li>架构<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/RabbitMQ_%E6%9E%B6%E6%9E%84.png" alt="RabbitMQ_架构"></li>
</ul>
</li>
<li>工作流程<ul>
<li>队列消费<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/RabbitMQ_%E9%98%9F%E5%88%97%E6%B6%88%E8%B4%B9.png" alt="RabbitMQ_队列消费"></li>
<li>有两个 consumer 消费队列 A，这两个 consumer 连在了集群的不同机器上。RabbitMQ 集群中的任何一个节点都拥有集群上所有队列的元信息，所以连接到集群中的任何一个节点都可以，主要区别在于有的 consumer 连在 master queue 所在节点，有的连在非 master queue 节点上。</li>
<li>因为 mirror queue 要和 master queue 保持一致，故需要同步机制，正因为一致性的限制，导致所有的读写操作都必须都操作在 master queue 上，然后由 master 节点同步操作到 mirror queue 所在的节点。即使 consumer 连接到了非 master queue 节点，该 consumer 的操作也会被路由到 master queue 所在的节点上，这样才能进行消费。</li>
</ul>
</li>
<li>队列生产<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/RabbitMQ_%E9%98%9F%E5%88%97%E7%94%9F%E4%BA%A7.png" alt="RabbitMQ_队列生产"></li>
<li>原理和消费一样，如果连接到非 master queue 节点，则路由过去。</li>
</ul>
</li>
</ul>
</li>
<li>RabbitMQ 的不足：由于 master queue 单节点，导致性能瓶颈，吞吐量受限。虽然为了提高性能，内部使用了 Erlang 这个语言实现，但是终究摆脱不了架构设计上的致命缺陷。</li>
</ul>
</li>
<li>NSQ</li>
<li>阿里孵化开源的 Apache RocketMQ</li>
<li>ActiveMQ</li>
<li>比较<ul>
<li><table>
<thead>
<tr>
<th align="center">特性</th>
<th align="center">ActiveMQ</th>
<th align="center">RabbitMQ</th>
<th align="center">RocketMQ</th>
<th align="center">Kafka</th>
</tr>
</thead>
<tbody><tr>
<td align="center">单机吞吐量</td>
<td align="center">万级，吞吐量比RocketMQ和Kafka要低了一个数量级</td>
<td align="center">万级，吞吐量比RocketMQ和Kafka要低了一个数量级</td>
<td align="center">10万级，RocketMQ也是可以支撑高吞吐的一种MQ</td>
<td align="center">10万级别，这是kafka最大的优点，就是吞吐量高。一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td>
</tr>
<tr>
<td align="center">topic数量对吞吐量的影响</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降。这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic</td>
<td align="center">topic从几十个到几百个的时候，吞吐量会大幅度下降。所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源</td>
</tr>
<tr>
<td align="center">时效性</td>
<td align="center">ms级</td>
<td align="center">微秒级，这是rabbitmq的一大特点，延迟是最低的</td>
<td align="center">ms级</td>
<td align="center">延迟在ms级以内</td>
</tr>
<tr>
<td align="center">可用性</td>
<td align="center">高，基于主从架构实现高可用性</td>
<td align="center">高，基于主从架构实现高可用性</td>
<td align="center">非常高，分布式架构</td>
<td align="center">非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td>
</tr>
<tr>
<td align="center">功能支持</td>
<td align="center">MQ领域的功能极其完备</td>
<td align="center">基于erlang开发，所以并发能力很强，性能极其好，延时很低</td>
<td align="center">MQ功能较为完善，还是分布式的，扩展性好</td>
<td align="center">功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准</td>
</tr>
<tr>
<td align="center">优劣势总结</td>
<td align="center">非常成熟，功能强大，在业内大量的公司以及项目中都有应用。偶尔会有较低概率丢失消息。而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本，而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用</td>
<td align="center">erlang语言开发，性能极其好，延时很低；吞吐量到万级，MQ功能比较完备；而且开源提供的管理界面非常棒，用起来很好用；社区相对比较活跃，几乎每个月都发布几个版本分；在国内一些互联网公司近几年用rabbitmq也比较多一些；但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。</td>
<td align="center">接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障。日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景，而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控。社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码。还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的</td>
<td align="center">kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展；同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量；而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略，这个特性天然适合大数据实时计算以及日志收集</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="缓存服务"><a href="#缓存服务" class="headerlink" title="缓存服务"></a>缓存服务</h2><ul>
<li>阿里 Tair</li>
<li>业界的 Redis</li>
<li>Memcached</li>
<li>Ehcache</li>
</ul>
<h2 id="配置中心"><a href="#配置中心" class="headerlink" title="配置中心"></a>配置中心</h2><ul>
<li>阿里 Nacos</li>
<li>携程 Apollo</li>
<li>百度 Disconf</li>
</ul>
<h2 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h2><ul>
<li>阿里 seata</li>
<li>腾讯 DTF</li>
</ul>
<h2 id="任务调度"><a href="#任务调度" class="headerlink" title="任务调度"></a>任务调度</h2><ul>
<li>阿里 SchedulerX</li>
<li>业界 xxl-job<ul>
<li>大众点评员工徐雪里于 2015 年发布的分布式任务调度平台，是一个轻量级分布式任务调度框架，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。</li>
<li>架构<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/xxl_job_%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="xxl_job_架构图"></li>
</ul>
</li>
</ul>
</li>
<li>当当 elastic-job<ul>
<li>当当开发的弹性分布式任务调度系统，功能丰富强大，采用 zookeeper 实现分布式协调，实现任务高可用以及分片，并且可以支持云开发，由两个相互独立的子项目 Elastic-Job-Lite 和 Elastic-Job-Cloud 组成。基于 Quartz ⼆次开发的。</li>
</ul>
</li>
<li>有赞 TSP</li>
</ul>
<h2 id="数据库层"><a href="#数据库层" class="headerlink" title="数据库层"></a>数据库层</h2><ul>
<li>用于支持弹性扩容和分库分表的 TDDL</li>
<li>数据库连接池 Driud</li>
<li>Binlog 同步的 Canal<ul>
<li>Canal 是阿里巴巴旗下的一款开源项目，纯 Java 开发。基于数据库增量日志解析，提供增量数据订阅&amp;消费，目前主要支持了 MySQL（也支持 MariaDB）。</li>
</ul>
</li>
<li>Mycat<ul>
<li>相关问题<ul>
<li><strong>Sharding-JDBC 和 Mycat 的区别？</strong><ul>
<li>工作层次：Sharding-JDBC 实现了 JDBC 协议，工作在 JDBC 层；Mycat 可以当做一个 MySQL 数据库使用，其实就是在 Proxy 层的。</li>
<li>运行方式：Sharding-JDBC 只需要在工程中导入一个 Sharding-JDBC 的 jar 包，然后在配置文件中配置相应的数据源和分片策略即可；Mycat 则是需要单独提供一个端口为 8066 的服务，然后在 Mycat 的配置文件中配置相关的数据源和分片策略。</li>
<li>开发方式：Sharding-JDBC 只需要在配置文件中进行配置即可使用；Mycat 需要在其配置文件中修改数据源等一系列参数。</li>
<li>运维成本：Sharding-JDBC 的运维成本低，java 开发人员的维护成本高；Mycat 运维成本高，得配置 Mycat 的一系列参数以及高可用负载均衡的配置，需要一定的运维实力。</li>
<li>支持的语言：Sharding-JDBC 只支持 java 语言；Mycat 支持实现了 JDBC 规范的语言。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul>
<li>Zookeeper<ul>
<li>Zookeeper 是一个开源的分布式协调服务，由雅虎公司创建，由于最初雅虎公司的内部研究小组的项目大多以动物的名字命名，所以后来就以 Zookeeper（动物管理员）来命名了，而就是由 Zookeeper 来负责这些分布式组件环境的协调工作。</li>
<li>可以用 ZooKeeper 来做：统一配置管理、统一命名服务、分布式锁、集群管理。</li>
<li>ZooKeeper 的数据结构，跟 Unix 文件系统非常类似，可以看做是一颗树，每个节点叫做 ZNode。每一个节点可以通过路径来标识<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/ZooKeeper_%E7%BB%93%E6%9E%84%E5%9B%BE.jpg" alt="ZooKeeper_结构图"></li>
<li>Znode 类型：<ul>
<li>短暂/临时（Ephemeral）<ul>
<li>当客户端和服务端断开连接后，所创建的 Znode（节点）会自动删除</li>
</ul>
</li>
<li>持久（Persistent）<ul>
<li>当客户端和服务端断开连接后，所创建的 Znode（节点）不会删除</li>
</ul>
</li>
<li>临时顺序<ul>
<li>ZK 会自动在这两种节点之后增加一个数字的后缀，而路径 + 数字后缀是能保证唯一的，这数字后缀的应用场景可以实现诸如分布式队列，分布式公平锁等。</li>
</ul>
</li>
<li>持久顺序<ul>
<li>ZK 会自动在这两种节点之后增加一个数字的后缀，而路径 + 数字后缀是能保证唯一的，这数字后缀的应用场景可以实现诸如分布式队列，分布式公平锁等。</li>
</ul>
</li>
<li>容器<ul>
<li>容器节点是 3.5 以后新增的节点类型，只要在调用 create 方法时，指定 CreateMode 为 CONTAINER 即可创建容器的节点类型，容器节点的表现形式和持久节点是一样的，但是区别是 ZK 服务端启动后，会有一个单独的线程去扫描，所有的容器节点，当发现容器节点的子节点数量为 0 时，会自动删除该节点，除此之外和持久节点没有区别，官方注释给出的使用场景是 Container nodes are special purpose nodes useful for recipes such as leader, lock, etc. 说可以用在 leader 或者锁的场景中。</li>
</ul>
</li>
<li>持久 TTL、持久顺序 TTL<ul>
<li>带有存活时间。就是当该节点下面没有子节点的话，超过了 TTL 指定时间后就会被自动删除，特性跟上面的容器节点很像，只是容器节点没有超时时间而已，但是 TTL 启用是需要额外的配置（这个之前也有提过）配置是 zookeeper.extendedTypesEnabled 需要配置成 true，否则的话创建 TTL 时会收到 Unimplemented 的报错</li>
</ul>
</li>
</ul>
</li>
<li>ACL（access control list 访问控制列表）<ul>
<li>zookeeper 在分布式系统中承担中间件的作用，它管理的每一个节点上都可能存储着重要的信息，因为应用可以读取到任意节点，这就可能造成安全问题，ACL 的作用就是帮助 zookeeper 实现权限控制。</li>
<li>zookeeper 的权限控制基于节点，每个 znode 可以有不同的权限。</li>
<li>子节点不会继承父节点的权限，访问不了该节点，并不代表访问不到其子节点。</li>
<li>Schema: 鉴权策略<ul>
<li>world<ul>
<li>默认方式，相当于全世界都能访问</li>
</ul>
</li>
<li>digest<ul>
<li>即: “用户名+密码” 这种认证方式，也是业务中常用的</li>
</ul>
</li>
<li>ip<ul>
<li>使用 IP 认证的方式</li>
</ul>
</li>
<li>auth<ul>
<li>代表已经认证通过的用户（cli 中可以通过 addauth digest user:pwd 来添加当前上下文中的授权用户）</li>
</ul>
</li>
</ul>
</li>
<li>授权对象<ul>
<li>world<ul>
<li>只有一个 ID：“anyone”</li>
</ul>
</li>
<li>digest<ul>
<li>自定义，通常是用户名:密码，在 ACl 中使用时，表达式将是 username：base64 编码的 SHA1.例如”admin:u53OoA8hprX59uwFsvQBS3QuI00=”（明文密码为123456）</li>
</ul>
</li>
<li>ip<ul>
<li>通常是一个 Ip 地址或者是 Ip 段, 例如 192.168.xxx.xxx 或者 192.168.xxx.xxx/xxx</li>
</ul>
</li>
<li>super<ul>
<li>与 digest 模式一样</li>
</ul>
</li>
</ul>
</li>
<li>权限<ul>
<li>create<ul>
<li>创建权限，授予权限的对象可以在数据节点下创建子节点；</li>
</ul>
</li>
<li>read<ul>
<li>读取权限，授予权限的对象可以读取该节点的内容以及子节点的信息；</li>
</ul>
</li>
<li>write<ul>
<li>更新权限，授予权限的对象可以更新该数据节点；</li>
</ul>
</li>
<li>delete<ul>
<li>删除权限，授予权限的对象可以删除该数据节点的子节点；</li>
</ul>
</li>
<li>admin<ul>
<li>管理者权限，授予权限的对象可以对该数据节点体进行 ACL 权限设置。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>集群<ul>
<li>角色介绍<ul>
<li>Leader<ul>
<li>Leader 不直接接受 client 的请求，但接受由其他 Follower 和 Observer 转发过来的 Client 请求，此外，Leader 还负责投票的发起和决议，即时更新状态和数据。</li>
</ul>
</li>
<li>Follower<ul>
<li>Follower 角色接受客户端请求并返回结果，参与 Leader 发起的投票和选举，但不具有写操作的权限。</li>
</ul>
</li>
<li>Observer<ul>
<li>Observer 角色接受客户端连接，将写操作转给 Leader，但 Observer 不参与投票（即不参加一致性协议的达成），只同步 Leader 节点的状态，Observer 角色是为集群系统扩展而生的。</li>
</ul>
</li>
</ul>
</li>
<li>ZAB（Zookeeper Atomic BroadCast）原子广播协议<ul>
<li>在 zookeeper 中，只有一台服务器机器作为 leader 机器，所以当客户端链接到机器的某一个节点时<ul>
<li>当这个客户端提交的是读取数据请求，那么当前连接的机器节点，就会把自己保存的数据返回出去。</li>
<li>当这个客户端提交的是写数据请求时，首先会看当前连接的节点是不是 leader 节点，如果不是 leader 节点则会转发出去到 leader 机器的节点上，由 leader 机器写入，然后广播出去通知其他的节点过来同步数据</li>
</ul>
</li>
<li>在 ZAB 中的三个重点数据<ul>
<li>Zxid：是 zookeeper 中的事务 ID，总长度为 64 位的长度的 Long 类型数据。其中有两部分构成前 32 位是 epoch 后 32 位是 xid</li>
<li>Epoch：每一个 leader 都会有一个这个值，表示当前 leader 获取到的最大 N 值，可以理解为“年代”</li>
<li>Xid：事务 ID，表示当前 zookeeper 集群当前提交的事物 ID 是多少（watch 机制），方便选举的过程后不会出现事务重复执行或者遗漏等一些特殊情况。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>监听器<ul>
<li>常见的监听场景有以下两项：<ul>
<li>监听 Znode 节点的数据变化</li>
<li>监听子节点的增减变化</li>
</ul>
</li>
</ul>
</li>
<li>用途<ul>
<li>统一配置管理<ul>
<li>问题描述<ul>
<li>比如我们现在有三个系统 A、B、C，他们有三份配置，分别是 ASystem.yml、BSystem.yml、CSystem.yml，然后，这三份配置又非常类似，很多的配置项几乎都一样。</li>
<li>此时，如果我们要改变其中一份配置项的信息，很可能其他两份都要改。并且，改变了配置项的信息很可能就要重启系统</li>
<li>于是，我们希望把 ASystem.yml、BSystem.yml、CSystem.yml 相同的配置项抽取出来成一份公用的配置 common.yml，并且即便 common.yml 改了，也不需要系统 A、B、C 重启。</li>
</ul>
</li>
<li>做法<ul>
<li>我们可以将 common.yml 这份配置放在 ZooKeeper 的 Znode 节点中，系统 A、B、C 监听着这个 Znode 节点有无变更，如果变更了，及时响应。</li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/ZooKeeper_%E7%BB%9F%E4%B8%80%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86.jpg" alt="ZooKeeper_统一配置管理"></li>
</ul>
</li>
</ul>
</li>
<li>统一命名服务<ul>
<li>问题描述<ul>
<li>统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取一个名字，别人通过这个名字就可以拿到对应的资源。</li>
<li>比如说，现在我有一个域名 <a href="http://www.java3y.com，但我这个域名下有多台机器：">www.java3y.com，但我这个域名下有多台机器：</a><ul>
<li>192.168.1.1、192.168.1.2、192.168.1.3、192.168.1.4</li>
</ul>
</li>
<li>别人访问 <a target="_blank" rel="noopener" href="http://www.java3y.com/">www.java3y.com</a> 即可访问到我的机器，而不是通过 IP 去访问。</li>
</ul>
</li>
<li>做法<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/ZooKeeper_%E7%BB%9F%E4%B8%80%E5%91%BD%E5%90%8D%E6%9C%8D%E5%8A%A1.jpg" alt="ZooKeeper_统一命名服务"></li>
</ul>
</li>
</ul>
</li>
<li>分布式锁<ul>
<li>做法<ul>
<li>系统 A、B、C 都去访问 /locks 节点</li>
<li>访问的时候会创建带顺序号的临时/短暂（EPHEMERAL_SEQUENTIAL）节点，比如，系统 A 创建了 id_000000 节点，系统 B 创建了 id_000002 节点，系统 C 创建了 id_000001 节点。</li>
<li>接着，拿到 /locks 节点下的所有子节点（id_000000,id_000001,id_000002），判断自己创建的是不是最小的那个节点<ul>
<li>如果是，则拿到锁。<ul>
<li>释放锁：执行完操作后，把创建的节点给删掉</li>
</ul>
</li>
<li>如果不是，则监听比自己要小 1 的节点变化</li>
</ul>
</li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/ZooKeeper_%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.jpg" alt="ZooKeeper_分布式锁"></li>
</ul>
</li>
<li>例子<ul>
<li>系统 A 拿到 /locks 节点下的所有子节点，经过比较，发现自己（id_000000），是所有子节点最小的。所以得到锁。</li>
<li>系统 B 拿到 /locks 节点下的所有子节点，经过比较，发现自己（id_000002），不是所有子节点最小的。所以监听比自己小 1 的节点 id_000001 的状态。</li>
<li>系统 C 拿到 /locks 节点下的所有子节点，经过比较，发现自己（id_000001），不是所有子节点最小的。所以监听比自己小 1 的节点 id_000000 的状态。</li>
<li>等到系统 A 执行完操作以后，将自己创建的节点删除（id_000000）。通过监听，系统 C 发现 id_000000 节点已经删除了，发现自己已经是最小的节点了，于是顺利拿到锁。</li>
</ul>
</li>
</ul>
</li>
<li>集群状态<ul>
<li>做法<ul>
<li>三个系统 A、B、C，在 ZooKeeper 中创建临时节点</li>
<li>只要系统 A 挂了，那 /groupMember/A 这个节点就会删除，通过监听 groupMember 下的子节点，系统 B 和 C 就能够感知到系统 A 已经挂了。</li>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/ZooKeeper_%E9%9B%86%E7%BE%A4%E7%8A%B6%E6%80%81.jpg" alt="ZooKeeper_集群状态"></li>
</ul>
</li>
<li>除了能够感知节点的上下线变化，ZooKeeper 还可以实现动态选举 Master 的功能。<ul>
<li>如果想要实现动态选举 Master 的功能，Znode 节点的类型是带顺序号的临时节点（EPHEMERAL_SEQUENTIAL）就好了。</li>
<li>Zookeeper 会每次选举最小编号的作为 Master，如果 Master 挂了，自然对应的 Znode 节点就会删除。然后让新的最小编号作为 Master，这样就可以实现动态选举的功能了。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>说说 Watcher 监听机制和它的原理？</strong><ul>
<li>Zookeeper 可以提供分布式数据的发布/订阅功能，依赖的就是 Watcher 监听机制。</li>
<li>客户端可以向服务端注册 Watcher 监听，服务端的指定事件触发之后，就会向客户端发送一个事件通知。</li>
<li>特性：<ul>
<li>一次性：一旦一个 Watcher 触发之后，Zookeeper 就会将它从存储中移除</li>
<li>客户端串行：客户端的 Watcher 回调处理是串行同步的过程，不要因为一个 Watcher 的逻辑阻塞整个客户端</li>
<li>轻量：Watcher 通知的单位是 WatchedEvent，只包含通知状态、事件类型和节点路径，不包含具体的事件内容，具体的时间内容需要客户端主动去重新获取数据</li>
</ul>
</li>
<li>流程<ul>
<li>客户端向服务端注册 Watcher 监听</li>
<li>保存 Watcher 对象到客户端本地的 WatcherManager 中</li>
<li>服务端 Watcher 事件触发后，客户端收到服务端通知，从 WatcherManager 中取出对应 Watcher 对象执行回调逻辑</li>
</ul>
</li>
</ul>
</li>
<li><strong>Zookeeper 是如何保证数据一致性的？</strong><ul>
<li>Zookeeper 通过 ZAB 原子广播协议来实现数据的最终顺序一致性，他是一个类似 2PC 两阶段提交的过程。</li>
<li>由于 Zookeeper 只有 Leader 节点可以写入数据，如果是其他节点收到写入数据的请求，则会将之转发给 Leader 节点。</li>
<li>主要流程：<ol>
<li>Leader 收到请求之后，将它转换为一个 proposal 提议，并且为每个提议分配一个全局唯一递增的事务 ID：zxid，然后把提议放入到一个 FIFO 的队列中，按照 FIFO 的策略发送给所有的 Follower</li>
<li>Follower 收到提议之后，以事务日志的形式写入到本地磁盘中，写入成功后返回 ACK 给 Leader</li>
<li>Leader 在收到超过半数的 Follower 的 ACK 之后，即可认为数据写入成功，就会发送 commit 命令给 Follower 告诉他们可以提交 proposal 了</li>
</ol>
<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/ZooKeeper_%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5.jpg" alt="ZooKeeper_数据同步"></li>
</ul>
</li>
<li>ZAB 包含两种基本模式，崩溃恢复和消息广播<ul>
<li>整个集群服务在启动、网络中断或者重启等异常情况的时候，首先会进入到崩溃恢复状态，此时会通过选举产生 Leader 节点，当集群过半的节点都和 Leader 状态同步之后，ZAB 就会退出恢复模式。之后，就会进入消息广播的模式。</li>
</ul>
</li>
</ul>
</li>
<li><strong>Zookeeper 如何进行 Leader 选举的？</strong><ul>
<li>Leader 的选举可以分为两个方面，同时选举主要包含事务 zxid 和 myid，节点主要包含 LEADING\FOLLOWING\LOOKING 3个状态。</li>
<li>不同时期选举<ul>
<li>服务启动期间的选举<ul>
<li>过程<ol>
<li>首先，每个节点都会对自己进行投票，然后把投票信息广播给集群中的其他节点</li>
<li>节点接收到其他节点的投票信息，然后和自己的投票进行比较，首先 zxid 较大的优先，如果 zxid 相同那么则会去选择 myid 更大者，此时大家都是 LOOKING 的状态</li>
<li>投票完成之后，开始统计投票信息，如果集群中过半的机器都选择了某个节点机器作为 leader，那么选举结束</li>
<li>最后，更新各个节点的状态，leader 改为 LEADING 状态，follower 改为 FOLLOWING 状态</li>
</ol>
</li>
</ul>
</li>
<li>服务运行期间的选举<ul>
<li>如果开始选举出来的 leader 节点宕机了，那么运行期间就会重新进行 leader 的选举。</li>
</ul>
<ol>
<li>leader 宕机之后，非 observer 节点都会把自己的状态修改为 LOOKING 状态，然后重新进入选举流程</li>
<li>生成投票信息（myid,zxid），同样，第一轮的投票大家都会把票投给自己，然后把投票信息广播出去</li>
<li>接下来的流程和上面的选举是一样的，都会优先以 zxid，然后选择 myid，最后统计投票信息，修改节点状态，选举结束</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>选举之后又是怎样进行数据同步的？</strong><ul>
<li>实际上 Zookeeper 在选举之后，Follower 和 Observer（统称为 Learner）就会去向 Leader 注册，然后就会开始数据同步的过程。</li>
<li>数据同步包含 3 个主要值和 4 种形式。</li>
<li>3 个主要值<ul>
<li>PeerLastZxid：Learner 服务器最后处理的 ZXID</li>
<li>minCommittedLog：Leader 提议缓存队列中最小 ZXID</li>
<li>maxCommittedLog：Leader 提议缓存队列中最大 ZXID</li>
</ul>
</li>
<li>4 种形式<ul>
<li>直接差异化同步（DIFF 同步）<ul>
<li>流程<ol>
<li>首先 Leader 向 Learner 发送 DIFF 指令，代表开始差异化同步，然后把差异数据（从 PeerLastZxid 到 maxCommittedLog 之间的数据）提议 proposal 发送给 Learner</li>
<li>发送完成之后发送一个 NEWLEADER 命令给 Learner，同时 Learner 返回 ACK 表示已经完成了同步</li>
<li>接着等待集群中过半的 Learner 响应了 ACK 之后，就发送一个 UPTODATE 命令，Learner 返回 ACK，同步流程结束</li>
</ol>
<ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/ZooKeeper_%E5%B7%AE%E5%BC%82%E5%8C%96%E5%90%8C%E6%AD%A5.jpg" alt="ZooKeeper_差异化同步"></li>
</ul>
</li>
</ul>
</li>
<li>先回滚再差异化同步（TRUNC+DIFF 同步）<ul>
<li>问题描述<ul>
<li>如果 Leader 刚生成一个 proposal，还没有来得及发送出去，此时 Leader 宕机，重新选举之后作为 Follower，但是新的 Leader 没有这个 proposal 数据。</li>
</ul>
</li>
<li>例子<ul>
<li>假设现在的 Leader 是 A，minCommittedLog=1，maxCommittedLog=3，刚好生成的一个 proposal 的 ZXID=4，然后挂了。</li>
<li>重新选举出来的 Leader 是 B，B 之后又处理了 2 个提议，然后 minCommittedLog=1，maxCommittedLog=5。</li>
<li>这时候A的 PeerLastZxid=4，在（1,5）之间。</li>
</ul>
</li>
<li>处理方式<ul>
<li>A 要进行事务回滚，相当于抛弃这条数据，并且回滚到最接近于 PeerLastZxid 的事务，对于 A 来说，也就是 PeerLastZxid=3。</li>
</ul>
</li>
<li>流程<ul>
<li>流程和 DIFF 一致，只是会先发送一个 TRUNC 命令，然后再执行差异化 DIFF 同步。</li>
</ul>
</li>
</ul>
</li>
<li>仅回滚同步（TRUNC 同步）<ul>
<li>针对 PeerLastZxid 大于 maxCommittedLog 的场景，流程和上述一致，事务将会被回滚到 maxCommittedLog 的记录。</li>
<li>例子<ul>
<li>可以认为 TRUNC+DIFF 中的例子，新的 Leader B没有处理提议，所以 B 中 minCommittedLog=1，maxCommittedLog=3。</li>
<li>所以 A 的 PeerLastZxid=4 就会大于 maxCommittedLog 了，也就是 A 只需要回滚就行了，不需要执行差异化同步 DIFF 了。</li>
</ul>
</li>
</ul>
</li>
<li>全量同步（SNAP 同步）<ul>
<li>适用于两个场景：<ul>
<li>PeerLastZxid 小于 minCommittedLog</li>
<li>Leader 服务器上没有提议缓存队列，并且 PeerLastZxid 不等于 Leader 的最大 ZXID</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>有可能会出现数据不一致的问题吗？</strong><ul>
<li>查询不一致<ul>
<li>因为 Zookeeper 是过半成功即代表成功，假设我们有 5 个节点，如果 123 节点写入成功，如果这时候请求访问到 4 或者 5 节点，那么有可能读取不到数据，因为可能数据还没有同步到 4、5 节点中，也可以认为这算是数据不一致的问题。</li>
<li>解决方案可以在读取前使用 sync 命令。</li>
</ul>
</li>
<li>leader 未发送 proposal 宕机<ul>
<li>这也就是数据同步说过的问题。</li>
<li>leader 刚生成一个 proposal，还没有来得及发送出去，此时 leader 宕机，重新选举之后作为 follower，但是新的 leader 没有这个 proposal。</li>
<li>这种场景下的日志将会被丢弃。</li>
</ul>
</li>
<li>leader 发送 proposal 成功，发送 commit 前宕机<ul>
<li>如果发送 proposal 成功了，但是在将要发送 commit 命令前宕机了，如果重新进行选举，还是会选择 zxid 最大的节点作为 leader，因此，这个日志并不会被丢弃，会在选举出 leader 之后重新同步到其他节点当中。</li>
</ul>
</li>
</ul>
</li>
<li><strong>如果作为注册中心，Zookeeper 和 Eureka、Consul、Nacos 有什么区别？</strong><ul>
<li><img src="/2019/09/01/%E5%B7%A5%E5%85%B7/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/ZooKeeper_%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E5%8C%BA%E5%88%AB.jpg" alt="ZooKeeper_注册中心区别"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/01/%E7%B3%BB%E7%BB%9F%E3%80%81%E6%9C%8D%E5%8A%A1%E5%99%A8/%E6%9C%8D%E5%8A%A1%E5%99%A8/%E6%9C%8D%E5%8A%A1%E5%99%A8-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/01/%E7%B3%BB%E7%BB%9F%E3%80%81%E6%9C%8D%E5%8A%A1%E5%99%A8/%E6%9C%8D%E5%8A%A1%E5%99%A8/%E6%9C%8D%E5%8A%A1%E5%99%A8-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">服务器-0-知识点汇总.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-01 09:15:30" itemprop="dateCreated datePublished" datetime="2019-09-01T09:15:30+08:00">2019-09-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%8D%E5%8A%A1%E5%99%A8/" itemprop="url" rel="index"><span itemprop="name">服务器</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Web-服务器"><a href="#Web-服务器" class="headerlink" title="Web 服务器"></a>Web 服务器</h2><h3 id="Servlet-服务器"><a href="#Servlet-服务器" class="headerlink" title="Servlet 服务器"></a>Servlet 服务器</h3><ul>
<li>Tomcat</li>
<li>Jetty<ul>
<li>基于 netty 实现的服务端 Nio MVC 业务开发平台，提供性能监控、日志分析、动态扩展的功能。</li>
<li>Jetty 更轻量级<ul>
<li>由于 Tomcat 除了遵循 Java Servlet 规范之外，自身还扩展了大量 JEE 特性以满足企业级应用的需求，所以 Tomcat 是较重量级的，而且配置较 Jetty 亦复杂许多。但对于大量普通互联网应用而言，并不需要用到 Tomcat 其他高级特性，所以在这种情况下，使用 Tomcat 是很浪费资源的。这种劣势放在分布式环境下，更是明显。换成 Jetty，每个应用服务器省下那几兆内存，对于大的分布式环境则是节省大量资源。而且，Jetty 的轻量级也使其在处理高并发细粒度请求的场景下显得更快速高效。</li>
</ul>
</li>
<li>Jetty 更灵活<ul>
<li>体现在其可插拔性和可扩展性，更易于开发者对 Jetty 本身进行二次开发，定制一个适合自身需求的 Web Server。</li>
</ul>
</li>
</ul>
</li>
<li>JBoss<ul>
<li>JBoss 是一个管理 EJB 的容器和服务器，但 JBoss 核心服务不包括支持 servlet/JSP 的 WEB 容器，一般与 Tomcat 或 Jetty 绑定使用。</li>
</ul>
</li>
</ul>
<h3 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h3><ul>
<li>是一个 web 服务器和反响代理服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。</li>
<li>限流<ul>
<li>Nginx 的限流都是基于漏桶流算法<ul>
<li>突发流量会进入到一个漏桶，漏桶会按照我们定义的速率依次处理请求，如果水流过大也就是突发流量过大就会直接溢出，则多余的请求会被拒绝。所以漏桶算法能控制数据的传输速率。</li>
</ul>
</li>
<li>限流有 3 种<ul>
<li>正常限制访问频率（正常流量）<ul>
<li>限制一个用户发送的请求，Nginx 多久接收一个请求。</li>
<li>Nginx 中使用 ngx_http_limit_req_module 模块来限制的访问频率，限制的原理实质是基于漏桶算法原理来实现的。在 nginx.conf 配置文件中可以使用 limit_req_zone 命令及 limit_req 命令限制单个IP的请求处理频率。</li>
<li>1r/s 代表 1 秒一个请求，1r/m 一分钟接收一个请求， 如果 Nginx 这时还有别人的请求没有处理完，Nginx 就会拒绝处理该用户请求。</li>
</ul>
</li>
<li>突发限制访问频率（突发流量）<ul>
<li>限制一个用户发送的请求，Nginx 多久接收一个</li>
<li>上面的配置一定程度可以限制访问频率，但是也存在着一个问题：如果突发流量超出请求被拒绝处理，无法处理活动时候的突发流量，这时候应该如何进一步处理呢？Nginx 提供 burst 参数结合 nodelay 参数可以解决流量突发的问题，可以设置能处理的超过设置的请求数外能额外处理的请求数。</li>
<li>为什么就多了一个 burst=5 nodelay; 呢，多了这个可以代表 Nginx 对于一个用户的请求会立即处理前五个，多余的就慢慢来落，没有其他用户的请求我就处理你的，有其他的请求的话我 Nginx 就漏掉不接受你的请求</li>
</ul>
</li>
<li>限制并发连接数<ul>
<li>Nginx 中的 ngx_http_limit_conn_module 模块提供了限制并发连接数的功能，可以使用 limit_conn_zone 指令以及 limit_conn 执行进行配置。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>负载均衡<ul>
<li>轮询（默认）<ul>
<li>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某个服务器宕机，能自动剔除故障系统。</li>
</ul>
</li>
<li>权重 weight<ul>
<li>weight 的值越大分配到的访问概率越高，主要用于后端每台服务器性能不均衡的情况下。其次是为在主从的情况下设置不同的权值，达到合理有效的地利用主机资源。</li>
</ul>
</li>
<li>ip_hash<ul>
<li>每个请求按访问 IP 的哈希结果分配，使来自同一个 IP 的访客固定访问一台后端服务器，并且可以有效解决动态网页存在的 session 共享问题</li>
</ul>
</li>
<li>fair（第三方插件）<ul>
<li>必须安装 upstream_fair 模块</li>
<li>对比 weight、ip_hash 更加智能的负载均衡算法，fair 算法可以根据页面大小和加载时间长短智能地进行负载均衡，响应时间短的优先分配。哪个服务器的响应速度快，就将请求分配到那个服务器上。</li>
</ul>
</li>
<li>url_hash（第三方插件）<ul>
<li>必须安装 Nginx 的 hash 软件包</li>
<li>按访问 url 的 hash 结果来分配请求，使每个 url 定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。</li>
</ul>
</li>
</ul>
</li>
<li>问题<ul>
<li><strong>为什么要用 Nginx？</strong><ul>
<li>跨平台、配置简单、方向代理、高并发连接：处理 2-3 万并发连接数，官方监测能支持 5 万并发，内存消耗小：开启 10 个 Nginx 才占 150M 内存 ，Nginx 处理静态文件好，耗费内存少。</li>
<li>而且 Nginx 内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。</li>
<li>使用 Nginx 的话还能：<ul>
<li>节省宽带：支持 GZIP 压缩，可以添加浏览器本地缓存</li>
<li>稳定性高：宕机的概率非常小</li>
<li>接收用户请求是异步的</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">操作系统-0-知识点汇总.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-01 09:15:30" itemprop="dateCreated datePublished" datetime="2019-09-01T09:15:30+08:00">2019-09-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" itemprop="url" rel="index"><span itemprop="name">操作系统</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li>进程管理<ul>
<li>进程和线程<ul>
<li>进程<ul>
<li>进程是具有一定功能的程序关于某个数据集合上的一次运行活动，进程是系统进行资源调度和分配的一个独立单位。</li>
<li>进程的通信方式<ul>
<li>管道<ul>
<li>管道是一种半双工的通信方式，数据只能单项流动，并且只能在具有亲缘关系的进程间流动，进程的亲缘关系通常是父子进程</li>
<li>分类<ul>
<li>普通管道 PIPE</li>
<li>流管道（s_pipe）</li>
<li>命名管道（name_pipe）<ul>
<li>命名管道也是半双工的通信方式，它允许无亲缘关系的进程间进行通信</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>系统 IPC（包括消息队列、信号量、共享存储）<ul>
<li>信号量是一个计数器，用来控制多个进程对资源的访问，它通常作为一种锁机制。</li>
<li>消息队列是消息的链表，存放在内核中并由消息队列标识符标识。</li>
<li>信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。</li>
<li>共享内存就是映射一段能被其它进程访问的内存，这段共享内存由一个进程创建，但是多个进程可以访问。</li>
</ul>
</li>
<li>SOCKET</li>
</ul>
</li>
<li>进程同步机制<ul>
<li>原子操作</li>
<li>信号量机制</li>
<li>自旋锁管程</li>
<li>会合</li>
<li>分布式系统</li>
</ul>
</li>
<li>进程调度策略<ul>
<li>FCFS（先来先服务）<ul>
<li>该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用 FCFS 算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。</li>
</ul>
</li>
<li>优先级<ul>
<li>短作业（进程）优先调度算法<ul>
<li>短作业（进程）优先调度算法 SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先（SJF）的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先（SPF）调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。</li>
</ul>
</li>
<li>高优先权优先调度算法<ul>
<li>优先权调度算法的类型<ul>
<li>非抢占式优先权算法<ul>
<li>在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。</li>
</ul>
</li>
<li>抢占式优先权调度算法<ul>
<li>在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程（原优先权最高的进程）的执行，重新将处理机分配给新到的优先权最高的进程。</li>
</ul>
</li>
</ul>
</li>
<li>高响应比优先调度算法<ul>
<li>在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行得不到保证。如果我们能为每个作业引入动态优先权，并使作业的优先级随着等待时间的增加而以速率 a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>时间片轮转<ul>
<li>在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。</li>
</ul>
</li>
<li>多级反馈<ul>
<li>前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。</li>
<li>实施过程<ul>
<li>应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第 i+1 个队列的时间片要比第 i 个队列的时间片长一倍。</li>
<li>当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业（进程）从第一队列依次降到第 n 队列后，在第 n 队列便采取按时间片轮转的方式运行。</li>
<li>仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1～(i-1) 队列均空时，才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时，又有新进程进入优先权较高的队列（第 1～(i-1) 中的任何一个队列），则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第 i 队列的末尾，把处理机分配给新到的高优先权进程。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>进程的 5 种状态及转换过程<ul>
<li><img src="/2019/09/01/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E8%BF%9B%E7%A8%8B%E4%BA%94%E6%80%81%E6%A8%A1%E5%9E%8B.jpg" alt="进程五态模型"></li>
<li>就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源</li>
<li>运行状态：占用处理机资源运行，处于此状态的进程数小于等于 CPU 数</li>
<li>阻塞状态：进程等待某种条件，在条件满足之前无法执行</li>
</ul>
</li>
</ul>
</li>
<li>线程<ul>
<li>线程是进程的实体，是 CPU 调度和分派的基本单位，它是比进程更小的能独立运行的基本单位。</li>
<li>线程同步的方式<ul>
<li>互斥量（CMutex）<ul>
<li>采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。</li>
</ul>
</li>
<li>信号量（CSemphore）<ul>
<li>它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。</li>
</ul>
</li>
<li>事件（信号）<ul>
<li>通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>线程与进程的区别</strong><ul>
<li>因为进程拥有独立的堆栈空间和数据段，所以每当启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这对于多进程来说十分“奢侈”，系统开销比较大，而线程不一样，线程拥有独立的堆栈空间，但是共享数据段，它们彼此之间使用相同的地址空间，共享大部分数据，比进程更节俭，开销比较小，切换速度也比进程快，效率高，但是正由于进程之间独立的特点，使得进程安全性比较高，也因为进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。一个线程死掉就等于整个进程死掉。</li>
<li>体现在通信机制上面，正因为进程之间互不干扰，相互独立，进程的通信机制相对很复杂，譬如管道，信号，消息队列，共享内存，套接字等通信机制，而线程由于共享数据段所以通信机制很方便。</li>
<li>体现在 CPU 系统上面，线程使得 CPU 系统更加有效，因为操作系统会保证当线程数不大于 CPU 数目时，不同的线程运行于不同的 CPU 上。</li>
<li>体现在程序结构上，举一个简明易懂的列子：当我们使用进程的时候，我们不自主的使用 if else 嵌套来判断 pid，使得程序结构繁琐，但是当我们使用线程的时候，基本上可以甩掉它，当然程序内部执行功能单元需要使用的时候还是要使用，所以线程对程序结构的改善有很大帮助。</li>
</ul>
</li>
</ul>
</li>
<li>同步和互斥<ul>
<li>同步是多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入阻塞态；</li>
<li>互斥是多个进程在同一时刻只有一个进程能进入临界区。</li>
</ul>
</li>
<li>饥饿与死锁<ul>
<li>饥饿<ul>
<li>指一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行的状态；</li>
</ul>
</li>
<li>死锁<ul>
<li>指两个或两个以上的进程/线程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。</li>
<li>产生的四个条件（有一个条件不成立，则不会产生死锁）<ul>
<li>互斥条件<ul>
<li>一个资源一次只能被一个进程使用</li>
</ul>
</li>
<li>请求与保持条件<ul>
<li>一个进程因请求资源而阻塞时，对已获得资源保持不放</li>
</ul>
</li>
<li>不剥夺条件<ul>
<li>进程获得的资源，在未完全使用完之前，不能强行剥夺</li>
</ul>
</li>
<li>循环等待条件<ul>
<li>若干进程之间形成一种头尾相接的环形等待资源关系</li>
</ul>
</li>
</ul>
</li>
<li>解决死锁的基本方法<ul>
<li>预防死锁<ul>
<li>资源一次性分配：（破坏请求和保持条件）</li>
<li>可剥夺资源：即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）</li>
<li>资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）</li>
</ul>
</li>
<li>避免死锁<ul>
<li>预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。<ul>
<li>银行家算法如何解题？<ul>
<li>列出各个资源的剩余情况，再列出各个进程完成需要的资源情况，最后根据前两种情况判断哪个进程可以执行完，执行完进程后会释放资源，再重复以上步骤即可。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>检测死锁<ul>
<li>首先为每个进程和每个资源指定一个唯一的号码；然后建立资源分配表和进程等待表。</li>
</ul>
</li>
<li>解除死锁<ul>
<li>当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有：<ul>
<li>剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；</li>
<li>撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>解决死锁的常用策略<ul>
<li>鸵鸟策略、预防策略、避免策略、检测与解除死锁</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>内存管理<ul>
<li>分页和分段<ul>
<li>段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。</li>
<li>段的大小不固定，有它所完成的功能决定；页大大小固定，由系统决定</li>
<li>段向用户提供二维地址空间；页向用户提供的是一维地址空间</li>
<li>段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。</li>
</ul>
</li>
<li>将用户程序变为可在内存中执行的程序的步骤<ul>
<li>编译</li>
<li>链接</li>
<li>装入</li>
</ul>
</li>
<li>程序的装入方式<ul>
<li>绝对装入</li>
<li>动态运行装入</li>
<li>可重定位装入</li>
</ul>
</li>
<li>内存连续分配管理方式<ul>
<li>单一连续分配</li>
<li>固定分区分配</li>
<li>动态分区分配</li>
</ul>
</li>
<li>页面置换算法<ul>
<li>最佳置换算法</li>
<li>先进先出置换算法</li>
<li>最近最久未使用算法</li>
<li>时钟置换算法</li>
</ul>
</li>
<li>堆栈（stack）、堆（heap）<ul>
<li>栈<ul>
<li>用户维护函数调用上下文。由高地址向低地址生长，通常以M为单位，由操作系统维护。</li>
<li>保存了一个函数调用所需要维护的信息，称为活动记录，包括<ul>
<li>函数的返回地址，参数</li>
<li>临时变量</li>
<li>上下文：寄存器</li>
</ul>
</li>
<li>空间管理<ul>
<li>栈（英文名称是 stack）是系统自动分配空间的，例如我们定义一个 <code>char a;</code> 系统会自动在栈上为其开辟空间</li>
<li>栈上的空间是自动分配自动回收的</li>
</ul>
</li>
<li>栈上的数据的生存周期只是在函数的运行过程中，运行后就释放掉，不可以再访问</li>
</ul>
</li>
<li>堆<ul>
<li>空间管理<ul>
<li>动态申请内存，即使用 new or malloc 等分配到的内存，可以比栈大很多，需用户自己释放<ul>
<li>malloc<ul>
<li>对于申请内存这种特权操作，肯定是操作系统内核来做比较合适，但是频繁的进行系统调用，在用户态和内核态之间切换，也就是频繁的调用中断处理程序，性能是较差的。所以，事实上都是通过 c 语言的运行库封装好的库函数，预申请一块设当的内存，然后零售给程序用，可以采用空闲链表或者位图等来管理。这取决于运行库的实现了。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>堆上的数据只要程序员不释放空间，就一直可以访问到，不过缺点是一旦忘记释放会造成内存泄露。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>文件管理<ul>
<li>磁盘调度算法（先来先服务算法、最短寻道时间优先算法、扫描算法、循环扫描算法）</li>
</ul>
</li>
<li>I/O 管理<ul>
<li>I/O 控制方式<ul>
<li>程序 I/O 方式<ul>
<li>这种方式下，CPU 通过 I/O 指令询问指定外设当前的状态，如果外设准备就绪，则进行数据的输入或输出，否则 CPU 等待，循环查询。</li>
</ul>
</li>
<li>中断驱动方式<ul>
<li>每次中断均需保存断点（返回地址）和现场（各寄存器的值，包括标志寄存器），中断返回时，要恢复断点和现场。</li>
</ul>
</li>
<li>DMA 方式<ul>
<li>DMA（Direct Memory Access，直接存储器访问）。在 DMA 出现之前，CPU 与外设之间的数据传送方式有程序传送方式、中断传送方式。CPU 是通过系统总线与其他部件连接并进行数据传输。</li>
<li>DMA 方式在数据传送过程中，没有保存现场、恢复现场之类的工作。</li>
<li>由于 CPU 根本不参加传送操作，因此就省去了 CPU 取指令、取数、送数等操作。内存地址修改、传送字个数的计数等等，也不是由软件实现，而是用硬件线路直接实现的。所以 DMA 方式能满足高速 I/O 设备的要求，也有利于 CPU 效率的发挥。</li>
</ul>
</li>
<li>I/O 通道控制方式<ul>
<li>通道是一个用来控制外部设备工作的硬件机制，相当于一个功能简单的处理机。通道是独立于 CPU 的、专门负责数据的输入输出传输工作的处理器，它对外部设备实统一管理，代替 CPU 对 I/O 操作进行控制，从而使 I/O 操作可以与 CPU 并行工作。通道是实现计算机和传输并行的基础，以提高整个系统的效率。</li>
</ul>
</li>
</ul>
</li>
<li>Spooling 技术<ul>
<li>Spooling 技术能够缓和 CPU 和外设的速度，提高 I/O 速度，将独占设备转化为共享设备，并实现虚拟设备功能。</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E3%80%81%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E3%80%81%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">数据结构-0-知识点汇总.md</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-01 09:15:30" itemprop="dateCreated datePublished" datetime="2019-09-01T09:15:30+08:00">2019-09-01</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" itemprop="url" rel="index"><span itemprop="name">数据结构</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><ul>
<li>前缀树（字典树）<ul>
<li>前缀树又名字典树，单词查找树，Trie 树，是一种多路树形结构，是哈希树的变种，和hash效率有一拼，是一种用于快速检索的多叉树结构。</li>
<li><img src="/2019/09/01/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E3%80%81%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/%E5%89%8D%E7%BC%80%E6%A0%91.jpg" alt="前缀树"></li>
<li>特性<ul>
<li>根节点不包含字符，除根节点外的每一个子节点都包含一个字符。</li>
<li>从根节点到某一节点的路径上的字符连接起来，就是该节点对应的字符串。</li>
<li>每个节点的所有子节点包含的字符都不相同。</li>
<li>每条边对应一个字母。每个节点对应一项前缀。叶节点对应最长前缀，即单词本身。</li>
</ul>
</li>
<li>应用场景<ul>
<li>字符串的快速检索</li>
<li>字符串排序</li>
<li>最长公共前缀</li>
<li>自动匹配前缀显示后缀</li>
</ul>
</li>
</ul>
</li>
<li>B树<ul>
<li>即二叉搜索树</li>
<li>结构特点<ul>
<li>所有非叶子结点至多拥有两个儿子（Left 和 Right）；</li>
<li>所有结点存储一个关键字；</li>
<li>非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树；</li>
</ul>
</li>
</ul>
</li>
<li>B-树<ul>
<li>B-tree，即 B树，而不要读成 B减树，它是一种多路搜索树（并不是二叉的）</li>
<li>结构特点<ul>
<li>定义任意非叶子结点最多只有 M 个儿子；且 M&gt;2；</li>
<li>根结点的儿子数为<code>[2, M]</code>；</li>
<li>除根结点以外的非叶子结点的儿子数为<code>[M/2, M]</code>；</li>
<li>每个结点存放至少 M/2-1（取上整）和至多 M-1 个关键字；（至少2个关键字）</li>
<li>非叶子结点的关键字个数=指向儿子的指针个数-1；</li>
<li>非叶子结点的关键字：<code>K[1], K[2], …, K[M-1]</code>；且 <code>K[i] &lt; K[i+1]</code>；</li>
<li>非叶子结点的指针：<code>P[1], P[2], …, P[M]</code>；其中 P[1] 指向关键字小 于K[1] 的子树，P[M] 指向关键字大于 K[M-1] 的子树，其它 P[i] 指向关键字属于<code>(K[i-1], K[i])</code>的子树；</li>
<li>所有叶子结点位于同一层；</li>
</ul>
</li>
<li>特性<ul>
<li>关键字集合分布在整颗树中；</li>
<li>任何一个关键字出现且只出现在一个结点中；</li>
<li>搜索有可能在非叶子结点结束；</li>
<li>其搜索性能等价于在关键字全集内做一次二分查找；</li>
<li>自动层次控制；</li>
</ul>
</li>
<li>如果索引是采用 B 树结构存储的，所以对应的索引项并不会被删除，经过一段时间的增删改操作后，数据库中就会出现大量的存储碎片，这和磁盘碎片、内存碎片产生原理是类似的，这些存储碎片不仅占用了存储空间，而且降低了数据库运行的速度。如果发现索引中存在过多的存储碎片的话就要进行 “碎片整理”了，最方便的“碎片整理” 手段就是重建索引， 重建索引会将先前创建的索引删除然后重新创建索引</li>
</ul>
</li>
<li>B+树<ul>
<li>B+树是B-树的变体，也是一种多路搜索树</li>
<li>结构特点<ul>
<li>其定义基本与 B-树同，除了：<ul>
<li>非叶子结点的子树指针与关键字个数相同；</li>
<li>非叶子结点的子树指针 P[i]，指向关键字值属于<code>(K[i], K[i+1])</code>的子树（B-树是开区间）；</li>
<li>为所有叶子结点增加一个链指针；</li>
<li>所有关键字都在叶子结点出现；</li>
</ul>
</li>
</ul>
</li>
<li>特性<ul>
<li>所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的；</li>
<li>不可能在非叶子结点命中；</li>
<li>非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层；</li>
<li>更适合文件索引系统；<ul>
<li>原因<ul>
<li>B+树空间利用率更高，因为 B+树的内部节点只是作为索引使用，而不像 B-树那样每个节点都需要存储硬盘指针。</li>
<li>增删文件（节点）时，效率更高，因为 B+树的叶子节点包含所有关键字，并以有序的链表结构存储，这样可很好提高增删效率。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>B*树<ul>
<li>是 B+树的变体，在 B+树的非根和非叶子结点再增加指向兄弟的指针</li>
</ul>
</li>
<li>平衡二叉树<ul>
<li>AVL 树<ul>
<li>平衡二叉搜索树（Self-balancing binary search tree）又被称为 AVL 树（有别于 AVL 算法）</li>
<li>具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一棵平衡二叉树。</li>
</ul>
</li>
<li>红黑树<ul>
<li>是一种平衡二叉树，但每个节点有一个存储位表示节点的颜色，可以是红或黑。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，红黑树确保没有一条路径会比其它路径长出两倍，因此，红黑树是一种弱平衡二叉树（由于是弱平衡，可以看到，在相同的节点情况下，AVL树的高度&lt;=红黑树），相对于要求严格的 AVL 树来说，它的旋转次数少，所以对于搜索，插入，删除操作较多的情况下，用红黑树。</li>
</ul>
</li>
<li>对比<ul>
<li><table>
<thead>
<tr>
<th align="center">平衡二叉树类型</th>
<th align="center">平衡度</th>
<th align="center">调整频率</th>
<th align="center">适用场景</th>
</tr>
</thead>
<tbody><tr>
<td align="center">AVL树</td>
<td align="center">高</td>
<td align="center">高</td>
<td align="center">查询多，增/删少</td>
</tr>
<tr>
<td align="center">红黑树</td>
<td align="center">低</td>
<td align="center">低</td>
<td align="center">增/删频繁</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/" class="post-title-link" itemprop="url">微积分-拉格朗日乘子法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-30 09:11:00" itemprop="dateCreated datePublished" datetime="2019-08-30T09:11:00+08:00">2019-08-30</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://www.matongxue.com/madocs/939.html">https://www.matongxue.com/madocs/939.html</a></p>
<h3 id="与原点的最短距离"><a href="#与原点的最短距离" class="headerlink" title="与原点的最短距离"></a>与原点的最短距离</h3><p>假如有方程：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1"></p>
<p>图像是这个样子滴：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/2.png" alt="2"></p>
<p>现在我们想求其上的点与原点的最短距离：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/3.gif" alt="3"></p>
<p>这里介绍一种解题思路。首先，与原点距离为 a 的点全部在半径为 a 的圆上：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/4.gif" alt="4"></p>
<p>那么，我们逐渐扩大圆的半径：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/5.gif" alt="5"></p>
<p>显然，第一次与 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1"> 相交的点就是距离原点最近的点：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/6.png" alt="6"></p>
<p>此时，圆和曲线相切，也就是在该点切线相同：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/7.png" alt="7"></p>
<p>至此，我们分析出了：<strong>在极值点，圆与曲线相切</strong></p>
<h3 id="等高线"><a href="#等高线" class="headerlink" title="等高线"></a>等高线</h3><p><img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/8.png" alt="8"></p>
<p>可以看作函数 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/9.png" alt="9"> 的等高线：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/10.png" alt="10"></p>
<p>梯度向量：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/11.png" alt="11"></p>
<p>是等高线的法线：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/12.png" alt="12"></p>
<p>另外一个函数 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/13.png" alt="13"> 的等高线为：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/14.png" alt="14"></p>
<p>之前的曲线 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1"> 就是其中值为3的等高线：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/15.png" alt="15"></p>
<p>因此，梯度向量：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/16.png" alt="16"></p>
<p>也垂直于等高线 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1">：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/17.png" alt="17"></p>
<p>梯度向量是等高线的法线，更准确地表述是：<strong>梯度与等高线的切线垂直</strong></p>
<h3 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="headerlink" title="拉格朗日乘子法"></a>拉格朗日乘子法</h3><h4 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h4><p>根据之前的两个分析：</p>
<ol>
<li>在极值点，圆与曲线相切</li>
<li>梯度与等高线的切线垂直</li>
</ol>
<p>综合可知，在相切点，圆的梯度向量和曲线的梯度向量平行：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/18.gif" alt="18"></p>
<p>也就是梯度向量平行，用数学符号表示为：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/19.png" alt="19"></p>
<p>还必须引入 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1"> 这个条件，否则这么多等高线，不知道指的是哪一根：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/20.png" alt="20"></p>
<p>因此联立方程：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/21.png" alt="21"></p>
<p>求一下试试：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/22.png" alt="22"></p>
<p>这就是拉格朗日乘子法。</p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>要求函数 f 在 g 约束下的极值这种问题可以表示为：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/23.png" alt="23"></p>
<p><em>s.t.</em> 意思是subject to，服从于，约束于的意思。</p>
<p>可以列出方程组进行求解：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/24.png" alt="24"></p>
<p>用这个定义来翻译下刚才的例子，要求：</p>
<p>令：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/25.png" alt="25"></p>
<p>求：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/26.png" alt="26"></p>
<p>联立方程进行求解：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/27.png" alt="27"></p>
<h4 id="变形"><a href="#变形" class="headerlink" title="变形"></a>变形</h4><p>这个定义还有种变形也比较常见，要求：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/23.png" alt="23"></p>
<p>定义：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/28.png" alt="28"></p>
<p>求解下面方程组即可得到答案：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/29.png" alt="29"></p>
<p>把等式左边的偏导算出来就和上面的定义是一样的了。</p>
<h4 id="多个约束条件"><a href="#多个约束条件" class="headerlink" title="多个约束条件"></a>多个约束条件</h4><p>如果增加一个约束条件呢？比如说：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/30.png" alt="30"></p>
<p>求：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/31.png" alt="31"></p>
<p>从图上看约束条件是这样的：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/32.png" alt="32"></p>
<p>很显然所求的距离是这样的：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/33.png" alt="33"></p>
<p>那这三者的法线又有什么关系呢？<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/34.png" alt="34"> 的法线是 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/35.png" alt="35"> 和 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/36.png" alt="36"> 的法线的线性组合：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/37.png" alt="37"></p>
<p>假设：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/38.png" alt="38"></p>
<p>那么线性组合就表示为：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/39.png" alt="39"></p>
<p>联立方程：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/40.png" alt="40"></p>
<p>即可求解。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">统计学系方法-第6章-逻辑斯谛回归与最大熵模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-29 11:37:12" itemprop="dateCreated datePublished" datetime="2019-08-29T11:37:12+08:00">2019-08-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>逻辑斯谛回归（logistic regression）是统计学习中的经典分类方法。最大熵是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型（maximum entropy model）。逻辑斯蒂回归模型与最大熵模型都属于对数线性模型。</p>
<h2 id="逻辑斯谛回归模型"><a href="#逻辑斯谛回归模型" class="headerlink" title="逻辑斯谛回归模型"></a>逻辑斯谛回归模型</h2><h3 id="逻辑斯谛分布"><a href="#逻辑斯谛分布" class="headerlink" title="逻辑斯谛分布"></a>逻辑斯谛分布</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%88%86%E5%B8%83.png" alt="逻辑斯谛分布"> </p>
<h3 id="二项逻辑斯谛回归模型"><a href="#二项逻辑斯谛回归模型" class="headerlink" title="二项逻辑斯谛回归模型"></a>二项逻辑斯谛回归模型</h3><p>二项逻辑斯谛回归模型（binomial logistic regression model）是一种分类模型，由条件概率分布 P(Y|X) 表示，形式为参数化的逻辑斯谛分布。这里，随机变量 X 取值为实数，随机变量 Y 取值为 1 或 0。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E4%BA%8C%E9%A1%B9%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B.png" alt="二项逻辑斯谛回归模型"> </p>
<p>一个事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值。如果事件发生的概率是 p，那么该事件的几率是 p/(1-p)，该事件的对数几率（log odds）或 logit 函数是 <img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/logit.png" alt="logit"></p>
<p>对逻辑斯谛回归而言，<img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E5%87%A0%E7%8E%87.png" alt="逻辑斯谛回归几率"></p>
<p>这就是说，在逻辑斯谛回归模型中，输出 Y=1 的对数几率是输入 x 的线性函数。或者说，输出 Y=1 的对数几率是由输入 x 的线性函数表示的模型，即逻辑斯谛回归模型。</p>
<h3 id="模型参数估计"><a href="#模型参数估计" class="headerlink" title="模型参数估计"></a>模型参数估计</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.png" alt="逻辑斯谛回归-模型参数估计"></p>
<h3 id="多项逻辑斯谛回归"><a href="#多项逻辑斯谛回归" class="headerlink" title="多项逻辑斯谛回归"></a>多项逻辑斯谛回归</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%A4%9A%E9%A1%B9%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92.png" alt="多项逻辑斯谛回归"></p>
<h2 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a>最大熵模型</h2><p>最大熵模型（maximum entropy model）由最大熵原理推导实现。</p>
<h3 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h3><p>最大熵原理是概率模型学习的一个准则。最大熵原理认为，学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足条件的模型集合中选取熵最大的模型。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E7%86%B5.png" alt="熵"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E5%87%A0%E4%BD%95%E8%A7%A3%E9%87%8A1.png" alt="最大熵几何解释1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E5%87%A0%E4%BD%95%E8%A7%A3%E9%87%8A2.png" alt="最大熵几何解释2"></p>
<h3 id="最大熵模型的定义"><a href="#最大熵模型的定义" class="headerlink" title="最大熵模型的定义"></a>最大熵模型的定义</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%891.png" alt="最大熵模型的定义1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%892.png" alt="最大熵模型的定义2"></p>
<h3 id="最大熵模型的学习"><a href="#最大熵模型的学习" class="headerlink" title="最大熵模型的学习"></a>最大熵模型的学习</h3><p>最大熵模型的学习过程就是求解最大熵模型的过程。最大熵模型的学习可以形式化为约束最优化问题。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A01.png" alt="最大熵模型的学习1"></p>
<p>求解上述约束最优问题，所得出的解，就是最大熵模型学习的解。</p>
<p>将约束最优化的原始问题转换为无约束最优化的对偶问题。通过求解对偶问题求解原始问题。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E5%BD%A2%E5%BC%8F.png" alt="拉格朗日对偶形式"></p>
<p>由于拉格朗日函数 L(P, w) 是 P 的凸函数，原始问题（6.18）的解与对偶问题（6.19）的解是等价的。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A31.png" alt="对偶问题求解1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A32.png" alt="对偶问题求解2"></p>
<h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E5%81%B6%E5%87%BD%E6%95%B0%E6%9E%81%E5%A4%A7%E5%8C%96%E7%AD%89%E4%BB%B7%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E8%AF%81%E6%98%8E1.png" alt="对偶函数极大化等价于最大熵模型的极大似然估计证明1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E5%81%B6%E5%87%BD%E6%95%B0%E6%9E%81%E5%A4%A7%E5%8C%96%E7%AD%89%E4%BB%B7%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E8%AF%81%E6%98%8E2.png" alt="对偶函数极大化等价于最大熵模型的极大似然估计证明2"></p>
<h2 id="模型学习的最优化算法"><a href="#模型学习的最优化算法" class="headerlink" title="模型学习的最优化算法"></a>模型学习的最优化算法</h2><p>逻辑斯谛回归模型、最大熵模型学习归结为似然函数为目标函数的最优化问题，通常通过迭代算法求解。从最优化的观点看，这时的目标函数具有很好的性质。它是光滑的凸函数，因此多种最优化的方法都适用，保证能找到全局最优解。常用的方法有改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法。牛顿法或拟牛顿法一般收敛速度更快。</p>
<h3 id="改进的迭代尺度法"><a href="#改进的迭代尺度法" class="headerlink" title="改进的迭代尺度法"></a>改进的迭代尺度法</h3><p>改进的迭代尺度法（improved iterative scaling, IIS）是一种最大熵模型学习的最优化算法。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/IIS.png" alt="IIS"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/IIS%E7%AE%97%E6%B3%951.png" alt="IIS算法1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/IIS%E7%AE%97%E6%B3%952.png" alt="IIS算法2"></p>
<h3 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/BFGS.png" alt="BFGS"></p>
<hr>
<p>Logistic Regression：根据周志华老师的讲法，这里 logistic 是对数几率的意思，所以正确的翻译方法应该叫 __对数几率回归__，所以不要以为这个东西叫 __逻辑回归__，逻辑回归是错误的翻译。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/" class="post-title-link" itemprop="url">Java-框架、相关技术-0-知识点汇总</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-26 15:28:58" itemprop="dateCreated datePublished" datetime="2019-08-26T15:28:58+08:00">2019-08-26</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><h3 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h3><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><ul>
<li>控制反转（IOC）<ul>
<li>注入方式<ul>
<li>构造器注入</li>
<li>setter 注入方式</li>
<li>注解注入</li>
<li>接口注入</li>
</ul>
</li>
<li>循环依赖<ul>
<li>singletonObjects：第一级缓存，里面放置的是实例化好的单例对象；</li>
<li>earlySingletonObjects：第二级缓存，里面存放的是提前曝光的单例对象；</li>
<li>singletonFactories：第三级缓存，里面存放的是要被实例化的对象的对象工厂</li>
<li>注入步骤<ul>
<li>创建 bean 的时候 Spring 首先从一级缓存 singletonObjects 中获取。</li>
<li>如果获取不到，并且对象正在创建中，就再从二级缓存 earlySingletonObjects 中获取。</li>
<li>如果还是获取不到就从三级缓存 singletonFactories 中取。（Bean 调用构造函数进行实例化后，即使属性还未填充，就可以通过三级缓存向外提前暴露依赖的引用值（提前曝光），根据对象引用能定位到堆中的对象，其原理是基于 Java的 引用传递），取到后从三级缓存移动到了二级缓存完全初始化之后将自己放入到一级缓存中供其他使用。</li>
</ul>
</li>
<li>因为加入 singletonFactories 三级缓存的前提是执行了构造器，所以构造器的循环依赖没法解决。<ul>
<li>构造器循环依赖解决办法<ul>
<li>在构造函数中使用 @Lazy 注解延迟加载。在注入依赖时，先注入代理对象，当首次使用时再创建对象。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>面向切面编程（AOP）<ul>
<li>名词<ul>
<li>切面（Aspect）：切面是通知和切点的结合。通知和切点共同定义了切面的全部内容。 在 Spring AOP 中，切面可以使用通用类（基于模式的风格） 或者在普通类中以 @AspectJ 注解来实现。</li>
<li>连接点（Join point）：指方法，在 Spring AOP 中，一个连接点总是代表一个方法的执行。应用可能有数以千计的时机应用通知。这些时机被称为连接点。连接点是在应用执行过程中能够插入切面的一个点。这个点可以是调用方法时、抛出异常时、甚至修改一个字段时。切面代码可以利用这些点插入到应用的正常流程之中，并添加新的行为。<ul>
<li><strong>Spring 只支持方法级别的连接点</strong><ul>
<li>因为 Spring 基于动态代理，所以 Spring 只支持方法连接点。Spring 缺少对字段连接点的支持，而且它不支持构造器连接点。方法之外的连接点拦截功能，我们可以利用 Aspect 来补充。</li>
</ul>
</li>
</ul>
</li>
<li>通知（Advice）：在 AOP 术语中，切面的工作被称为通知。<ul>
<li>5 种类型的通知<ul>
<li>前置通知（Before）：在目标方法被调用之前调用通知功能；</li>
<li>后置通知（After）：在目标方法完成之后调用通知，此时不会关心方法的输出是什么；</li>
<li>返回通知（After-returning）：在目标方法成功执行之后调用通知；</li>
<li>异常通知（After-throwing）：在目标方法抛出异常后调用通知；</li>
<li>环绕通知（Around）：通知包裹了被通知的方法，在被通知的方法调用之前和调用之后执行自定义的行为。</li>
</ul>
</li>
</ul>
</li>
<li>切入点（Pointcut）：切点的定义会匹配通知所要织入的一个或多个连接点。我们通常使用明确的类和方法名称，或是利用正则表达式定义所匹配的类和方法名称来指定这些切点。</li>
<li>引入（Introduction）：引入允许我们向现有类添加新方法或属性。</li>
<li>目标对象（Target Object）：被一个或者多个切面（aspect）所通知（advise）的对象。它通常是一个代理对象。也有人把它叫做被通知（adviced）对象。 既然 Spring AOP 是通过运行时代理实现的，这个对象永远是一个被代理（proxied）对象。</li>
<li>织入（Weaving）：织入是把切面应用到目标对象并创建新的代理对象的过程。在目标对象的生命周期里有多少个点可以进行织入<ul>
<li>编译期：切面在目标类编译时被织入。AspectJ 的织入编译器是以这种方式织入切面的。</li>
<li>类加载期：切面在目标类加载到 JVM 时被织入。需要特殊的类加载器，它可以在目标类被引入应用之前增强该目标类的字节码。AspectJ5 的加载时织入就支持以这种方式织入切面。</li>
<li>运行期：切面在应用运行的某个时刻被织入。一般情况下，在织入切面时，AOP 容器会为目标对象动态地创建一个代理对象。SpringAOP 就是以这种方式织入切面。</li>
</ul>
</li>
</ul>
</li>
<li>通过动态代理方式实现<ul>
<li>JDK 动态代理<ul>
<li>实现原理<ul>
<li>通过实现 InvocationHandlet 接口创建自己的调用处理器；</li>
<li>通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理；</li>
<li>通过反射机制获取动态代理类的构造函数，其唯一参数类型就是调用处理器接口类型；</li>
<li>通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数参入；</li>
</ul>
</li>
<li>是面向接口的代理模式，如果被代理目标没有接口那么 Spring 也无能为力，Spring 通过 Java 的反射机制生产被代理接口的新的匿名实现类，重写了其中 AOP 的增强方法。</li>
</ul>
</li>
<li>CGLib 动态代理<ul>
<li>Spring 在运行期间通过 CGlib 继承要被动态代理的类，重写父类的方法，实现 AOP 面向切面编程呢。CGLib 动态代理是通过字节码底层继承要代理类来实现（如果被代理类被 final 关键字所修饰，那么会失败）。</li>
</ul>
</li>
</ul>
</li>
<li>配置 AOP 执行顺序<ul>
<li>通过实现 org.springframework.core.Ordered 接口</li>
<li>通过 <code>@Order()</code> 注解</li>
<li>通过配置文件配置</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Spring-容器"><a href="#Spring-容器" class="headerlink" title="Spring 容器"></a>Spring 容器</h4><ul>
<li><p>基础组件</p>
<ul>
<li><p>BeanFactory</p>
<ul>
<li>Spring 底层容器，定义了最基本的容器功能</li>
<li>BeanFactory 位于整个容器类体系结构的顶端，其基本实现类为 DefaultListableBeanFactory。之所以称其为核心容器，是因为该类容器实现 IOC 的核心功能：比如配置文件的加载解析，Bean 依赖的注入以及生命周期的管理等。BeanFactory 作为 Spring 框架的基础设施，面向 Spring 框架本身，一般不会被用户直接使用。</li>
</ul>
</li>
<li><p>ApplicationContext</p>
<ul>
<li><p>扩展于 BeanFactory，拥有更丰富的功能。例如：添加事件发布机制、父子级容器，一般都是直接使用 ApplicationContext。</p>
</li>
<li><p>通常译为应用上下文，不过称其为应用容器可能更形象些。它在 BeanFactory 提供的核心 IOC 功能之上作了扩展。通常 ApplicationContext 的实现类内部都持有一个 BeanFactory 的实例，IOC 容器的核心功能会交由它去完成。而 ApplicationContext 本身，则专注于在应用层对 BeanFactory 作扩展，比如提供对国际化的支持，支持框架级的事件监听机制以及增加了很多对应用环境的适配等。ApplicationContext 面向的是使用 Spring 框架的开发者。开发中经常使用的 ClassPathXmlApplicationContext 就是典型的 Spring 的应用容器，也是要进行解读的 IOC 容器。</p>
</li>
<li><p>相关类</p>
<ul>
<li><p>AbstractApplicationContext</p>
<ul>
<li><p>ApplicationContext 接口的抽象实现类，能够自动检测并注册各种后置处理器（PostProcessor）和事件监听器（Listener），以模板方法模式定义了一些容器的通用方法，比如启动容器的真正方法 <code>refresh()</code> 就是在该类中定义的。</p>
</li>
<li><p><code>refresh()</code> 方法</p>
<ul>
<li><p>```<br>@Override<br>public void refresh() throws BeansException, IllegalStateException {<br>  synchronized (this.startupShutdownMonitor) {</p>
<pre><code>  // Prepare this context for refreshing.
  // 准备，记录容器的启动时间 startupDate，标记容器为激活，初始化上下文环境如文件路径信息，验证必填属性是否填写
  prepareRefresh();

  // Tell the subclass to refresh the internal bean factory.
  // 这步比较重要（解析），告诉子类去刷新 bean 工厂，这步完成后配置文件就解析成一个个 bean 定义，注册到 BeanFactory（但是未被初始化，仅将信息写到了 beanDefination 的 map 中）
  ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();

  // Prepare the bean factory for use in this context.
  // 设置 beanFactory 类加载器，添加多个 beanPostProcesser
  prepareBeanFactory(beanFactory);

  try &#123;
    // Allows post-processing of the bean factory in context subclasses.
    // 允许子类上下文中对 beanFactory 做后期处理
    postProcessBeanFactory(beanFactory);

    // Invoke factory processors registered as beans in the context.
    // 调用 BeanFactoryPostProcessor 各个实现类的方法
    invokeBeanFactoryPostProcessors(beanFactory);

    // Register bean processors that intercept bean creation.
    // 注册 BeanPostProcessor 的实现类，注意看和 BeanFactoryPostProcessor 的区别
    // 此接口两个方法: postProcessBeforeInitialization 和 postProcessAfterInitialization
    // 两个方法分别在 Bean 初始化之前和初始化之后得到执行。注意，到这里 Bean 还没初始化
    registerBeanPostProcessors(beanFactory);

    // Initialize message source for this context.
    //初始化 ApplicationContext 的 MessageSource
    initMessageSource();

    // Initialize event multicaster for this context.
    // 初始化 ApplicationContext 事件广播器
    initApplicationEventMulticaster();

    // Initialize other special beans in specific context subclasses.
    // 初始化子类特殊 bean（钩子方法）
    onRefresh();

    // Check for listener beans and register them.
    // 注册事件监听器
    registerListeners();

    // Instantiate all remaining (non-lazy-init) singletons.
    // 初始化所有 singleton bean
    finishBeanFactoryInitialization(beanFactory);

    // Last step: publish corresponding event.
    // 广播事件，ApplicationContext 初始化完成
    finishRefresh();
  &#125;

  catch (BeansException ex) &#123;
    if (logger.isWarnEnabled()) &#123;
        logger.warn(&quot;Exception encountered during context initialization - &quot; +
              &quot;cancelling refresh attempt: &quot; + ex);
    &#125;

    // Destroy already created singletons to avoid dangling resources.
    destroyBeans();

    // Reset &#39;active&#39; flag.
    cancelRefresh(ex);

    // Propagate exception to caller.
    throw ex;
  &#125;

  finally &#123;
    // Reset common introspection caches in Spring&#39;s core, since we
    // might not ever need metadata for singleton beans anymore...
    resetCommonCaches();
  &#125;
</code></pre>
<p>  }<br>}</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line">      - AbstractRefreshableApplicationContext</span><br><span class="line">        - 继承 AbstractApplicationContext 的抽象类。内部持有一个 DefaultListableBeanFactory 的实例，使得继承 AbstractRefreshableApplicationContext 的 Spring 的应用容器内部默认有一个 Spring 的核心容器，那么 Spring 容器的一些核心功能就可以委托给内部的核心容器去完成。</span><br><span class="line">        - AbstractRefreshableApplicationContext 在内部定义了创建、销毁以及刷新核心容器 BeanFactory 的方法。</span><br><span class="line">      - ClassPathXmlApplicationContext</span><br><span class="line">        - 最常用的 Spring 的应用容器之一。在启动时会加载类路径下的 xml 文件作为容器的配置信息。</span><br><span class="line">      - BeanFactoryPostProcessor</span><br><span class="line">        - 实现该接口，可以在 Spring 的 bean 创建之前，修改 bean 的定义属性。也就是说，Spring 允许 BeanFactoryPostProcessor 在容器实例化任何其它 bean 之前读取配置元数据，并可以根据需要进行修改，例如可以把 bean 的 scope 从 singleton 改为 prototype，也可以把 property 的值给修改掉。可以同时配置多个 BeanFactoryPostProcessor，并通过设置&#x27;order&#x27;属性来控制各个 BeanFactoryPostProcessor 的执行次序。</span><br><span class="line">        - BeanFactoryPostProcessor 是在 spring 容器加载了 bean 的定义文件之后，在 bean 实例化之前执行的。接口方法的入参是 ConfigurrableListableBeanFactory，使用该参数，可以获取到相关 bean 的定义信息。</span><br><span class="line">        - Spring 中，有内置的一些 BeanFactoryPostProcessor 实现类，常用的有：</span><br><span class="line">          - org.springframework.beans.factory.config.PropertyPlaceholderConfigurer</span><br><span class="line">          - org.springframework.beans.factory.config.PropertyOverrideConfigurer</span><br><span class="line">          - org.springframework.beans.factory.config.CustomEditorConfigurer：用来注册自定义的属性编辑器</span><br><span class="line">      - BeanPostProcessor</span><br><span class="line">        - BeanPostProcessor，可以在 Spring 容器实例化 bean 之后，在执行 bean 的初始化方法前后，添加一些自己的处理逻辑。</span><br><span class="line">        - 这里说的初始化方法，指的是下面两种：</span><br><span class="line">          - bean 实现了 InitializingBean 接口，对应的方法为 afterPropertiesSet</span><br><span class="line">          - 在 bean 定义的时候，通过 init-method 设置的方法</span><br><span class="line">        - BeanPostProcessor 是在 Spring 容器加载了 bean 的定义文件并且实例化 bean 之后执行的。BeanPostProcessor 的执行顺序是在 BeanFactoryPostProcessor 之后。</span><br><span class="line">        - Spring中，有内置的一些 BeanPostProcessor 实现类，例如：</span><br><span class="line">          - org.springframework.context.annotation.CommonAnnotationBeanPostProcessor：支持 @Resource 注解的注入</span><br><span class="line">          - org.springframework.beans.factory.annotation.RequiredAnnotationBeanPostProcessor：支持 @Required 注解的注入</span><br><span class="line">          - org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor：支持 @Autowired 注解的注入</span><br><span class="line">          - org.springframework.orm.jpa.support.PersistenceAnnotationBeanPostProcessor：支持 @PersistenceUnit 和 @PersistenceContext 注解的注入</span><br><span class="line">          - org.springframework.context.support.ApplicationContextAwareProcessor：用来为 bean 注入 ApplicationContext 等容器对象</span><br><span class="line">  - Resource</span><br><span class="line">    - bean 配置文件，一般为 xml 文件。可以理解为保存 bean 信息的文件。</span><br><span class="line">  - BeanDefinition</span><br><span class="line">    - BeanDefinition 定义了 bean 的基本信息，根据它来创造 bean。</span><br><span class="line">- 容器启动步骤</span><br><span class="line">  - ![Spring_容器启动的整个流程](Java-框架、相关技术-0-知识点汇总/Spring_容器启动的整个流程.png)</span><br><span class="line">  1. 资源定位：找到配置文件</span><br><span class="line">  2. BeanDefinition 载入和解析</span><br><span class="line">  3. BeanDefinition 注册</span><br><span class="line">  4. bean 的实例化和依赖注入</span><br><span class="line">- BeanFactory</span><br><span class="line">  - BeanFactory 定义的标准处理顺序</span><br><span class="line">    1. BeanNameAware&#x27;s setBeanName</span><br><span class="line">    2. BeanClassLoaderAware&#x27;s setBeanClassLoader</span><br><span class="line">    3. BeanFactoryAware&#x27;s setBeanFactory</span><br><span class="line">    4. ResourceLoaderAware&#x27;s setResourceLoader (only applicable when running in an application context)</span><br><span class="line">    5. ApplicationEventPublisherAware&#x27;s setApplicationEventPublisher (only applicable when running in an application context)</span><br><span class="line">    6. MessageSourceAware&#x27;s setMessageSource (only applicable when running in an application context)</span><br><span class="line">    7. ApplicationContextAware&#x27;s setApplicationContext (only applicable when running in an application context)</span><br><span class="line">    8. ServletContextAware&#x27;s setServletContext (only applicable when running in a web application context)</span><br><span class="line">    9. postProcessBeforeInitialization methods of BeanPostProcessors</span><br><span class="line">    10. InitializingBean&#x27;s afterPropertiesSet</span><br><span class="line">    11. a custom init-method definition</span><br><span class="line">    12. postProcessAfterInitialization methods of BeanPostProcessors</span><br><span class="line">    - 第 9 点和 12 点是通过 BeanPostProccessor 接口进行处理的</span><br><span class="line">    - 第 10 点是通过 InitializingBean 接口去实现的</span><br><span class="line">  - BeanFactory 关闭的处理顺序</span><br><span class="line">    1. DisposableBean&#x27;s destroy</span><br><span class="line">    2. a custom destroy-method definition</span><br><span class="line"></span><br><span class="line">#### Spring 事件监听机制</span><br><span class="line">- 说明</span><br><span class="line">  - 事件监听机制可以理解为是一种观察者模式，有数据发布者（事件源）和数据接受者（监听器）；</span><br><span class="line">  - 在 Java 中，事件对象都是继承 java.util.EventObject 对象，事件监听器都是 java.util.EventListener 实例；</span><br><span class="line">  - EventObject 对象不提供默认构造器，需要外部传递 source 参数，即用于记录并跟踪事件的来源；</span><br><span class="line">- Spring 事件</span><br><span class="line">  - Spring 事件对象为 ApplicationEvent，继承 EventObject</span><br><span class="line">  - Spring 事件监听器为 ApplicationListener，继承 EventListener</span><br><span class="line">- 实现 Spring 事件监听有两种方式：</span><br><span class="line">  - 面向接口编程，实现 ApplicationListener 接口；</span><br><span class="line">  - 基于注解驱动，@EventListener（Spring 自定义的注解）；</span><br><span class="line">- Spring 自带的监听器</span><br><span class="line">  - ContextLoaderListener</span><br><span class="line">    - 在启动 Web 容器时，自动装配 Spring applicationContext.xml 的配置信息。</span><br><span class="line">    - 因为它实现了 ServletContextListener 这个接口，在 web.xml 配置这个监听器，启动容器时，就会默认执行它实现的方法。在 ContextLoaderListener 中关联了 ContextLoader 这个类，所以整个加载配置过程由 ContextLoader 来完成。</span><br><span class="line">  - RequestContextListener</span><br><span class="line">    - Spring2.0 中新增了三个 web 作用域：request、session、global session，如果希望 web 容器中的某个 bean 具有新的作用域，除了在 bean 中配置相应的 scope 属性外，还需要在容器中进行额外的初始化配置。</span><br><span class="line"></span><br><span class="line">#### SpringMVC</span><br><span class="line">- MVC 模式代表 Model-View-Controller（模型-视图-控制器）模式。</span><br><span class="line">- 原理</span><br><span class="line">  - ![SpringMVC_请求处理的流程](Java-框架、相关技术-0-知识点汇总/SpringMVC_请求处理的流程.png)</span><br><span class="line">  - 执行流程</span><br><span class="line">    - 用户向服务器发送请求，请求会到 DispatcherServlet，DispatcherServlet 对请求 URL 进行解析，得到请求资源标识符（URI），然后根据该 URI，调用 HandlerMapping 获得该 Handler 配置的所有相关的对象（包括一个 Handler 处理器对象、多个 HandlerInterceptor 拦截器对象），最后以 HandlerExecutionChain 对象的形式返回。</span><br><span class="line">    - DispatcherServlet 根据获得的 Handler，选择一个合适的 HandlerAdapter。提取 Request 中的模型数据，填充 Handler 入参，开始执行 Handler（Controller）。 在填充 Handler 的入参过程中，根据你的配置，Spring 将帮你做一些额外的工作：</span><br><span class="line">      - HttpMessageConveter： 将请求消息（如 Json、xml 等数据）转换成一个对象，将对象转换为指定的响应信息</span><br><span class="line">      - 数据转换：对请求消息进行数据转换。如 String 转换成 Integer、Double 等</span><br><span class="line">      - 数据格式化：对请求消息进行数据格式化。 如将字符串转换成格式化数字或格式化日期等</span><br><span class="line">      - 数据验证： 验证数据的有效性（长度、格式等），验证结果存储到 BindingResult 或 Error 中</span><br><span class="line">    - Handler 执行完成后，向 DispatcherServlet 返回一个 ModelAndView 对象；根据返回的 ModelAndView，选择一个适合的 ViewResolver 返回给 DispatcherServlet；ViewResolver 结合 Model 和 View，来渲染视图，最后将渲染结果返回给客户端。</span><br><span class="line"></span><br><span class="line">#### 注解</span><br><span class="line">- 注入相关</span><br><span class="line">  - @Qualifier</span><br><span class="line">    - 用处：当一个接口有多个实现的时候，为了指名具体调用哪个类的实现。</span><br><span class="line">  - @Resource</span><br><span class="line">    - 可以通过 byName 和 byType 的方式注入，默认先按 byName 的方式进行匹配，如果匹配不到，再按 byType 的方式进行匹配。</span><br><span class="line">    - 由 JSR-250 提供</span><br><span class="line">  - @Autowired</span><br><span class="line">    - 按 byType 方式注入，如果按 byType 冲突或找不到的话可以用 @Qualifier 来找 byName</span><br><span class="line">    - 由 spring 提供</span><br><span class="line">  - @Inject</span><br><span class="line">    - 由 JSR-330 提供</span><br><span class="line">    - 注意</span><br><span class="line">      - 使用前需要导入 jar 包——javax.inject；</span><br><span class="line">      - 支持 @Primary 注解，而且因为没有精确匹配，@Primary 的优先级最高；</span><br><span class="line">      - 不支持 required=false，即不能注入 null，如果找不到组件肯定报错；</span><br><span class="line">      - 默认按照属性名跟 bean 的名称匹配查找，如果不存在，再按类型匹配查找。</span><br><span class="line"></span><br><span class="line">#### 事务</span><br><span class="line">- 事务传播机制</span><br><span class="line">  - PROPAGATION_REQUIRED：如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。这是最常⻅的选择。 </span><br><span class="line">  - PROPAGATION_SUPPORTS：支持当前事务，如果当前没有事务，就以非事务方式执行。 </span><br><span class="line">  - PROPAGATION_MANDATORY：使用当前的事务，如果当前没有事务，就抛出异常。 </span><br><span class="line">  - PROPAGATION_REQUIRES_NEW：新建事务，如果当前存在事务，把当前事务挂起。 </span><br><span class="line">  - PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。</span><br><span class="line">  - PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 </span><br><span class="line">  - PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行。与 PROPAGATION_REQUIRED 类似的操作。</span><br><span class="line">- 事务原理</span><br><span class="line">  - Spring 在扫描 bean 的时候会扫描方法上是否包含 @Transactional 注解，如果包含，Spring 会为这个 bean 动态地生成一个子类（即代理类，proxy），代理类是继承原来那个 bean 的。此时，当这个有注解的方法被调用的时候，实际上是由代理类来调用的，代理类在调用之前就会启动 transaction。</span><br><span class="line">    - ```</span><br><span class="line">      @Service</span><br><span class="line">      class A&#123;</span><br><span class="line">          @Transactinal</span><br><span class="line">          method b()&#123;...&#125;</span><br><span class="line">          </span><br><span class="line">          method a()&#123;    //标记1</span><br><span class="line">              b();</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      //Spring扫描注解后，创建了另外一个代理类，并为有注解的方法插入一个startTransaction()方法：</span><br><span class="line">      class proxy$A&#123;</span><br><span class="line">          A objectA = new A();</span><br><span class="line">          method b()&#123;    //标记2</span><br><span class="line">              startTransaction();</span><br><span class="line">              objectA.b();</span><br><span class="line">          &#125;</span><br><span class="line">      </span><br><span class="line">          method a()&#123;    //标记3</span><br><span class="line">              objectA.a();    //由于a()没有注解，所以不会启动transaction，而是直接调用A的实例的a()方法</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>@Transactional 注解事务不生效的情况</p>
<ul>
<li>数据库<ul>
<li>事务生效的前提是你的数据源得支持事务，比如 mysql 的 MyISAM 引擎就不支持事务，而 Innodb 支持事务</li>
</ul>
</li>
<li>类内部访问<ul>
<li>在一个 Service 内部，事务方法之间的嵌套调用，普通方法和事务方法之间的嵌套调用，都不会开启新的事务。<ul>
<li>非事务方法 A 调用事务方法 B，方法 B 事务不生效<ul>
<li>因为 spring 采用动态代理机制来实现事务控制，而动态代理最终都是要调用原始对象的，而原始对象在去调用方法时，是不会再触发代理了</li>
</ul>
</li>
<li>在事务方法 A 中调用另外一个事务方法 B，被调用方法 B 的事务没起作用<ul>
<li>spring 是通过代理代管理事务的，当在第一个方法 insertUser1 内直接调用 insertUser2 的时候 ，insertUser2 上的事务是不会起作用的（也就是 insertUser2 是没有开启事务）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>私有方法<ul>
<li>在私有方法上，添加 @Transactional 注解也不会生效，私有方法外部不能访问，所以只能内部访问，上面的 case 不生效，这个当然也不生效了</li>
</ul>
</li>
<li>异常不匹配<ul>
<li>@Transactional 注解默认处理运行时异常，即只有抛出运行时异常时，才会触发事务回滚，否则并不会如</li>
</ul>
</li>
<li>多线程<ul>
<li>在标记事务的方法内部，另起子线程执行 db 操作，此时事务同样不会生效</li>
</ul>
</li>
<li>传播属性<ul>
<li>几种传播方式是不走事务执行的</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Bean"><a href="#Bean" class="headerlink" title="Bean"></a>Bean</h4><ul>
<li>Bean 的作用域<ul>
<li>singleton : bean 在每个 Spring ioc 容器中只有一个实例。</li>
<li>prototype：一个 bean 的定义可以有多个实例。</li>
<li>request：每次 http 请求都会创建一个 bean，该作用域仅在基于 web 的 Spring ApplicationContext 情形下有效。</li>
<li>session：在一个 HTTP Session 中，一个 bean 定义对应一个实例。该作用域仅在基于 web 的 Spring ApplicationContext 情形下有效。</li>
<li>global-session：在一个全局的 HTTP Session 中，一个 bean 定义对应一个实例。该作用域仅在基于 web 的 Spring ApplicationContext 情形下有效。</li>
</ul>
</li>
<li>Bean 的生命周期<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Spring_bean%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.jpg" alt="Spring_bean的生命周期"></li>
</ul>
<ol>
<li>Spring 启动，查找并加载需要被 Spring 管理的 Bean，进行 Bean 的实例化</li>
<li>Bean 实例化后对将 Bean 的引入和值注入到 Bean 的属性中</li>
<li>如果 Bean 实现了 BeanNameAware 接口的话，Spring 将 Bean 的 Id 传递给 setBeanName() 方法</li>
<li>如果 Bean 实现了 BeanFactoryAware 接口的话，Spring 将调用 setBeanFactory() 方法，将 BeanFactory 容器实例传入</li>
<li>如果 Bean 实现了 ApplicationContextAware 接口的话，Spring 将调用 Bean 的 setApplicationContext() 方法，将 Bean 所在应用上下文引用传入进来。</li>
<li>如果 Bean 实现了 BeanPostProcessor 接口，Spring 就将调用他们的 postProcessBeforeInitialization() 方法。</li>
<li>如果 Bean 实现了 InitializingBean 接口，Spring 将调用他们的 afterPropertiesSet() 方法。类似的，如果 Bean 使用 init-method 声明了初始化方法，该方法也会被调用</li>
<li>如果 Bean 实现了 BeanPostProcessor 接口，Spring 就将调用他们的 postProcessAfterInitialization() 方法。</li>
<li>此时，Bean 已经准备就绪，可以被应用程序使用了。他们将一直驻留在应用上下文中，直到应用上下文被销毁。</li>
<li>如果 Bean 实现了 DisposableBean 接口，Spring 将调用它的 destory() 接口方法，同样，如果 Bean 使用了 destory-method 声明销毁方法，该方法也会被调用。</li>
</ol>
</li>
<li>获取 bean 流程<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Java_Spring_%E8%8E%B7%E5%8F%96bean%E6%B5%81%E7%A8%8B.JPG" alt="Java_Spring_获取bean流程"></li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>Spring 框架中的单例 bean 是线程安全的吗？</strong><ul>
<li>不是，Spring 框架中的单例 bean 不是线程安全的。</li>
<li>spring 中的 bean 默认是单例模式，spring 框架并没有对单例 bean 进行多线程的封装处理。</li>
<li>实际上大部分时候 spring bean 无状态的（比如 dao 类），所有某种程度上来说 bean 也是安全的，但如果 bean 有状态的话（比如 view model 对象），那就要开发者自己去保证线程安全了，最简单的就是改变 bean 的作用域，把“singleton”变更为“prototype”，这样请求 bean 相当于 <code>new Bean()</code> 了，所以就可以保证线程安全了。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h4><ul>
<li>application.yml 中的 MySQL 密码可以通过第三方包加密（jasypt）</li>
</ul>
<h4 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h4><ul>
<li><strong>Spring 框架中都用到了哪些设计模式？</strong><ul>
<li>工厂模式：BeanFactory 就是简单工厂模式的体现，用来创建对象的实例；</li>
<li>单例模式：Bean 默认为单例模式。</li>
<li>代理模式：Spring 的 AOP 功能用到了 JDK 的动态代理和 CGLIB 字节码生成技术；</li>
<li>模板方法：用来解决代码重复的问题。比如：RestTemplate, JmsTemplate, JpaTemplate。</li>
<li>观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如 Spring 中 listener 的实现 ApplicationListener。</li>
</ul>
</li>
<li><strong>Spring BeanFactory 与 FactoryBean 的区别</strong><ul>
<li>BeanFactory<ul>
<li>BeanFactory，以 Factory 结尾，表示它是一个工厂类（接口），用于管理 Bean 的一个工厂。在 Spring 中，BeanFactory 是 IOC 容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。</li>
<li>Spring 为我们提供了许多易用的 BeanFactory 实现，XmlBeanFactory 就是常用的一个，该实现将以 XML 方式描述组成应用的对象及对象间的依赖关系。XmlBeanFactory 类将持有此 XML 配置元数据，并用它来构建一个完全可配置的系统或应用。</li>
</ul>
</li>
<li>FactoryBean<ul>
<li>以 Bean 结尾，表示它是一个 Bean，不同于普通 Bean 的是：它是实现了 <code>FactoryBean&lt;T&gt;</code> 接口的 Bean，根据该 Bean 的 ID 从 BeanFactory 中获取的实际上是 FactoryBean 的 <code>getObject()</code> 返回的对象，而不是 FactoryBean 本身，如果要获取F actoryBean 对象，请在 id 前面加一个 &amp; 符号来获取。</li>
<li>例如自己实现一个 FactoryBean，功能：用来代理一个对象，对该对象的所有方法做一个拦截，在调用前后都输出一行 LOG，模仿 ProxyFactoryBean 的功能。</li>
</ul>
</li>
<li>BeanFactory 是个 Factory，也就是 IOC 容器或对象工厂，FactoryBean 是个 Bean。在 Spring 中，所有的 Bean 都是由 BeanFactory（也就是 IOC 容器）来进行管理的。但对 FactoryBean 而言，这个 Bean 不是简单的 Bean，而是一个能生产或者修饰对象生成的工厂 Bean，它的实现与设计模式中的工厂模式和修饰器模式类似。</li>
</ul>
</li>
<li><strong>如何指定 bean 的初始化顺序？</strong><ul>
<li>构造方法依赖<ul>
<li>是最简单也是最常见的使用姿势，但是在使用时，需要注意循环依赖等问题。</li>
<li>bean 的注入方式之中，有一个就是通过构造方法来注入，借助这种方式，我们可以解决有优先级要求的 bean 之间的初始化顺序。</li>
<li>虽然这种方式比较直观简单，但是有几个限制<ul>
<li>需要有注入关系，如 CDemo2 通过构造方法注入到 CDemo1 中，如果需要指定两个没有注入关系的 bean 之间优先级，则不太合适（比如我希望某个 bean 在所有其他的 Bean 初始化之前执行）</li>
<li>循环依赖问题，如过上面的 CDemo2 的构造方法有一个 CDemo1 参数，那么循环依赖产生，应用无法启动</li>
</ul>
</li>
<li>另外一个需要注意的点是，在构造方法中，不应有复杂耗时的逻辑，会拖慢应用的启动时间</li>
</ul>
</li>
<li>@DependOn 注解<ul>
<li>这是一个专用于解决 bean 的依赖问题，当一个 bean 需要在另一个 bean 初始化之后再初始化时，可以使用这个注解</li>
<li>在使用这个注解的时候，有一点需要特别注意，它能控制 bean 的实例化顺序，但是 bean 的初始化操作（如构造 bean 实例之后，调用 @PostConstruct 注解的初始化方法）顺序则不能保证<ul>
<li>完整的 bean 创建，分成了两块顺序<ul>
<li>实例化（调用构造方法）</li>
<li>初始化（注入依赖属性，调用 @PostConstruct 方法）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>BeanPostProcessor 扩展<ul>
<li>非典型的使用方式，如非必要，请不要用这种方式来控制 bean 的加载顺序</li>
</ul>
</li>
</ul>
</li>
<li><strong>Spring 如何统计 bean 的数量？</strong><ul>
<li>通过实现 BeanFactoryPostProcessor 接口，调用 ConfigurableListableBeanFactory 的 <code>getBeanDefinitionCount()</code> 方法。</li>
</ul>
</li>
</ul>
<h3 id="SpringBoot"><a href="#SpringBoot" class="headerlink" title="SpringBoot"></a>SpringBoot</h3><ul>
<li>maven<ul>
<li>spring-boot-starter-parent<ul>
<li>通过这个作为 parent，可以继承其中定义的配置、各项依赖以及版本号</li>
<li>在本项目中添加依赖时，可以省略版本号</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="MyBatis"><a href="#MyBatis" class="headerlink" title="MyBatis"></a>MyBatis</h3><ul>
<li>介绍<ul>
<li>MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。</li>
</ul>
</li>
<li>语法<ul>
<li><code>#&#123;&#125;</code> 和 <code>$&#123;&#125;</code><ul>
<li><code>#&#123;&#125;</code>：使用的是预编译，对应 JBDC 中的 PreparedStatement</li>
<li><code>$&#123;&#125;</code>：不会修改或者转义字符换，直接输出变量值<ul>
<li>会引发 SQL 注入问题</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>SqlSession<ul>
<li>SqlSession 是 Mybatis 最重要的构建之一，可以简单的认为 Mybatis 一系列的配置目的是生成类似 JDBC 生成的 Connection 对象的 SqlSession 对象，这样才能与数据库开启“沟通”，通过 SqlSession 可以实现增删改查（当然现在更加推荐是使用 Mapper 接口形式）。</li>
</ul>
</li>
<li>工作原理<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MyBatis_%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.jpg" alt="MyBatis_工作原理"></li>
</ul>
<ol>
<li>读取 MyBatis 配置文件：mybatis-config.xml 为 MyBatis 的全局配置文件，配置了 MyBatis 的运行环境等信息，例如数据库连接信息。</li>
<li>加载映射文件。映射文件即 SQL 映射文件，该文件中配置了操作数据库的 SQL 语句，需要在 MyBatis 配置文件 mybatis-config.xml 中加载。mybatis-config.xml 文件可以加载多个映射文件，每个文件对应数据库中的一张表。</li>
<li>构造会话工厂：通过 MyBatis 的环境等配置信息构建会话工厂 SqlSessionFactory。</li>
<li>创建会话对象：由会话工厂创建 SqlSession 对象，该对象中包含了执行 SQL 语句的所有方法。</li>
<li>Executor 执行器：MyBatis 底层定义了一个 Executor 接口来操作数据库，它将根据 SqlSession 传递的参数动态地生成需要执行的 SQL 语句，同时负责查询缓存的维护。</li>
<li>MappedStatement 对象：在 Executor 接口的执行方法中有一个 MappedStatement 类型的参数，该参数是对映射信息的封装，用于存储要映射的 SQL 语句的 id、参数等信息。</li>
<li>输入参数映射：输入参数类型可以是 Map、List 等集合类型，也可以是基本数据类型和 POJO 类型。输入参数映射过程类似于 JDBC 对 preparedStatement 对象设置参数的过程。</li>
<li>输出结果映射：输出结果类型可以是 Map、 List 等集合类型，也可以是基本数据类型和 POJO 类型。输出结果映射过程类似于 JDBC 对结果集的解析过程。</li>
</ol>
</li>
<li>一级缓存与二级缓存<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/MyBatis_%E7%BC%93%E5%AD%98.jpg" alt="MyBatis_缓存"></li>
<li>一级缓存<ul>
<li>该级缓存默认开启，不能关闭；</li>
<li>该级缓存为 SqlSession 级别的缓存，也称为本地缓存；</li>
<li>以下 4 种情况将会导致该级缓存失效：<ul>
<li>在不同 SqlSession 中查询数据；</li>
<li>相同 SqlSession 中查询数据，但查询条件不同</li>
<li>相同 SqlSession 中查询数据，但两次查询之间执行了增删改操作</li>
<li>同 SqlSession 中查询数据，但第二次查询前，程序调用 SqlSession 对象 <code>clearCache()</code> 方法手动清除了一级缓存</li>
</ul>
</li>
<li>原理<ul>
<li>第一次发出一个查询 sql，sql 查询结果写入 sqlsession 的一级缓存中，缓存使用的数据结构是一个 map。<ul>
<li>key：MapperID+offset+limit+Sql+所有的入参</li>
<li>value：用户信息</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>二级缓存<ul>
<li>该级缓存默认不开启，但如果使用二级缓存需要在每个 XML 映射文件中添加 <code>&lt;cache&gt;&lt;/cache&gt;</code> 以配置该级缓存（相应实体类要序列化）。二级缓存可以通过在全局配置文件配置 setting 标签来关闭该级缓存。<ul>
<li>如果这样配置的话，很多其他的配置就会被默认进行，如：<ul>
<li>映射文件所有的 select 语句会被缓存</li>
<li>映射文件的所有的 insert、update 和 delete 语句会刷新缓存</li>
<li>缓存会使用默认的 Least Recently Used（LRU，最近最少使用原则）的算法来回收缓存空间</li>
<li>根据时间表，比如 No Flush Interval，（CNFI，没有刷新间隔），缓存不会以任何时间顺序来刷新</li>
<li>缓存会存储列表集合或对象（无论查询方法返回什么）的 1024 个引用</li>
<li>缓存会被视为是 read/write（可读/可写）的缓存，意味着对象检索不是共享的，而且可以很安全的被调用者修改，不干扰其他调用者或县城所作的潜在修改</li>
</ul>
</li>
</ul>
</li>
<li>该级缓存为 namespace 级别的缓存</li>
<li>工作机制：通过 SqlSession 查询数据，这些数据将会放到当前会话的一级缓存中；如果当前会话关闭，则一级缓存中的数据会被保存到二级缓存中，此后新的 SqlSession 将从二级缓存中查找数据；</li>
<li>select 标签的 useCache 属性用于设置是否使用二级缓存；insert、update、delete 或 select 标签均有 flushCache 属性，其中增删改默认true，即 sql 执行以后，会同时清空一级和二级缓存，查询默认 false。</li>
<li>为了提高扩展性，MyBatis 定义了 Cache 缓存接口，可以通过实现该缓存接口自定义二级缓存</li>
</ul>
</li>
</ul>
</li>
<li>Mybatis 的分页原理<ul>
<li>Mybatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的内存分页，而非物理分页，可以在 sql 内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。</li>
<li>分页插件的原理就是使用 MyBatis 提供的插件接口，实现自定义插件，在插件的拦截方法内，拦截待执行的 SQL，然后根据设置的 dialect（方言），和设置的分页参数，重写 SQL，生成带有分页语句的 SQL，执行重写后的 SQL，从而实现分页。</li>
</ul>
</li>
<li>相关问题<ul>
<li><strong>Mybatis 为什么出现？为什么不是直接使用 jdbc？</strong><ul>
<li>JDBC 操作数据库的步骤<ul>
<li>注册驱动；</li>
<li>获取数据库连接；</li>
<li>拼接sql语句，设置sql参数；</li>
<li>执行sql语句；</li>
<li>sql返回结果；</li>
<li>执行语句和数据库连接；</li>
</ul>
</li>
<li>直接用 JDBC 每次都要做大量的相同的操作，并且还要对执行 sql 语句过程中所出现的各种异常和资源释放进行处理，而真正涉及到业务功能的代码其实很少，这明显影响了效率。</li>
<li>再有就是当你接收数据库返回的结果集的时候，需要赋值给程序中的实体，使用 JDBC 需要你手动写代码去遍历每一条记录赋值给对应的实体 list 集合中，使用 JDBC 意味着需要更多的代码来提取结果并将它们映射到对象实例中，</li>
<li><strong>MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。</strong></li>
</ul>
</li>
<li><strong>通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应，请问，这个 Dao 接口的工作原理是什么？Dao 接口里的方法，参数不同时，方法能重载吗？</strong><ul>
<li>Dao 接口，就是人们常说的 Mapper 接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中 MappedStatement 的 id 值，接口方法内的参数，就是传递给 sql 的参数。Mapper 接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个 MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到 namespace 为 com.mybatis3.mappers.StudentDao 下面 id = findStudentById 的 MappedStatement。在 Mybatis 中，每一个 <code>&lt;select&gt;</code>、<code>&lt;insert&gt;</code>、<code>&lt;update&gt;</code>、<code>&lt;delete&gt;</code>标签，都会被解析为一个 MappedStatement 对象。</li>
<li>Dao 接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。</li>
<li>Dao 接口的工作原理是 JDK 动态代理，Mybatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行 MappedStatement 所代表的 sql，然后将 sql 执行结果返回。</li>
</ul>
</li>
<li><strong>简述 MyBatis 的插件运行原理，以及如何编写一个插件？</strong><ul>
<li>Mybatis 仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、Executor 这 4 种接口的插件，Mybatis 使用 JDK  的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler 的 <code>invoke()</code> 方法，当然，只会拦截那些你指定需要拦截的方法。实现 Mybatis 的 Interceptor 接口并复写 <code>intercept()</code> 方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，还需要在配置文件中配置你编写的插件。<ul>
<li>StatementHandler<ul>
<li>StatementHandler 是数据库会话器，专门用来处理数据库会话的。StatementHandler 内运用了适配器模式和策略模式的思想</li>
</ul>
</li>
<li>ResultSetHandler<ul>
<li>ResultHandler 是一个结果处理器，StatementHandler 完成了查询之后，最终就是通过 ResultHandler 来实现结果集映射，ResultSetHandler 接口中只定义了3个方法用来处理结果。</li>
<li>ResultHandler 也默认提供了一个实现类：DefaultResultSetHandler。一般我们平常用的最多的就是通过 handleResultSets 来实现结果集转换。</li>
</ul>
</li>
<li>ParameterHandler<ul>
<li>ParameterHandler 是一个参数处理器，主要是用来对预编译语句进行参数设置的，只有一个默认实现类 DefaultParameterHandler。</li>
<li>ParameterHandler 中只定义了两个方法，一个获取参数，一个设置参数。</li>
</ul>
</li>
<li>Executor<ul>
<li>Executor 就是真正用来执行 Sql 语句的对象，我们调用 SqlSession 中的方法，最终实际上都是通过 Executor 来完成的。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="ShardingSphere-JDBC"><a href="#ShardingSphere-JDBC" class="headerlink" title="ShardingSphere-JDBC"></a>ShardingSphere-JDBC</h3><ul>
<li>Apache ShardingSphere 是一套开源的分布式数据库解决方案组成的生态圈，它由 JDBC、Proxy 和 Sidecar（规划中）这 3 款既能够独立部署，又支持混合部署配合使用的产品组成。它们均提供标准化的数据水平扩展、分布式事务和分布式治理等功能，可适用于如 Java 同构、异构语言、云原生等各种多样化的应用场景。</li>
</ul>
<h3 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h3><ul>
<li>介绍<ul>
<li>Netty 是一个 基于 NIO 的 client-server（客户端服务器）框架，使用它可以快速简单地开发网络应用程序。</li>
<li>它极大地简化并优化了 TCP 和 UDP 套接字服务器等网络编程，并且性能以及安全性等很多方面甚至都要更好。</li>
<li>支持多种协议，如 FTP、SMTP、HTTP 以及各种二进制和基于文本的传统协议。</li>
<li>很多开源项目比如我们常用的 Dubbo、RocketMQ、ElasticSearch、gRPC 等等都用到了 Netty。</li>
</ul>
</li>
<li>本质：JBoss 做的一个 Jar 包</li>
<li>目的：快速开发高性能、高可靠性的网络服务器和客户端程序</li>
<li>优点<ul>
<li>统一的 API，支持多种传输类型，阻塞和非阻塞的。</li>
<li>简单而强大的线程模型。</li>
<li>自带编解码器解决 TCP 粘包/拆包问题。</li>
<li>自带各种协议栈。</li>
<li>真正的无连接数据包套接字支持。</li>
<li>比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。</li>
<li>安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。</li>
<li>社区活跃</li>
<li>成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。</li>
</ul>
</li>
<li>应用场景<ul>
<li>作为 RPC 框架的网络通信工具<ul>
<li>我们在分布式系统中，不同服务节点之间经常需要相互调用，这个时候就需要 RPC 框架了。不同服务节点之间的通信是如何做的呢？可以使用 Netty 来做。比如我调用另外一个节点的方法的话，至少是要让对方知道我调用的是哪个类中的哪个方法以及相关参数吧！</li>
</ul>
</li>
<li>实现一个自己的 HTTP 服务器<ul>
<li>通过 Netty 我们可以自己实现一个简单的 HTTP 服务器，这个大家应该不陌生。说到 HTTP 服务器的话，作为 Java 后端开发，我们一般使用 Tomcat 比较多。一个最基本的 HTTP 服务器可要以处理常见的 HTTP Method 的请求，比如 POST 请求、GET 请求等等。</li>
</ul>
</li>
<li>实现一个即时通讯系统 <ul>
<li>使用 Netty 我们可以实现一个可以聊天类似微信的即时通讯系统。</li>
</ul>
</li>
<li>实现消息推送系统<ul>
<li>市面上有很多消息推送系统都是基于 Netty 来做的。</li>
</ul>
</li>
</ul>
</li>
<li>架构<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Netty_%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="Netty_架构图"><ul>
<li>绿色的部分 Core 核心模块，包括零拷贝、API 库、可扩展的事件模型。</li>
<li>橙色部分 Protocol Support 协议支持，包括 Http 协议、webSocket、SSL（安全套接字协议）、谷歌 Protobuf 协议、zlib/gzip 压缩与解压缩、Large File Transfer 大文件传输等等。</li>
<li>红色的部分 Transport Services 传输服务，包括 Socket、Datagram、Http Tunnel 等等。</li>
</ul>
</li>
<li>构成部分<ul>
<li>Channel<ul>
<li>NIO 基本结构，代表一个用于连接到实体如硬件设备、文件、网络套接字或程序组件，能否执行一个或多个不同的 I/O 操作的开放连接。</li>
<li>比较常用的 Channel 接口实现类是 NioServerSocketChannel（服务端）和 NioSocketChannel（客户端），这两个 Channel 可以和 BIO 编程模型中的 ServerSocket 以及 Socket 两个概念对应上。Netty 的 Channel 接口所提供的 API，大大地降低了直接使用 Socket 类的复杂性。</li>
</ul>
</li>
<li>Future<ul>
<li>提供了另一种通知应用操作已经完成的方式，这个对象作为一个一步操作结果的占位符，他将在将来的某个时候完成并提交结果。</li>
<li>Netty 提供自己的实现，ChannelFuture，用于执行异步操作时使用。每个 Netty 的 outbound I/O 操作都会返回一个 ChannelFuture，这样就不会阻塞，这便是 Netty 所谓的“自底向上的异步和事件驱动”。相关实现的步骤如下：<ol>
<li>异步连接到远程对等节点，调用立即返回并提供 ChannelFuture；</li>
<li>操作完成后通知注册一个 ChannelFutureListener；</li>
<li>当 <code>operationComplete()</code> 调用时检查操作的状态；</li>
<li>如果成功就创建一个 ByteBuf 来保存数据；</li>
<li>异步发送数据到远程，再次返回 ChannelFuture；</li>
<li>如果有一个错误则抛出 Throwable，描述错误原因。</li>
</ol>
</li>
<li>相关类<ul>
<li>ChannelFuture<ul>
<li>Netty 是异步非阻塞的，所有的 I/O 操作都为异步的。</li>
<li>因此，我们不能立刻得到操作是否执行成功，但是，你可以通过 ChannelFuture 接口的 <code>addListener()</code> 方法注册一个 ChannelFutureListener，当操作执行成功或者失败时，监听就会自动触发返回结果。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Event 和 Handle<ul>
<li>Netty 使用不同的事件来通知我们更改的状态或操作的状态，这使我们能够根据发声的事件触发适当的行为。</li>
<li>这些行为可能包括：日志、数据转换、流控制、应用程序逻辑，由于 Netty 是一个网络框架，事件很清晰的跟入栈或出出站数据流相关，因为一些事件可能触发的传入的数据或状态的变化包括：活动或非活动连接、数据的读取、用户事件、错误，出站事件是由于在未来操作将触发的一个动作，这些包括：打开或关闭一个连接到远程、写或冲刷数据到 socket。</li>
<li>每个事件都可以分配给用户实现处理程序类的方法，这些范例可直接转换为应用程序构建块。</li>
<li>Netty 的 ChannelHandler 是各种处理程序的基本抽象，每个处理器实例就是一个回调，用于执行各种事件的响应。</li>
<li>相关类<ul>
<li>ChannelHandler<ul>
<li>ChannelHandler 是消息的具体处理器。他负责处理读写操作、客户端连接等事情。</li>
</ul>
</li>
<li>ChannelPipeline<ul>
<li>ChannelPipeline 为 ChannelHandler 的链，提供了一个容器并定义了用于沿着链传播入站和出站事件流的 API 。当 Channel 被创建时，它会被自动地分配到它专属的 ChannelPipeline。</li>
<li>我们可以在 ChannelPipeline 上通过 <code>addLast()</code> 方法添加一个或者多个 ChannelHandler ，因为一个数据或者事件可能会被多个 Handler 处理。当一个 ChannelHandler 处理完之后就将数据交给下一个 ChannelHandler 。</li>
</ul>
</li>
<li>EventLoop<ul>
<li>EventLoop 定义了 Netty 的核心抽象，用于处理连接的生命周期中所发生的事件。</li>
<li>EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。</li>
<li>Channel 为 Netty 网络操作（读写等操作）抽象类，EventLoop 负责处理注册到其上的 Channel 处理 I/O 操作，两者配合参与 I/O 操作。</li>
</ul>
</li>
<li>EventLoopGroup<ul>
<li>EventLoopGroup 包含多个 EventLoop（每一个 EventLoop 通常内部包含一个线程），上面我们已经说了 EventLoop 的主要作用实际就是负责监听网络事件并调用事件处理器进行相关 I/O 操作的处理。</li>
<li>并且 EventLoop 处理的 I/O 事件都将在它专有的 Thread 上被处理，即 Thread 和 EventLoop 属于 1 : 1 的关系，从而保证线程安全。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>其他<ul>
<li>Bootstrap 和 ServerBootstrap<ul>
<li>Bootstrap 是客户端的启动引导类/辅助类</li>
<li>ServerBootstrap 客户端的启动引导类/辅助类</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Netty 的线程模型<ul>
<li>对于网络请求一般可以分为两个处理阶段，一是接收请求任务，二是处理网络请求。根据不同阶段处理方式分为以下几种线程模型：<ul>
<li>串行化处理模型<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Netty_%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B_%E4%B8%B2%E8%A1%8C%E5%8C%96%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B.jpg" alt="Netty_线程模型_串行化处理模型"></li>
<li>这个模型中用一个线程来处理网络请求连接和任务处理，当 worker 接受到一个任务之后，就立刻进行处理，也就是说任务接受和任务处理是在同一个 worker 线程中进行的，没有进行区分。这样做存在一个很大的问题是，必须要等待某个 task 处理完成之后，才能接受处理下一个 task。</li>
<li>因此可以把接收任务和处理任务两个阶段分开处理，一个线程接收任务，放入任务队列，另外的线程异步处理任务队列中的任务。</li>
</ul>
</li>
<li>并行化处理模型<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Netty_%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B_%E5%B9%B6%E8%A1%8C%E5%8C%96%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B.jpg" alt="Netty_线程模型_并行化处理模型"></li>
<li>由于任务处理一般比较缓慢，会导致任务队列中任务积压长时间得不到处理，这时可以使用线程池来处理。可以通过为每个线程维护一个任务队列来改进这种模型。</li>
</ul>
</li>
</ul>
</li>
<li>Netty 具体线程模型<ul>
<li>Reactor 模式基于事件驱动，采用多路复用将事件分发给相应的 Handler 处理，非常适合处理海量 IO 的场景。</li>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Netty_%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg" alt="Netty_线程模型"></li>
<li>每个 NioEventLoop 都绑定了一个 Selector，所以在 Netty 的线程模型中，是由多个 Selecotr 在监听 I/O 就绪事件。而 Channel 注册到 Selector。</li>
<li>一个 Channel 绑定一个 NioEventLoop，相当于一个连接绑定一个线程，这个连接所有的 ChannelHandler 都是在一个线程中执行的，避免了多线程干扰。更重要的是 ChannelPipline 链表必须严格按照顺序执行的。单线程的设计能够保证 ChannelHandler 的顺序执行。</li>
<li>一个 NioEventLoop 的 selector 可以被多个 Channel 注册，也就是说多个 Channel 共享一个 EventLoop。EventLoop 的 Selecctor 对这些 Channel 进行检查。</li>
<li>相关问题<ul>
<li><strong>如何理解 NioEventLoop 和 NioEventLoopGroup</strong><ul>
<li>NioEventLoop 实际上就是工作线程，可以直接理解为一个线程。NioEventLoopGroup 是一个线程池，线程池中的线程就是 NioEventLoop。</li>
<li>实际上 bossGroup 中有多个 NioEventLoop 线程，每个 NioEventLoop 绑定一个端口，也就是说，如果程序只需要监听 1 个端口的话，bossGroup 里面只需要有一个 NioEventLoop 线程就行了。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Netty 工作原理<ul>
<li>server 端工作原理<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Netty_Server%E7%AB%AF%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.jpg" alt="Netty_Server端工作原理"></li>
</ul>
</li>
<li>client 端工作原理<ul>
<li><img src="/2019/08/26/%E8%AF%AD%E8%A8%80/Java/%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF/Java-%E6%A1%86%E6%9E%B6%E3%80%81%E7%9B%B8%E5%85%B3%E6%8A%80%E6%9C%AF-0-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%B1%87%E6%80%BB/Netty_Client%E7%AB%AF%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.jpg" alt="Netty_Client端工作原理"></li>
</ul>
</li>
</ul>
</li>
<li>Netty 的零拷贝<ul>
<li>零复制（英语：Zero-copy；也译零拷贝）技术是指计算机执行操作时，CPU 不需要先将数据从某处内存复制到另一个特定区域。这种技术通常用于通过网络传输文件时节省 CPU 周期和内存带宽。</li>
<li>在 OS 层面上的 Zero-copy 通常指避免在用户态（User-space）与内核态（Kernel-space）之间来回拷贝数据。而在 Netty 层面，零拷贝主要体现在对于数据操作的优化。</li>
<li>Netty 中的零拷贝体现在以下几个方面：<ul>
<li>使用 Netty 提供的 CompositeByteBuf 类, 可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf, 避免了各个 ByteBuf 之间的拷贝。</li>
<li>ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf, 避免了内存的拷贝。</li>
<li>通过 FileRegion 包装的 FileChannel.tranferTo 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel, 避免了传统通过循环 write 方式导致的内存拷贝问题。</li>
</ul>
</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/11/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/69/">69</a><a class="extend next" rel="next" href="/page/13/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhang Wetts"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhang Wetts</p>
  <div class="site-description" itemprop="description">Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">681</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">67</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">349</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wetts" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wetts" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhang.wetts@163.com" title="E-Mail → mailto:zhang.wetts@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhang Wetts</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hibiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
</html>
