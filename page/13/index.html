<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wetts.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Stay Hungry, Stay Foolish. [build by hexo&#x2F;next&#x2F;gitalk&#x2F;hexo-generator-search&#x2F;LaTeX]">
<meta property="og:type" content="website">
<meta property="og:title" content="Wetts&#39;s blog">
<meta property="og:url" content="https://wetts.github.io/page/13/index.html">
<meta property="og:site_name" content="Wetts&#39;s blog">
<meta property="og:description" content="Stay Hungry, Stay Foolish. [build by hexo&#x2F;next&#x2F;gitalk&#x2F;hexo-generator-search&#x2F;LaTeX]">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Zhang Wetts">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://wetts.github.io/page/13/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Wetts's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Wetts's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Stay Hungry, Stay Foolish.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/wetts" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/" class="post-title-link" itemprop="url">统计学系方法-第5章-决策树</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-24 18:37:12" itemprop="dateCreated datePublished" datetime="2019-08-24T18:37:12+08:00">2019-08-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>决策树（decision tree）是一种基本的分类与回归方法。决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是 if-then 规则的集合，也可以认为是定义在特征空间与类空间伤的条件概率分布。其主要优点是模型具有可读性，分类速度快。学习时，利用训练数据，根据损失函数最小化的原则简历决策树模型。预测时，对新的数据，利用决策树模型进行分类。决策树学习通常包括 3 个步骤：特征选择、决策树的生成和决策树的修剪。</p>
<h2 id="决策树模型与学习"><a href="#决策树模型与学习" class="headerlink" title="决策树模型与学习"></a>决策树模型与学习</h2><h3 id="决策树模型"><a href="#决策树模型" class="headerlink" title="决策树模型"></a>决策树模型</h3><p>分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点（node）和有向边（directed edge）组成。结点有两种类型：内部结点（internal node）和叶结点（leaf node）。内部结点表示一个特征或属性，叶结点表示一个类。</p>
<p>用决策树分类，从根结点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子节点；这时，每一个子节点对应着该特征的一个取值。如此递归地对实例进行测试并分配，直至达到叶结点。最后将实例分到叶结点的类中。</p>
<h3 id="决策树与-if-then-规则"><a href="#决策树与-if-then-规则" class="headerlink" title="决策树与 if-then 规则"></a>决策树与 if-then 规则</h3><p>可以将决策树看成一个 if-then 规则的集合。将决策树转换成 if-then 规则的过程是这样的：由决策树的根结点到叶结点的每一条路径构建一条规则；路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。决策树的路径或其对应的 if-then 规则集合具有一个重要的性质：互斥并且完备。这就是说，每一个实例都被一条路径或一条规则所覆盖，而且只被一条路径或一条规则所覆盖。这里所谓的覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。</p>
<h3 id="决策树与条件概率分布"><a href="#决策树与条件概率分布" class="headerlink" title="决策树与条件概率分布"></a>决策树与条件概率分布</h3><p>决策树还表示给定特征条件下类的条件概率分布。这一条件概率分布定义在特征空间的一个划分（partition）上。将特征空间划分为互不相交的单元（cell）或区域（region），并在每个单元定义一个类的概率分布就构成了一个条件概率分布。决策树的一条路径对应于划分中的一个单元。决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。假设 X 为表示特征的随机变量，Y 为表示类的随机变量，那么这个条件概率分布可以表示为 P(Y|X)。X 取值于给定划分下单元的集合，Y 取值于类的集合。各叶结点（单元）上的条件概率往往偏向某一个类，即属于某一类的概率较大。决策树分类时将该结点的实例强行分到条件概率的那一类去。</p>
<h3 id="决策树学习"><a href="#决策树学习" class="headerlink" title="决策树学习"></a>决策树学习</h3><p>决策树学习本质上是从训练数据集中归纳出一组分类规则。与训练数据集不相矛盾的决策树（即能对训练数据进行正确分类的决策树）可能有多个，也可能一个也没有。我们需要的是一个与训练数据矛盾较小的决策树，同时具有较好的泛化能力。从另一个角度看，决策树学习是由训练数据集估计条件概率模型。基于特征空间划分的类的条件概率模型有无穷多个。我们选择的条件概率模型应该不仅对训练数据有很好的拟合，而且对位置数据有很好的预测。</p>
<p>决策树学习用损失函数表示这一目标。决策树学习的损失函数通常是正则化的极大似然函数。决策树学习的策略是以损失函数为目标函数的最小化。</p>
<p>决策树学习的算法通常是一个递归地选择最优特征，并根据该特征对训练数据进行分割，使得各个子数据集有一个最好的分类的过程。</p>
<p>以上方法生成的决策树可能对训练数据有很好的分类能力，但对未知的测试数据却未必有很好的分类能力，即可能发生过拟合现象。我们需要对已生成的树自下而上进行剪枝，将树变得更简单，从而使它具有更好的泛化能力。</p>
<p>如果特征数量很多，也可以在决策树学习开始的时候，对特征进行选择，只留下对训练数据有足够分类能力的特征。</p>
<p>决策树学习算法包含特征选择、决策树的生成与决策树的剪枝过程。由于决策树表示一个条件概率分布，所以深浅不同的决策树对应着不同复杂度的概率模型。决策树的生成对应于模型的局部选择，决策树的剪枝对应于模型的全局选择。决策树的生成只考虑局部最优，相对地，决策树的剪枝则考虑全局最优。</p>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><h3 id="特征选择问题"><a href="#特征选择问题" class="headerlink" title="特征选择问题"></a>特征选择问题</h3><p>特征选择在于选取对训练数据具有分类能力的特征。这样可以提高决策树学习的效率。如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的。经验上扔掉这样的特征对决策树学习的精度影响不大。通常特征选择的准则是信息增益或信息增益比。</p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>在信息论与概率统计中，熵（entropy）是表示随机变量不确定性的度量。设 X 是一个取有限个值的离散随机变量，其概率分布为 P(X=xi)=pi，i=1,2,…,n，则随机变量 X 的熵的定义为 <img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E7%86%B5.png" alt="熵"> </p>
<p>设有随机变量(X, Y)，其联合概率分布为 P(X=xi, Y=yj)=pij, i=1,2,…,n; j=1,2,…,m，条件熵 H(Y|X) 表示在已知随机变量 X 的条件下随机变量 Y 的不确定性。随机变量 X 给定的条件下随机变量 Y 的条件熵（conditional entropy）H(Y|X)，定义为 X 给定条件下 Y 的条件概率分布的熵对 X 的数学期望 <img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%9D%A1%E4%BB%B6%E7%86%B5.png" alt="条件熵">，这里，pi=P(X=xi), i=1,2,…,n</p>
<p>当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为经验熵（empirical entropy）和经验条件熵（empirical conditional entropy）。此时如果有 0 概率，令 0log0=0。</p>
<p>信息增益（information gain）表示得知特征 X 的信息而使得类 Y 的信息不确定性减少的程度。</p>
<p><strong>信息增益：</strong> 特征 A 对训练数据集 D 的信息增益 g(D, A)，定义为集合 D 的经验熵 H(D) 与特征 A 给定条件下 D 的经验条件熵 H(D|A) 之差。即 <code>g(D, A) = H(D) - H(D|A)</code></p>
<p>一般地，熵 H(Y) 与条件熵 H(Y|X) 之差称为互信息（mutual information）。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。</p>
<p>信息增益大的特征具有更强分类能力。</p>
<p>根据信息增益准则的特征选择方法是：对训练数据集（或子集）D，计算其每个特征的信息增益，并比较它们的大小，选择信息增益最大的特征。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%AE%97%E6%B3%951.png" alt="信息增益算法1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%AE%97%E6%B3%952.png" alt="信息增益算法2"> </p>
<h3 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h3><p>以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题。使用信息增益比（information gain ratio）可以对这一问题进行校正。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E6%AF%94.png" alt="信息增益比"> </p>
<h2 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h2><h3 id="ID3-算法"><a href="#ID3-算法" class="headerlink" title="ID3 算法"></a>ID3 算法</h3><p>ID3 算法的核心是在决策树各个节点上应用信息增益准则选择特征，递归地构建决策树。具体方法是：从根结点（root node）开始，对结点计算所有可能的特征信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子节点；再对子节点递归地调用以上方法，构建决策树；直到所有特征的信息增益均很小或没有特征可以选择为止。最后得到一个决策树。ID3 相当于用极大似然法进行概率模型的选择。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/ID3.png" alt="ID3"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/ID3-2.png" alt="ID3-2"> </p>
<p>ID3 算法只有树的生成，所以该算法生成的树容易产生过拟合。</p>
<h3 id="C4-5-的生成算法"><a href="#C4-5-的生成算法" class="headerlink" title="C4.5 的生成算法"></a>C4.5 的生成算法</h3><p>C4.5 算法与 ID3 算法相似，C4.5 算法对 ID3 算法进行了改进。C4.5 在生成的过程中，用信息增益比来选择特征。<br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/C4.5%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95.png" alt="C4.5生成算法"> </p>
<h2 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h2><p>决策树生成算法递归地产生决策树，直到不能继续下去为止。这样产生的树往往对训练数据的分类很准确，但对未知的测试数据的分类却没有那么准确，即出现过拟合现象。过拟合的原因在于学习时过多地考虑如何提高对训练数据的正确分类，从而构建出过于复杂的决策树。解决这个问题的办法是考虑决策树的复杂度，对已生成的决策树进行简化。</p>
<p>在决策树学习中将已生成的树进行简化的过程称为剪枝（pruning）。具体地，剪枝从已生成的树上裁掉一些子树或叶结点，并将其根结点或父节点作为新的叶结点，从而简化分类树模型。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%951.png" alt="剪枝算法1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%952.png" alt="剪枝算法2"> </p>
<p>剪枝，就是当 α 确定时，选择损失函数最小的模型，即损失函数最小的子树。当 α 值确定时，子树越大，往往与训练数据的拟合越好，但是模型的复杂度就越高；相反，子树越小，模型的复杂度就越低，但是往往与训练数据的拟合不好。损失函数正好表示了对两者的平衡。</p>
<p>可以看出，决策树生成只考虑了通过提高信息增益（或信息增益比）对训练数据进行更好的拟合。而决策树剪枝通过优化损失函数还考虑减小模型复杂度。决策树生成学习局部的模型，而决策树剪枝学习整体的模型。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%A0%91%E7%9A%84%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%951.png" alt="树的剪枝算法1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%A0%91%E7%9A%84%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%952.png" alt="树的剪枝算法2"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%A0%91%E7%9A%84%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%953.png" alt="树的剪枝算法3"> </p>
<h2 id="CART-算法"><a href="#CART-算法" class="headerlink" title="CART 算法"></a>CART 算法</h2><p>分类与回归树（classification and regression tree, CART）模型由 Breiman 等人在 1984年提出，是应用广泛的决策树学习方法。CART 同样由特征选择、树的生成及剪枝组成，即可以用于分类也可以用于回归。以下将用于分类与回归的树统称为决策树。</p>
<p>CART 是在给定输入随机变量 X 条件下输出随机变量 Y 的条件概率分布的学习方法。CART 假设决策树是二叉树，内部结点特征的取值为“是”与“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等价于递归地二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。</p>
<p>CART 算法由以下两步组成：</p>
<ol>
<li>决策树生成：基于训练数据集生成决策树，生成的决策树要尽量大；</li>
<li>决策树剪枝：用验证数据集对已生成的树进行剪枝并选择最优子树，这时用损失函数最小作为剪枝的标准。</li>
</ol>
<h3 id="CART-生成"><a href="#CART-生成" class="headerlink" title="CART 生成"></a>CART 生成</h3><p>决策树的生成就是递归地构建二叉决策树的过程。对回归树用平方误差最小化准则，对分类树用基尼指数（Gini index）最小化准则，进行特征选择，生成二叉树。</p>
<h4 id="回归树的生成"><a href="#回归树的生成" class="headerlink" title="回归树的生成"></a>回归树的生成</h4><p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E5%9B%9E%E5%BD%92%E6%A0%91%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95.png" alt="最小二乘回归树生成算法"> </p>
<h4 id="分类树的生成"><a href="#分类树的生成" class="headerlink" title="分类树的生成"></a>分类树的生成</h4><p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B01.png" alt="基尼指数1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B02.png" alt="基尼指数2"> </p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/CART%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%951.png" alt="CART生成算法1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/CART%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%952.png" alt="CART生成算法2"> </p>
<h3 id="CART-剪枝"><a href="#CART-剪枝" class="headerlink" title="CART 剪枝"></a>CART 剪枝</h3><p>CART 剪枝算法从“完全生长”的决策树的底端剪去一些子树，使决策树变小（模型变简单），从而能够对未知数据有更准确的预测。CART 剪枝算法由两步组成：首先从生成算法产生的决策树 T0底端开始不断剪枝，直到 T0 的根结点，形成一个子树序列 {T0, T1,…Tn}；然后通过交叉验证法在独立的验证数据集上对子树序列进行测试，从中选择最优子树。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/CART%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%95.png" alt="CART剪枝算法 "> </p>
<hr>
<h3 id="附西瓜书第4章-决策树部分内容"><a href="#附西瓜书第4章-决策树部分内容" class="headerlink" title="附西瓜书第4章-决策树部分内容"></a>附西瓜书第4章-决策树部分内容</h3><p>决策树的剪枝（pruning）的基本策略有“预剪枝”（prepruning）和“后剪枝”（postpruning）。预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点；后剪枝则是先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为子节点。</p>
<p>后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/22/%E8%AF%AD%E8%A8%80/Python/API/numpy/Python-numpy-newaxis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/22/%E8%AF%AD%E8%A8%80/Python/API/numpy/Python-numpy-newaxis/" class="post-title-link" itemprop="url">Python-numpy-newaxis</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-22 20:33:12" itemprop="dateCreated datePublished" datetime="2019-08-22T20:33:12+08:00">2019-08-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://blog.csdn.net/xtingjie/article/details/72510834">https://blog.csdn.net/xtingjie/article/details/72510834</a></p>
<p>numpy中包含的newaxis可以给原数组增加一个维度</p>
<p>np.newaxis放的位置不同，产生的新数组也不同</p>
<p>一维数组</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">x</span><br><span class="line">Out[48]: array([4, 6, 6, 6, 5])</span><br><span class="line"></span><br><span class="line">x1 = x[np.newaxis, :]</span><br><span class="line"></span><br><span class="line">x1</span><br><span class="line">Out[50]: array([[4, 6, 6, 6, 5]])</span><br><span class="line"></span><br><span class="line">x2 = x[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">x2</span><br><span class="line">Out[52]: </span><br><span class="line">array([[4],</span><br><span class="line">       [6],</span><br><span class="line">       [6],</span><br><span class="line">       [6],</span><br><span class="line">       [5]])</span><br></pre></td></tr></table></figure>
<p>由以上代码可以看出，当把newaxis放在前面的时候</p>
<p>以前的shape是5，现在变成了1×5，也就是前面的维数发生了变化，后面的维数发生了变化</p>
<p>而把newaxis放后面的时候，输出的新数组的shape就是5×1，也就是后面增加了一个维数</p>
<p>所以，newaxis放在第几个位置，就会在shape里面看到相应的位置增加了一个维数</p>
<p>如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(1, 8, size=(2, 3, 4))</span><br><span class="line">y = x[:, np.newaxis, :, :]</span><br><span class="line">z = x[:, :, np.newaxis, :]</span><br><span class="line"></span><br><span class="line">x.shape</span><br><span class="line">Out: (2, 3, 4)</span><br><span class="line"></span><br><span class="line">y.shape</span><br><span class="line">Out: (2, 1, 3, 4)</span><br><span class="line"></span><br><span class="line">z.shape</span><br><span class="line">Out: (2, 3, 1, 4)</span><br></pre></td></tr></table></figure>

<h4 id="一般问题"><a href="#一般问题" class="headerlink" title="一般问题"></a>一般问题</h4><p>经常会遇到这样的问题，需要从数组中取出一部分的数据，也就是取出“一片”或者“一条”</p>
<p>比如需要从二维数组里面抽取一列</p>
<p>取出来之后维度却变成了一维</p>
<p>假如我们需要将其还原为二维，就需要上面的方法了</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/22/%E8%AF%AD%E8%A8%80/Python/API/numpy/Python-numpy-%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%87%E7%89%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/22/%E8%AF%AD%E8%A8%80/Python/API/numpy/Python-numpy-%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%87%E7%89%87/" class="post-title-link" itemprop="url">Python-numpy-索引与切片</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-22 14:55:49" itemprop="dateCreated datePublished" datetime="2019-08-22T14:55:49+08:00">2019-08-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>参考：<a target="_blank" rel="noopener" href="https://www.numpy.org.cn/user_guide/numpy_basics/indexing.html">https://www.numpy.org.cn/user_guide/numpy_basics/indexing.html</a></p>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><h4 id="单个元素索引"><a href="#单个元素索引" class="headerlink" title="单个元素索引"></a>单个元素索引</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(10)</span><br><span class="line">&gt;&gt;&gt; x[2]</span><br><span class="line">2</span><br><span class="line">&gt;&gt;&gt; x[-2]</span><br><span class="line">8</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x.shape = (2,5) # now x is 2-dimensional</span><br><span class="line">&gt;&gt;&gt; x[1,3]</span><br><span class="line">8</span><br><span class="line">&gt;&gt;&gt; x[1,-1]</span><br><span class="line">9</span><br><span class="line">&gt;&gt;&gt; x[0]</span><br><span class="line">array([0, 1, 2, 3, 4])</span><br></pre></td></tr></table></figure>
<p>指定的每个索引都会选择与所选维度的其余部分相对应的数组。在上面的例子中，选择0表示长度为5的剩余维度未指定，并且返回的是具有该维度和大小的数组。必须注意的是，返回的数组不是原始数据的副本，而是指向与原始数组相同的内存值。在这种情况下，返回第一个位置（0）处的一维数组。因此，在返回的数组上使用单个索引会导致返回一个元素。那是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[0][2]</span><br><span class="line">2</span><br></pre></td></tr></table></figure>
<p>因此，请注意，<code>x[0, 2] = x[0][2]</code>， 但是第二种情况效率更低，因为一个新的临时数组在第一个索引后创建了，这个临时数组随后才被2这个数字索引。</p>
<h4 id="其他索引选项"><a href="#其他索引选项" class="headerlink" title="其他索引选项"></a>其他索引选项</h4><p>可以对数组进行切片和步进，以提取具有相同数量维数的数组，但其大小与原始数据不同。切片和跨步的工作方式与对列表和元组完全相同，除此之外它们还可以应用于多个维度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(10)</span><br><span class="line">&gt;&gt;&gt; x[2:5]</span><br><span class="line">array([2, 3, 4])</span><br><span class="line">&gt;&gt;&gt; x[:-7]</span><br><span class="line">array([0, 1, 2])</span><br><span class="line">&gt;&gt;&gt; x[1:7:2]</span><br><span class="line">array([1, 3, 5])</span><br><span class="line">&gt;&gt;&gt; y = np.arange(35).reshape(5,7)</span><br><span class="line">&gt;&gt;&gt; y[1:5:2,::3]</span><br><span class="line">array([[ 7, 10, 13],</span><br><span class="line">       [21, 24, 27]])</span><br></pre></td></tr></table></figure>
<p>请注意，数组切片不会复制内部数组数据，但也会产生原始数据的新视图。</p>
<h4 id="索引数组"><a href="#索引数组" class="headerlink" title="索引数组"></a>索引数组</h4><p>数组索引指的是使用方括号（[]）来索引数组值。有很多选项来索引，这使numpy索引很强大，但功能上的强大也带来一些复杂性和潜在的混乱。</p>
<p>索引数组必须是整数类型。数组中的每个值指示数组中要使用哪个值来代替索引。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(10,1,-1)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([10,  9,  8,  7,  6,  5,  4,  3,  2])</span><br><span class="line">&gt;&gt;&gt; x[np.array([3, 3, 1, 8])]</span><br><span class="line">array([7, 7, 9, 2])</span><br></pre></td></tr></table></figure>

<p>索引值超出范围是错误的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[np.array([3, 3, 20, 8])]</span><br><span class="line">&lt;type &#x27;exceptions.IndexError&#x27;&gt;: index 20 out of bounds 0&lt;=index&lt;9</span><br></pre></td></tr></table></figure>
<p>一般来说，使用索引数组时返回的是与索引数组具有相同形状的数组，但是索引数组的类型和值。作为一个例子，我们可以使用多维索引数组来代替：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[np.array([[1,1],[2,3]])]</span><br><span class="line">array([[9, 9],</span><br><span class="line">       [8, 7]])</span><br></pre></td></tr></table></figure>

<h4 id="索引多维数组"><a href="#索引多维数组" class="headerlink" title="索引多维数组"></a>索引多维数组</h4><p>对多维数组进行索引时，情况会变得更加复杂，特别是对于多维索引数组。这些往往是更常用的用途，但它们是允许的，并且它们对于一些问题是有用的。我们将从最简单的多维情况开始：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y = np.arange(35).reshape(5,7)</span><br><span class="line">&gt;&gt;&gt; y[np.array([0,2,4]), np.array([0,1,2])]</span><br><span class="line">array([ 0, 15, 30])</span><br></pre></td></tr></table></figure>
<p>在这种情况下，如果索引数组具有匹配的形状，并且索引数组的每个维都有一个索引数组，则结果数组具有与索引数组相同的形状，并且这些值对应于每个索引集的索引在索引数组中的位置。在此示例中，两个索引数组的第一个索引值为0，因此结果数组的第一个值为<code>y[0, 0]</code>。下一个值是<code>y[2, 1]</code>，最后一个是<code>y[4, 2]</code>。</p>
<p>广播机制允许索引数组与其他索引的标量组合。结果是标量值用于索引数组的所有对应值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y[np.array([0,2,4]), 1]</span><br><span class="line">array([ 1, 15, 29])</span><br></pre></td></tr></table></figure>
<p>跳到复杂性的下一个级别，可以只用索引数组部分索引数组。理解在这种情况下会发生什么需要一些思考。例如，如果我们只使用一个索引数组与y：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y[np.array([0,2,4])]</span><br><span class="line">array([[ 0,  1,  2,  3,  4,  5,  6],</span><br><span class="line">       [14, 15, 16, 17, 18, 19, 20],</span><br><span class="line">       [28, 29, 30, 31, 32, 33, 34]])</span><br></pre></td></tr></table></figure>
<p>什么结果是一个新的数组的结构，其中索引数组的每个值从被索引的数组中选择一行，并且结果数组具有结果形状（行的大小，数字索引元素）。</p>
<p>这可能有用的一个示例是用于颜色查找表，我们想要将图像的值映射到RGB三元组中进行显示。查找表可能有一个形状（nlookup，3）。使用带有dtype = np.uint8（或任何整数类型，只要值与查找表的边界）形状（ny，nx）的图像索引这样一个数组将导致一个形状数组（ny，nx， 3）RGB值的三倍与每个像素位置相关联。</p>
<p>通常，resulant数组的形状将是索引数组形状（或所有索引数组广播的形状）与索引数组中任何未使用的维（未索引的维）的形状的串联。</p>
<h4 id="布尔值或掩码索引数组"><a href="#布尔值或掩码索引数组" class="headerlink" title="布尔值或掩码索引数组"></a>布尔值或掩码索引数组</h4><p>用作索引的布尔数组的处理方式完全不同于索引数组。布尔数组的形状必须与被索引数组的初始维相同。在最直接的情况下，布尔数组具有相同的形状：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; b = y&gt;20</span><br><span class="line">&gt;&gt;&gt; y[b]</span><br><span class="line">array([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34])</span><br></pre></td></tr></table></figure>
<p>与整数索引数组不同，在布尔情况下，结果是一维数组，其中包含索引数组中所有对应于布尔数组中所有真实元素的元素。索引数组中的元素始终以行优先（C样式）顺序进行迭代和返回。结果也与<code>y[np.nonzero(b)]</code>相同。与索引数组一样，返回的是数据的副本，而不是像切片一样获得的视图。</p>
<p>如果y比b的维数更高，则结果将是多维的。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; b[:,5] # use a 1-D boolean whose first dim agrees with the first dim of y</span><br><span class="line">array([False, False, False,  True,  True], dtype=bool)</span><br><span class="line">&gt;&gt;&gt; y[b[:,5]]</span><br><span class="line">array([[21, 22, 23, 24, 25, 26, 27],</span><br><span class="line">       [28, 29, 30, 31, 32, 33, 34]])</span><br></pre></td></tr></table></figure>
<p>这里第4行和第5行是从索引数组中选择出来的，并组合起来构成一个二维数组。</p>
<p>一般来说，当布尔数组的维数小于被索引的数组时，这相当于<code>y[b, ...]</code></p>
<h4 id="组合索引和切片"><a href="#组合索引和切片" class="headerlink" title="组合索引和切片"></a>组合索引和切片</h4><p>索引数组可以与切片组合。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y[np.array([0,2,4]),1:3]</span><br><span class="line">array([[ 1,  2],</span><br><span class="line">       [15, 16],</span><br><span class="line">       [29, 30]])</span><br></pre></td></tr></table></figure>
<p>实际上，切片被转换为索引数组<code>np.array([[1,2]])</code>（形状（1,2）），该数组与索引数组一起广播以产生形状的结果数组（3,2） 。</p>
<p>同样，切片可以与广播布尔指数结合使用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y[b[:,5],1:3]</span><br><span class="line">array([[22, 23],</span><br><span class="line">       [29, 30]])</span><br></pre></td></tr></table></figure>

<h4 id="结构化索引工具"><a href="#结构化索引工具" class="headerlink" title="结构化索引工具"></a>结构化索引工具</h4><p>为了便于将数组形状与表达式和赋值相匹配，可以在数组索引中使用np.newaxis对象来添加大小为1的新维度。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y.shape</span><br><span class="line">(5, 7)</span><br><span class="line">&gt;&gt;&gt; y[:,np.newaxis,:].shape</span><br><span class="line">(5, 1, 7)</span><br></pre></td></tr></table></figure>
<p>请注意，数组中没有新元素，只是增加了维度。这可以很方便地以一种其他方式需要明确重塑操作的方式组合两个数组。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(5)</span><br><span class="line">&gt;&gt;&gt; x[:,np.newaxis] + x[np.newaxis,:]</span><br><span class="line">array([[0, 1, 2, 3, 4],</span><br><span class="line">       [1, 2, 3, 4, 5],</span><br><span class="line">       [2, 3, 4, 5, 6],</span><br><span class="line">       [3, 4, 5, 6, 7],</span><br><span class="line">       [4, 5, 6, 7, 8]])</span><br></pre></td></tr></table></figure>
<p>省略号语法可以用于指示完整地选择任何剩余的未指定的维度。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; z = np.arange(81).reshape(3,3,3,3)</span><br><span class="line">&gt;&gt;&gt; z[1,...,2]</span><br><span class="line">array([[29, 32, 35],</span><br><span class="line">       [38, 41, 44],</span><br><span class="line">       [47, 50, 53]])</span><br></pre></td></tr></table></figure>
<p>这相当于：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; z[1,:,:,2]</span><br><span class="line">array([[29, 32, 35],</span><br><span class="line">       [38, 41, 44],</span><br><span class="line">       [47, 50, 53]])</span><br></pre></td></tr></table></figure>

<h4 id="给被索引的数组赋值"><a href="#给被索引的数组赋值" class="headerlink" title="给被索引的数组赋值"></a>给被索引的数组赋值</h4><p>如前所述，可以使用单个索引，切片以及索引和掩码数组来选择数组的子集。分配给索引数组的值必须是形状一致的（形状与索引产生的形状相同或相同）。例如，允许为切片分配一个常量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(10)</span><br><span class="line">&gt;&gt;&gt; x[2:7] = 1</span><br></pre></td></tr></table></figure>
<p>或者正确大小的数组：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[2:7] = np.arange(5)</span><br></pre></td></tr></table></figure>
<p>请注意，如果将较高类型分配给较低类型（在int类型中添加浮点数（floats））或甚至导致异常（将复数分配给int/float类型），分配可能会导致更改：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[1] = 1.2</span><br><span class="line">&gt;&gt;&gt; x[1]</span><br><span class="line">1</span><br><span class="line">&gt;&gt;&gt; x[1] = 1.2j</span><br><span class="line">&lt;type &#x27;exceptions.TypeError&#x27;&gt;: can&#x27;t convert complex to long; use</span><br><span class="line">long(abs(z))</span><br></pre></td></tr></table></figure>
<p>与一些引用（如数组和掩码索引）不同，赋值通常是对数组中的原始数据进行赋值的（事实上，没有其他意义了！）。但请注意，有些行为可能不会如人们所期望的那样行事。这个特殊的例子通常令人惊讶：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(0, 50, 10)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([ 0, 10, 20, 30, 40])</span><br><span class="line">&gt;&gt;&gt; x[np.array([1, 1, 3, 1])] += 1</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([ 0, 11, 20, 31, 40])</span><br></pre></td></tr></table></figure>
<p>人们预计第一个地点会增加3。实际上，它只会增加1。原因是因为从原始数据（作为临时数据）中提取了一个新的数组，其中包含1,1,1,1,1,1的值，则将值1添加到临时数据中，然后将临时数据分配回原始数组。因此，<code>x[1]+1</code>处的数组值被分配给<code>x[1]</code>三次，而不是递增3次。</p>
<h4 id="处理程序中可变数量的索引"><a href="#处理程序中可变数量的索引" class="headerlink" title="处理程序中可变数量的索引"></a>处理程序中可变数量的索引</h4><p>索引语法非常强大，但在处理可变数量的索引时受到限制。例如，如果你想编写一个可以处理各种维数参数的函数，而不必为每个可能维数编写特殊的代码，那又怎么办？如果向元组提供元组，则该元组将被解释为索引列表。例如（使用数组z的前一个定义）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; z = np.arange(81).reshape(3,3,3,3)</span><br><span class="line">&gt;&gt;&gt; indices = (1,1,1,1)</span><br><span class="line">&gt;&gt;&gt; z[indices]</span><br><span class="line">40</span><br></pre></td></tr></table></figure>
<p>所以可以使用代码来构造任意数量的索引的元组，然后在索引中使用这些元组。</p>
<p>切片可以通过在Python中使用slice()函数在程序中指定。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; indices = (1,1,1,slice(0,2)) # same as [1,1,1,0:2]</span><br><span class="line">&gt;&gt;&gt; z[indices]</span><br><span class="line">array([39, 40])</span><br></pre></td></tr></table></figure>
<p>同样，省略号可以通过使用省略号对象的代码指定：</p>
<p>````</p>
<blockquote>
<blockquote>
<blockquote>
<p>indices = (1, Ellipsis, 1) # same as [1,…,1]<br>z[indices]<br>array([[28, 31, 34],<br>       [37, 40, 43],<br>       [46, 49, 52]])</p>
</blockquote>
</blockquote>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">由于这个原因，可以直接使用np.where()函数的输出作为索引，因为它总是返回索引数组的元组。</span><br><span class="line"></span><br><span class="line">由于元组的特殊处理，它们不会自动转换为列表。举个例子：</span><br></pre></td></tr></table></figure>
<blockquote>
<blockquote>
<blockquote>
<p>z[[1,1,1,1]] # produces a large array<br>array([[[[27, 28, 29],<br>         [30, 31, 32], …<br>z[(1,1,1,1)] # returns a single value<br>40<br>```</p>
</blockquote>
</blockquote>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/" class="post-title-link" itemprop="url">统计学系方法-第4章-朴素贝叶斯法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-21 21:03:44" itemprop="dateCreated datePublished" datetime="2019-08-21T21:03:44+08:00">2019-08-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>朴素贝叶斯（naive Bayes）法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入 x，利用贝叶斯定理求出后验概率的最大输出 y。</p>
<h2 id="朴素贝叶斯法的学习与分类"><a href="#朴素贝叶斯法的学习与分类" class="headerlink" title="朴素贝叶斯法的学习与分类"></a>朴素贝叶斯法的学习与分类</h2><h3 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h3><p>朴素贝叶斯法对条件概率分布作了条件独立性的假设。由于这是一个较强的假设，朴素贝叶斯法也由此得名。具体地，条件独立性假设是 <img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E5%81%87%E8%AE%BE.png" alt="条件独立假设"></p>
<p>朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。这一假设使朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p>
<p>后验概率计算根据贝叶斯定理进行：<img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87.png" alt="后验概率"></p>
<h2 id="朴素贝叶斯法的参数估计"><a href="#朴素贝叶斯法的参数估计" class="headerlink" title="朴素贝叶斯法的参数估计"></a>朴素贝叶斯法的参数估计</h2><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p><img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1.png" alt="极大似然估计"></p>
<h3 id="学习与分类算法"><a href="#学习与分类算法" class="headerlink" title="学习与分类算法"></a>学习与分类算法</h3><p>朴素贝叶斯算法（naive Bayes algorithm）<br><img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95.png" alt="朴素贝叶斯算法"></p>
<h3 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h3><p>用极大似然估计可能会出现所要估计的概率为 0 的情况。这时会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。具体地，条件概率的贝叶斯估计是 <img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1.png" alt="条件概率的贝叶斯估计"> 式中 λ&gt;=0。等价于在随机变量各个取值的频数上赋予一个正数 λ&gt;0。当 λ=0 时就是极大似然估计。常取 λ=1，这时称为拉普拉斯平滑（Laplace smoothing）。显然，对任何 l=1,2,…,K。有 <img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91.png" alt="拉普拉斯平滑">。同样，先验概率的贝叶斯估计是 <img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1.png" alt="先验概率的贝叶斯估计"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/19/%E6%95%B0%E5%AD%A6/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/19/%E6%95%B0%E5%AD%A6/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" class="post-title-link" itemprop="url">A基本概念</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-19 14:57:42" itemprop="dateCreated datePublished" datetime="2019-08-19T14:57:42+08:00">2019-08-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><p>中心极限定理：说明的是在一定条件下，大量独立随机变量的平均数是以正态分布为极限的。而大数定律只是揭示了大量随机变量的平均结果，但没有涉及到随机变量的分布的问题。</p>
</li>
<li><p>大数定律</p>
<ul>
<li>伯努利大数定律：证明了在多次相同的条件的重复试验中，频率有越接近一稳定值的趋势。也告诉了我们当实验次数很大时，可以用事件发生的频率来代替事件的概率。</li>
<li>辛钦大数定律：用算术平均值来近似实际真值是合理的，而在数理统计中，用算术平均值来估计数学期望就是根据此定律，这一定律使算术平均值的法则有了理论依据。</li>
<li>切比雪夫大数定律：随着样本容量n的增加，样本平均数将接近于总体平均数。 从而为统计推断中依据样本平均数估计总体平均数提供了理论依据。 同分布，相较于伯努利大数定律和辛钦大数定律更具一般性。</li>
</ul>
</li>
<li><p>百分位数（percentile）：如果将一组数据从小到大排序，并计算相应的累计百分位，则某一百分位所对应数据的值就称为这一百分位的百分位数。可表示为：一组n个观测值按数值大小排列。如，处于p%位置的值称第p百分位数。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/17/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC3%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/17/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC3%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95/" class="post-title-link" itemprop="url">统计学系方法-第3章-k近邻法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-17 20:11:05" itemprop="dateCreated datePublished" datetime="2019-08-17T20:11:05+08:00">2019-08-17</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>k 近邻法（k-nearest neighbor, k-NN）是一种基本分类与回归方法。</p>
<h2 id="k-近邻算法"><a href="#k-近邻算法" class="headerlink" title="k 近邻算法"></a>k 近邻算法</h2><p>k 近邻算法简单、直观：给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最临近的 k 个 实例，这 k 个实例的多数属于某个类，就把该输入实例分为这个类。</p>
<p><img src="/2019/08/17/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC3%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95/k%E8%BF%91%E9%82%BB%E6%B3%95.png" alt="k近邻法"></p>
<p>k 近邻法的特殊情况是 k=1 的情形，称为最近邻算法。</p>
<h2 id="k-近邻模型"><a href="#k-近邻模型" class="headerlink" title="k 近邻模型"></a>k 近邻模型</h2><p>k 近邻法使用的模型实际上对应于对特征空间的划分。模型由三个基本要素——距离度量、k 值的选择和分类决策规则决定。</p>
<h3 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h3><p>特征空间中两个实例点的距离是两个实例点相似程度的反映。k 近邻模型的特征空间一般是 n 维实数向量空间 Rn。使用的距离是欧式距离，但也可以是其他距离。</p>
<p><img src="/2019/08/17/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC3%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95/%E8%B7%9D%E7%A6%BB.png" alt="距离"></p>
<h3 id="k-值的选择"><a href="#k-值的选择" class="headerlink" title="k 值的选择"></a>k 值的选择</h3><p>k 值的选择会对 k 近邻法的结果产生重大影响。</p>
<p>如果选择较小的 k 值，就相当于用较小的领域中的训练实例进行预测，“学习”的近似误差（approximation error）会减小，只有输入实例较近的（相似的）训练实例才会对预测结果起作用。但缺点是“学习”的估计误差（estimation error）会增大，预测结果会对近邻的实例点非常敏感。如果近邻的实例点恰好是噪声，预测就会出错。换句话说，k 值的减小就意味着整体模型变得复杂，容易发生过拟合。</p>
<p>如果选择较大的 k 值，就相当于用较大领域中的训练实例进行预测。其有点是可以减小学习的估计误差。但缺点是学习的近邻误差会增大。这时与输入实例较远的（不相似的）训练实例也会对预测起作用，使预测发生错误。k 值的增大就意味着整体的模型变得简单。</p>
<p>在应用中，k 值一般取一个比较小的数值。通常采用交叉验证法来选取最优的 k 值。</p>
<h3 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h3><p>k 近邻法的分类决策规则往往是多数表决，即由输入实例的 k 个近邻的训练实例中的多数类决定输入实例的类。</p>
<h2 id="k-近邻法的实现：kd-树"><a href="#k-近邻法的实现：kd-树" class="headerlink" title="k 近邻法的实现：kd 树"></a>k 近邻法的实现：kd 树</h2><p>k 近邻法最简单的实现方法是线性扫描（linear scan）。这时计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，这种方法是不可行的。</p>
<p>为了提高 k 近邻搜索的效率，可以考虑使用特殊的结构存储训练数据，以减少计算距离的次数。</p>
<h3 id="构造-kd-树"><a href="#构造-kd-树" class="headerlink" title="构造 kd 树"></a>构造 kd 树</h3><p>kd 树是一种对 k 维空间中的实例点进行存储以便对其进行快速检索的树形数据结构。kd 树是二叉树，表示对 k 维空间的一个划分（partition）。构造 kd 树相当于不断地用垂直于坐标轴的超平面将 k 维空间切分，构成一系列的 k 维超矩形区域。kd 树的每个结点对应于一个 k 维超矩形区域。</p>
<p>构造 kd 树的方法如下：构造根结点，使根结点对应于 k 维空间中包含所有实例点的超矩形区域；通过下面的递归方法，不断地对 k 维空间进行切分，生成子节点。在超矩形区域（结点）上选择一个坐标轴和在此坐标轴上的一个切分点，确定一个超平面，这个超平面通过选定的切分点并垂直于选定的坐标轴，将当前超矩形区域切分为左右两个子区域（子节点）；这时，实例被分到两个子区域。这个过程直到子区域内没有实例时终止（终止时的结点为叶结点）。在此过程中，将实例保存在相应的结点上。</p>
<p>通常，依次选择坐标轴对空间切分，选择训练实例点在选定坐标轴上的中位数（median）为切分点，这样得到的 kd 树是平衡的。注意，平衡的 kd 树搜索时的效率未必是最优的。</p>
<p><img src="/2019/08/17/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC3%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95/%E6%9E%84%E9%80%A0kd%E6%A0%911.png" alt="构造kd树1"><br><img src="/2019/08/17/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC3%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95/%E6%9E%84%E9%80%A0kd%E6%A0%912.png" alt="构造kd树2"></p>
<h3 id="搜索-kd-树"><a href="#搜索-kd-树" class="headerlink" title="搜索 kd 树"></a>搜索 kd 树</h3><p>给定一个目标点，搜索其最近邻。首选找到包含目标点的叶结点；然后从该叶结点出发，依次回退到父节点；不断查找与目标点最邻近的结点，当确定不可能存在更近的结点时终止。这样搜索就被限制在空间的局部区域上，效率大为提高。</p>
<p>包含目标点的叶结点对应包含目标点的最小超矩形区域。依次叶结点的实例点作为当前最近点。目标点的最近邻一定在以目标点为中心并通过当前最近点的超球体的内部。然后返回当前结点的父节点，如果父节点的另一子节点的超矩形区域与超球体相交，那么在相交的区域内寻找与目标点更近的实例点。如果存在这样的点，将此点作为新的当前最近点。算法赚到更上一级的父节点，继续上述过程。如果父节点的另一子节点的超矩形区域与超球体不相交，或不存在比当前最近点更近的点，则停止搜索。</p>
<p><img src="/2019/08/17/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC3%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95/%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A21.png" alt="最近邻搜索1"><br><img src="/2019/08/17/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC3%E7%AB%A0-k%E8%BF%91%E9%82%BB%E6%B3%95/%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A22.png" alt="最近邻搜索2">  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/16/%E8%AF%AD%E8%A8%80/Python/%E5%85%B6%E4%BB%96/Python-%E4%B8%8B%E5%88%92%E7%BA%BF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/16/%E8%AF%AD%E8%A8%80/Python/%E5%85%B6%E4%BB%96/Python-%E4%B8%8B%E5%88%92%E7%BA%BF/" class="post-title-link" itemprop="url">Python-下划线</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-16 14:13:40" itemprop="dateCreated datePublished" datetime="2019-08-16T14:13:40+08:00">2019-08-16</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/36173202">https://zhuanlan.zhihu.com/p/36173202</a></p>
<ul>
<li>单前导下划线：<code>_var</code></li>
<li>单末尾下划线：<code>var_</code></li>
<li>双前导下划线：<code>__var</code></li>
<li>双前导和末尾下划线：<code>__var__</code></li>
<li>单下划线：<code>_</code></li>
</ul>
<h3 id="单前导下划线-var"><a href="#单前导下划线-var" class="headerlink" title="单前导下划线 _var"></a>单前导下划线 <code>_var</code></h3><p>下划线前缀的含义是告知其他程序员：以单个下划线开头的变量或方法仅供内部使用。 该约定在PEP 8中有定义。</p>
<p>这不是Python强制规定的。 Python不像Java那样在“私有”和“公共”变量之间有很强的区别。</p>
<p>看看下面的例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">class Test:</span><br><span class="line">   def __init__(self):</span><br><span class="line">       self.foo = 11</span><br><span class="line">       self._bar = 23</span><br></pre></td></tr></table></figure>
<p>如果你实例化此类，并尝试访问在<code>__init__</code>构造函数中定义的foo和_bar属性，会发生什么情况？ 让我们来看看：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t = Test()</span><br><span class="line">&gt;&gt;&gt; t.foo</span><br><span class="line">11</span><br><span class="line">&gt;&gt;&gt; t._bar</span><br><span class="line">23</span><br></pre></td></tr></table></figure>
<p>你会看到_bar中的单个下划线并没有阻止我们“进入”类并访问该变量的值。</p>
<p>这是因为Python中的单个下划线前缀仅仅是一个约定 - 至少相对于变量和方法名而言。</p>
<p>但是，前导下划线的确会影响从模块中导入名称的方式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># This is my_module.py:</span><br><span class="line"></span><br><span class="line">def external_func():</span><br><span class="line">   return 23</span><br><span class="line"></span><br><span class="line">def _internal_func():</span><br><span class="line">   return 42</span><br></pre></td></tr></table></figure>
<p>现在，如果使用通配符从模块中导入所有名称，则Python不会导入带有前导下划线的名称（除非模块定义了覆盖此行为的<code>__all__</code>列表）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from my_module import *</span><br><span class="line">&gt;&gt;&gt; external_func()</span><br><span class="line">23</span><br><span class="line">&gt;&gt;&gt; _internal_func()</span><br><span class="line">NameError: &quot;name &#x27;_internal_func&#x27; is not defined&quot;</span><br></pre></td></tr></table></figure>
<p>顺便说一下，应该避免通配符导入，因为它们使名称空间中存在哪些名称不清楚。 为了清楚起见，坚持常规导入更好。</p>
<p>与通配符导入不同，常规导入不受前导单个下划线命名约定的影响：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import my_module</span><br><span class="line">&gt;&gt;&gt; my_module.external_func()</span><br><span class="line">23</span><br><span class="line">&gt;&gt;&gt; my_module._internal_func()</span><br><span class="line">42</span><br></pre></td></tr></table></figure>
<p>我知道这一点可能有点令人困惑。 如果你遵循PEP 8推荐，避免通配符导入，那么你真正需要记住的只有这个：</p>
<blockquote>
<p>单个下划线是一个Python命名约定，表示这个名称是供内部使用的。 它通常不由Python解释器强制执行，仅仅作为一种对程序员的提示。</p>
</blockquote>
<h3 id="单末尾下划线-var"><a href="#单末尾下划线-var" class="headerlink" title="单末尾下划线 var_"></a>单末尾下划线 <code>var_</code></h3><p>有时候，一个变量的最合适的名称已经被一个关键字所占用。 因此，像class或def这样的名称不能用作Python中的变量名称。 在这种情况下，你可以附加一个下划线来解决命名冲突：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; def make_object(name, class):</span><br><span class="line">SyntaxError: &quot;invalid syntax&quot;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; def make_object(name, class_):</span><br><span class="line">...    pass</span><br></pre></td></tr></table></figure>
<p>总之，单个末尾下划线（后缀）是一个约定，用来避免与Python关键字产生命名冲突。 PEP 8解释了这个约定。</p>
<h3 id="双前导下划线-var"><a href="#双前导下划线-var" class="headerlink" title="双前导下划线 __var"></a>双前导下划线 <code>__var</code></h3><p>双下划线前缀会导致Python解释器重写属性名称，以避免子类中的命名冲突。</p>
<p>这也叫做名称修饰（name mangling） - 解释器更改变量的名称，以便在类被扩展的时候不容易产生冲突。</p>
<p>我知道这听起来很抽象。 因此，我组合了一个小小的代码示例来予以说明：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">class Test:</span><br><span class="line">   def __init__(self):</span><br><span class="line">       self.foo = 11</span><br><span class="line">       self._bar = 23</span><br><span class="line">       self.__baz = 23</span><br></pre></td></tr></table></figure>
<p>让我们用内置的dir()函数来看看这个对象的属性：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t = Test()</span><br><span class="line">&gt;&gt;&gt; dir(t)</span><br><span class="line">[&#x27;_Test__baz&#x27;, &#x27;__class__&#x27;, &#x27;__delattr__&#x27;, &#x27;__dict__&#x27;, &#x27;__dir__&#x27;,</span><br><span class="line">&#x27;__doc__&#x27;, &#x27;__eq__&#x27;, &#x27;__format__&#x27;, &#x27;__ge__&#x27;, &#x27;__getattribute__&#x27;,</span><br><span class="line">&#x27;__gt__&#x27;, &#x27;__hash__&#x27;, &#x27;__init__&#x27;, &#x27;__le__&#x27;, &#x27;__lt__&#x27;, &#x27;__module__&#x27;,</span><br><span class="line">&#x27;__ne__&#x27;, &#x27;__new__&#x27;, &#x27;__reduce__&#x27;, &#x27;__reduce_ex__&#x27;, &#x27;__repr__&#x27;,</span><br><span class="line">&#x27;__setattr__&#x27;, &#x27;__sizeof__&#x27;, &#x27;__str__&#x27;, &#x27;__subclasshook__&#x27;,</span><br><span class="line">&#x27;__weakref__&#x27;, &#x27;_bar&#x27;, &#x27;foo&#x27;]</span><br></pre></td></tr></table></figure>
<p>以上是这个对象属性的列表。 让我们来看看这个列表，并寻找我们的原始变量名称<code>foo</code>，<code>_bar</code>和<code>__baz</code> - 我保证你会注意到一些有趣的变化。</p>
<ul>
<li><code>self.foo</code>变量在属性列表中显示为未修改为<code>foo</code>。</li>
<li><code>self._bar</code>的行为方式相同 - 它以<code>_bar</code>的形式显示在类上。 就像我之前说过的，在这种情况下，前导下划线仅仅是一个约定。 给程序员一个提示而已。</li>
<li>然而，对于<code>self.__baz</code>而言，情况看起来有点不同。 当你在该列表中搜索<code>__baz</code>时，你会看不到有这个名字的变量。<br><code>__baz</code>出什么情况了？</li>
</ul>
<p>如果你仔细观察，你会看到此对象上有一个名为<code>_Test__baz</code>的属性。 这就是Python解释器所做的名称修饰。 它这样做是为了防止变量在子类中被重写。</p>
<p>让我们创建另一个扩展Test类的类，并尝试重写构造函数中添加的现有属性：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class ExtendedTest(Test):</span><br><span class="line">   def __init__(self):</span><br><span class="line">       super().__init__()</span><br><span class="line">       self.foo = &#x27;overridden&#x27;</span><br><span class="line">       self._bar = &#x27;overridden&#x27;</span><br><span class="line">       self.__baz = &#x27;overridden&#x27;</span><br></pre></td></tr></table></figure>
<p>现在，你认为<code>foo</code>，<code>_bar</code>和<code>__baz</code>的值会出现在这个ExtendedTest类的实例上吗？ 我们来看一看：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t2 = ExtendedTest()</span><br><span class="line">&gt;&gt;&gt; t2.foo</span><br><span class="line">&#x27;overridden&#x27;</span><br><span class="line">&gt;&gt;&gt; t2._bar</span><br><span class="line">&#x27;overridden&#x27;</span><br><span class="line">&gt;&gt;&gt; t2.__baz</span><br><span class="line">AttributeError: &quot;&#x27;ExtendedTest&#x27; object has no attribute &#x27;__baz&#x27;&quot;</span><br></pre></td></tr></table></figure>
<p>等一下，当我们尝试查看<code>t2.__baz</code>的值时，为什么我们会得到AttributeError？ 名称修饰被再次触发了！ 事实证明，这个对象甚至没有<code>__baz</code>属性：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; dir(t2)</span><br><span class="line">[&#x27;_ExtendedTest__baz&#x27;, &#x27;_Test__baz&#x27;, &#x27;__class__&#x27;, &#x27;__delattr__&#x27;,</span><br><span class="line">&#x27;__dict__&#x27;, &#x27;__dir__&#x27;, &#x27;__doc__&#x27;, &#x27;__eq__&#x27;, &#x27;__format__&#x27;, &#x27;__ge__&#x27;,</span><br><span class="line">&#x27;__getattribute__&#x27;, &#x27;__gt__&#x27;, &#x27;__hash__&#x27;, &#x27;__init__&#x27;, &#x27;__le__&#x27;,</span><br><span class="line">&#x27;__lt__&#x27;, &#x27;__module__&#x27;, &#x27;__ne__&#x27;, &#x27;__new__&#x27;, &#x27;__reduce__&#x27;,</span><br><span class="line">&#x27;__reduce_ex__&#x27;, &#x27;__repr__&#x27;, &#x27;__setattr__&#x27;, &#x27;__sizeof__&#x27;, &#x27;__str__&#x27;,</span><br><span class="line">&#x27;__subclasshook__&#x27;, &#x27;__weakref__&#x27;, &#x27;_bar&#x27;, &#x27;foo&#x27;, &#x27;get_vars&#x27;]</span><br></pre></td></tr></table></figure>
<p>正如你可以看到<code>__baz</code>变成<code>_ExtendedTest__baz</code>以防止意外修改：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t2._ExtendedTest__baz</span><br><span class="line">&#x27;overridden&#x27;</span><br></pre></td></tr></table></figure>
<p>但原来的<code>_Test__baz</code>还在：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; t2._Test__baz</span><br><span class="line">42</span><br></pre></td></tr></table></figure>
<p>双下划线名称修饰对程序员是完全透明的。 下面的例子证实了这一点：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class ManglingTest:</span><br><span class="line">   def __init__(self):</span><br><span class="line">       self.__mangled = &#x27;hello&#x27;</span><br><span class="line"></span><br><span class="line">   def get_mangled(self):</span><br><span class="line">       return self.__mangled</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; ManglingTest().get_mangled()</span><br><span class="line">&#x27;hello&#x27;</span><br><span class="line">&gt;&gt;&gt; ManglingTest().__mangled</span><br><span class="line">AttributeError: &quot;&#x27;ManglingTest&#x27; object has no attribute &#x27;__mangled&#x27;&quot;</span><br></pre></td></tr></table></figure>
<p>名称修饰是否也适用于方法名称？ 是的，也适用。名称修饰会影响在一个类的上下文中，以两个下划线字符（”dunders”）开头的所有名称：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">class MangledMethod:</span><br><span class="line">   def __method(self):</span><br><span class="line">       return 42</span><br><span class="line"></span><br><span class="line">   def call_it(self):</span><br><span class="line">       return self.__method()</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; MangledMethod().__method()</span><br><span class="line">AttributeError: &quot;&#x27;MangledMethod&#x27; object has no attribute &#x27;__method&#x27;&quot;</span><br><span class="line">&gt;&gt;&gt; MangledMethod().call_it()</span><br><span class="line">42</span><br></pre></td></tr></table></figure>
<p>这是另一个也许令人惊讶的运用名称修饰的例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">_MangledGlobal__mangled = 23</span><br><span class="line"></span><br><span class="line">class MangledGlobal:</span><br><span class="line">   def test(self):</span><br><span class="line">       return __mangled</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; MangledGlobal().test()</span><br><span class="line">23</span><br></pre></td></tr></table></figure>
<p>在这个例子中，我声明了一个名为<code>_MangledGlobal__mangled</code>的全局变量。然后我在名为MangledGlobal的类的上下文中访问变量。由于名称修饰，我能够在类的test()方法内，以<code>__mangled</code>来引用<code>_MangledGlobal__mangled</code>全局变量。</p>
<p>Python解释器自动将名称<code>__mangled</code>扩展为<code>_MangledGlobal__mangled</code>，因为它以两个下划线字符开头。这表明名称修饰不是专门与类属性关联的。它适用于在类上下文中使用的两个下划线字符开头的任何名称。</p>
<h3 id="双前导和双末尾下划线-var"><a href="#双前导和双末尾下划线-var" class="headerlink" title="双前导和双末尾下划线 __var__"></a>双前导和双末尾下划线 <code>__var__</code></h3><p>也许令人惊讶的是，如果一个名字同时以双下划线开始和结束，则不会应用名称修饰。 由双下划线前缀和后缀包围的变量不会被Python解释器修改：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">class PrefixPostfixTest:</span><br><span class="line">   def __init__(self):</span><br><span class="line">       self.__bam__ = 42</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; PrefixPostfixTest().__bam__</span><br><span class="line">42</span><br></pre></td></tr></table></figure>
<p>但是，Python保留了有双前导和双末尾下划线的名称，用于特殊用途。 这样的例子有，<code>__init__</code>对象构造函数，或<code>__call__</code> — 它使得一个对象可以被调用。</p>
<p>这些dunder方法通常被称为神奇方法。</p>
<p>最好避免在自己的程序中使用以双下划线（“dunders”）开头和结尾的名称，以避免与将来Python语言的变化产生冲突。</p>
<h3 id="单下划线"><a href="#单下划线" class="headerlink" title="单下划线 _"></a>单下划线 <code>_</code></h3><p>按照习惯，有时候单个独立下划线是用作一个名字，来表示某个变量是临时的或无关紧要的。</p>
<p>例如，在下面的循环中，我们不需要访问正在运行的索引，我们可以使用“_”来表示它只是一个临时值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; for _ in range(32):</span><br><span class="line">...    print(&#x27;Hello, World.&#x27;)</span><br></pre></td></tr></table></figure>
<p>你也可以在拆分(unpacking)表达式中将单个下划线用作“不关心的”变量，以忽略特定的值。 同样，这个含义只是“依照约定”，并不会在Python解释器中触发特殊的行为。 单个下划线仅仅是一个有效的变量名称，会有这个用途而已。</p>
<p>在下面的代码示例中，我将汽车元组拆分为单独的变量，但我只对颜色和里程值感兴趣。 但是，为了使拆分表达式成功运行，我需要将包含在元组中的所有值分配给变量。 在这种情况下，“_”作为占位符变量可以派上用场：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; car = (&#x27;red&#x27;, &#x27;auto&#x27;, 12, 3812.4)</span><br><span class="line">&gt;&gt;&gt; color, _, _, mileage = car</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; color</span><br><span class="line">&#x27;red&#x27;</span><br><span class="line">&gt;&gt;&gt; mileage</span><br><span class="line">3812.4</span><br><span class="line">&gt;&gt;&gt; _</span><br><span class="line">12</span><br></pre></td></tr></table></figure>
<p>除了用作临时变量之外，“_”是大多数Python REPL中的一个特殊变量，它表示由解释器评估的最近一个表达式的结果。</p>
<p>这样就很方便了，比如你可以在一个解释器会话中访问先前计算的结果，或者，你是在动态构建多个对象并与它们交互，无需事先给这些对象分配名字：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 20 + 3</span><br><span class="line">23</span><br><span class="line">&gt;&gt;&gt; _</span><br><span class="line">23</span><br><span class="line">&gt;&gt;&gt; print(_)</span><br><span class="line">23</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; list()</span><br><span class="line">[]</span><br><span class="line">&gt;&gt;&gt; _.append(1)</span><br><span class="line">&gt;&gt;&gt; _.append(2)</span><br><span class="line">&gt;&gt;&gt; _.append(3)</span><br><span class="line">&gt;&gt;&gt; _</span><br><span class="line">[1, 2, 3]</span><br></pre></td></tr></table></figure>

<h3 id="Python下划线命名模式-小结"><a href="#Python下划线命名模式-小结" class="headerlink" title="Python下划线命名模式 - 小结"></a>Python下划线命名模式 - 小结</h3><p><img src="/2019/08/16/%E8%AF%AD%E8%A8%80/Python/%E5%85%B6%E4%BB%96/Python-%E4%B8%8B%E5%88%92%E7%BA%BF/1.png" alt="1"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/" class="post-title-link" itemprop="url">统计学系方法-第2章-感知机</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-15 13:43:22" itemprop="dateCreated datePublished" datetime="2019-08-15T13:43:22+08:00">2019-08-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>感知机（perceptron）是二类分类的线性分类模型，其输入为实例的特征向量，输出为实例的类别，取 +1 和 -1 二值。感知机对应于输入空间（特征空间）中将实例划分为正负两类的分离超平面，属于判别模型。</p>
<h2 id="感知机模型"><a href="#感知机模型" class="headerlink" title="感知机模型"></a>感知机模型</h2><p>由输入空间到输出空间的如下函数 <img src="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B.png" alt="感知机模型"> 称为感知机。其中，w 和 b 为感知机模型参数， w 叫作权值（weight）或权值向量（weight vector），b 叫作偏置（bias）。sign 是符号函数，即 <img src="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/%E7%AC%A6%E5%8F%B7%E5%87%BD%E6%95%B0.png" alt="符号函数"></p>
<h2 id="感知机学习策略"><a href="#感知机学习策略" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h2><h3 id="数据集的线性可分性"><a href="#数据集的线性可分性" class="headerlink" title="数据集的线性可分性"></a>数据集的线性可分性</h3><p>如果存在某个超平面 S 能够将数据集的正实例点和负实例点完全正确地划分到超平面的两侧，则称数据集 T 为线性可分数据集（linearly separable data set）；否则，称数据集 T 线性不可分。</p>
<h3 id="感知机学习策略-1"><a href="#感知机学习策略-1" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h3><p>感知机的损失函数定义为 <img src="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.png" alt="损失函数"> 其中 M 为误分类点的集合。这个损失函数就是感知机学习的经验风险函数。</p>
<p>显然，损失函数 L(w, b) 是非负的。如果没有误分类点，损失函数值是 0.而且，误分类点越少，误分类点离超平面越近，损失函数值越小。</p>
<p>感知机学习的策略是在假设空间中选取使损失函数式最小的模型参数 w 和 b，即感知机模型。</p>
<h2 id="感知机学习算法"><a href="#感知机学习算法" class="headerlink" title="感知机学习算法"></a>感知机学习算法</h2><p>感知机学习问题转化为求解损失函数式的最优化问题，最优化的方法是随机梯度下降法。</p>
<h3 id="感知机学习算法的原始形式"><a href="#感知机学习算法的原始形式" class="headerlink" title="感知机学习算法的原始形式"></a>感知机学习算法的原始形式</h3><p><img src="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/%E7%AE%97%E6%B3%95%E5%8E%9F%E5%A7%8B%E5%BD%A2%E5%BC%8F.png" alt="算法原始形式"></p>
<p>这种学习算法直观上有如下解释：当一个实例点被误分类，即位于分离超平面的错误一侧时，则调整 w, b 的值，使分离超平面向该误分类点的一侧移动，以减小该误分离点与超平面间的距离，直至超平面越过该误分类点使其被正确分类。</p>
<h3 id="算法的收敛性"><a href="#算法的收敛性" class="headerlink" title="算法的收敛性"></a>算法的收敛性</h3><p><img src="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/%E7%AE%97%E6%B3%95%E7%9A%84%E6%94%B6%E6%95%9B%E6%80%A7.png" alt="算法的收敛性"></p>
<h3 id="感知机学习算法的对偶形式"><a href="#感知机学习算法的对偶形式" class="headerlink" title="感知机学习算法的对偶形式"></a>感知机学习算法的对偶形式</h3><p><img src="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/%E5%AF%B9%E5%81%B6%E5%BD%A2%E5%BC%8F%E7%9A%84%E6%80%9D%E8%B7%AF.png" alt="对偶形式的思路"></p>
<p>实例点更新次数越多，意味着它距离分离超平面越近，也就越难正确分类（越容易分错，超平面一动不多就容易将这些点分错），换句话说，这样的实例对学习结果影响最大（在支持向量机中，这些点代表着支持向量）。</p>
<p><img src="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/%E7%AE%97%E6%B3%95%E5%AF%B9%E5%81%B6%E5%BD%A2%E5%BC%8F1.png" alt="算法对偶形式1"><br><img src="/2019/08/15/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC2%E7%AB%A0-%E6%84%9F%E7%9F%A5%E6%9C%BA/%E7%AE%97%E6%B3%95%E5%AF%B9%E5%81%B6%E5%BD%A2%E5%BC%8F2.png" alt="算法对偶形式2"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/" class="post-title-link" itemprop="url">向量点乘（内积）和叉乘（外积、向量积）概念及几何意义解读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-14 15:12:22" itemprop="dateCreated datePublished" datetime="2019-08-14T15:12:22+08:00">2019-08-14</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://blog.csdn.net/dcrmg/article/details/52416832">https://blog.csdn.net/dcrmg/article/details/52416832</a></p>
<p>向量是由n个实数组成的一个 n 行 1 列（n<em>1）或一个 1 行 n 列（1</em>n）的有序数组；</p>
<p>向量的点乘,也叫向量的内积、数量积，对两个向量执行点乘运算，就是对这两个向量对应位一一相乘之后求和的操作，点乘的结果是一个标量。</p>
<h2 id="点乘"><a href="#点乘" class="headerlink" title="点乘"></a>点乘</h2><h3 id="点乘公式"><a href="#点乘公式" class="headerlink" title="点乘公式"></a>点乘公式</h3><p>对于向量a和向量b：<img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E5%90%91%E9%87%8Fa.png" alt="向量a">  <img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E5%90%91%E9%87%8Fb.png" alt="向量b"></p>
<p>a和b的点积公式为：<img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E7%82%B9%E4%B9%98%E5%85%AC%E5%BC%8F.png" alt="点乘公式"></p>
<p>要求一维向量a和向量b的行列数相同。</p>
<h3 id="点乘几何意义"><a href="#点乘几何意义" class="headerlink" title="点乘几何意义"></a>点乘几何意义</h3><p>点乘的几何意义是可以用来表征或计算两个向量之间的夹角，以及在b向量在a向量方向上的投影，有公式：<img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E7%82%B9%E4%B9%98%E5%A4%B9%E8%A7%92.png" alt="点乘夹角"></p>
<p>推导过程如下，首先看一下向量组成：<img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E7%82%B9%E4%B9%98%E5%9B%BE.png" alt="点乘图"></p>
<h2 id="叉乘"><a href="#叉乘" class="headerlink" title="叉乘"></a>叉乘</h2><h3 id="叉乘公式"><a href="#叉乘公式" class="headerlink" title="叉乘公式"></a>叉乘公式</h3><p>两个向量的叉乘，又叫向量积、外积、叉积，叉乘的运算结果是一个向量而不是一个标量。并且两个向量的叉积与这两个向量组成的坐标平面垂直。</p>
<p>对于向量a和向量b：<img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E5%90%91%E9%87%8Fab.png" alt="向量ab"> </p>
<p>a和b的叉乘公式为：<img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E5%8F%89%E4%B9%98%E5%85%AC%E5%BC%8F.png" alt="叉乘公式"> </p>
<p>其中：<img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E5%9F%BA.png" alt="基"> </p>
<h3 id="叉乘几何意义"><a href="#叉乘几何意义" class="headerlink" title="叉乘几何意义"></a>叉乘几何意义</h3><p>在三维几何中，向量a和向量b的叉乘结果是一个向量，更为熟知的叫法是法向量，该向量垂直于a和b向量构成的平面。</p>
<p>在3D图像学中，叉乘的概念非常有用，可以通过两个向量的叉乘，生成第三个垂直于a，b的法向量，从而构建X、Y、Z坐标系。如下图所示：<img src="/2019/08/14/%E6%95%B0%E5%AD%A6/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/%E5%90%91%E9%87%8F%E7%82%B9%E4%B9%98%EF%BC%88%E5%86%85%E7%A7%AF%EF%BC%89%E5%92%8C%E5%8F%89%E4%B9%98%EF%BC%88%E5%A4%96%E7%A7%AF%E3%80%81%E5%90%91%E9%87%8F%E7%A7%AF%EF%BC%89%E6%A6%82%E5%BF%B5%E5%8F%8A%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E8%A7%A3%E8%AF%BB/%E5%8F%89%E4%B9%98%E5%9B%BE.png" alt="叉乘图"> </p>
<p>在二维空间中，叉乘还有另外一个几何意义就是：aXb等于由向量a和向量b构成的平行四边形的面积。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/" class="post-title-link" itemprop="url">统计学系方法-第1章-统计学习方法概论</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-11 21:29:48" itemprop="dateCreated datePublished" datetime="2019-08-11T21:29:48+08:00">2019-08-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="统计学习"><a href="#统计学习" class="headerlink" title="统计学习"></a>统计学习</h2><p>统计学习主要特点：</p>
<ol>
<li>统计学习以计算机及网络为平台，是建立在计算机及网络之上的；</li>
<li>统计学习以数据为研究对象，是数据驱动的学科；</li>
<li>统计学习的目的是对数据进行预测与分析；</li>
<li>统计学习以方法为中心，统计学习方法构建模型并应用模型进行预测与分析；</li>
<li>统计学习是概率论、统计学、信息论、计算理论、最优化理论及计算机科学等多个领域的交叉学科，并且在发展中逐步形成独立的理论体现与方法论。</li>
</ol>
<p>统计学习的组成：</p>
<ul>
<li>监督学习（supervised learning）</li>
<li>非监督学习（unsupervised learning）</li>
<li>半监督学习（semi-supervised learning）</li>
<li>强化学习（reinforcement learning）</li>
</ul>
<p>统计学习方法的三要素：</p>
<ul>
<li>模型（model）</li>
<li>策略（strategy）</li>
<li>算法（algorithm）</li>
</ul>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><p>监督学习的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做出一个好的预测。</p>
<h2 id="统计学习三要素"><a href="#统计学习三要素" class="headerlink" title="统计学习三要素"></a>统计学习三要素</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>在监督学习过程中，模型就是所要学习的条件概率分布或决策函数。模型的假设空间（hypothesis space）包含所有可能的条件概率分布或决策函数。</p>
<h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><h4 id="损失函数和风险函数"><a href="#损失函数和风险函数" class="headerlink" title="损失函数和风险函数"></a>损失函数和风险函数</h4><h5 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h5><p>监督学习问题是在假设空间 F 中选取模型 f 作为决策函数，对于给定的输入 X，由 f(X) 给出相应的输出 Y，这个输出的预测值 f(X) 与真实值 Y 可能一致也可能不一致，用一个损失函数（loss function）或代价函数（cost function）来度量预测错误的程度。损失函数是 f(x) 和 Y 的非负实值函数，记作 <code>L(Y, f(X))</code>。</p>
<p>常用的损失函数：</p>
<ol>
<li>0-1损失函数（0-1 loss function)<br><img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/01.png" alt="0-1损失函数"></li>
<li>平方损失函数(quadratic loss function)<br><img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/quadratic.png" alt="平方损失函数"></li>
<li>绝对损失函数（absolute loss function）<br><img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/absolute.png" alt="绝对损失函数"></li>
<li>对数损失函数（logarithmic loss function）或对数似然损失函数（loglikelihood loss function）<br><img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/logarithmic.png" alt="对数损失函数"></li>
</ol>
<h5 id="风险函数"><a href="#风险函数" class="headerlink" title="风险函数"></a>风险函数</h5><p>损失函数数值越小，模型就越好。由于模型的输入、输出 (X, Y) 是随机变量，遵循联合分布 P(X, Y)，所以损失函数的期望是<img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E6%9C%9F%E6%9C%9B.png" alt="损失函数的期望"></p>
<p>这是理论上模型 f(X) 关于联合分布 P(X, Y) 的平均意义下的损失，称为风险函数（risk funciton）或期望损失（expected loss）。</p>
<p>学习的目标就是选择期望风险最小的模型。由于联合分布是未知的，所以损失函数的期望不能直接计算。</p>
<p>给定一个训练数据集<img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86T.png" alt="训练数据集T">。模型 f(X) 关于训练数据集的平均损失称为经验风险（empirical risk）或经验损失风险（empirical loss），记作：<img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/%E7%BB%8F%E9%AA%8C%E6%8D%9F%E5%A4%B1%E9%A3%8E%E9%99%A9.png" alt="经验损失风险"></p>
<p>根据大数定律，当样本容量 N 趋于无穷时，经验风险趋于期望风险。</p>
<h4 id="经验风险最小化与结构风险最小化"><a href="#经验风险最小化与结构风险最小化" class="headerlink" title="经验风险最小化与结构风险最小化"></a>经验风险最小化与结构风险最小化</h4><h5 id="经验风险"><a href="#经验风险" class="headerlink" title="经验风险"></a>经验风险</h5><p>在假设空间、损失函数以及训练数据集确定的情况下，经验风险函数式就可以确定。经验风险最小化（empirical risk minimization，ERM）的策略认为，经验风险最小的模型是最优的模型。</p>
<p>当样本容量足够大时，经验风险最小化能保证有很好的学习效果。比如，极大似然估计（maximum likelihood estimation）就是经验风险最小化的例子。当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等驾驭极大似然估计。</p>
<p>但是，当样本容量很小时，经验风险最小化学习的效果就未必很好，就产生“过拟合（over-fitting）“现象。</p>
<h4 id="结构风险"><a href="#结构风险" class="headerlink" title="结构风险"></a>结构风险</h4><p>结构风险最小化（structural risk minimization，SRM）是为了防止过拟合而提出来的策略。结构风险最小化等价于正则化（regularization）。结构风险在经验风险上加上表示模型复杂度的正则化项（regularizer）或罚项（penalty term）。在假设空间、损失函数以及训练数据集确定的情况下，结构风险的定义是：<img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/%E7%BB%93%E6%9E%84%E9%A3%8E%E9%99%A9.png" alt="结构风险">。其中 J(f) 为模型的复杂度，是定义在假设空间 F 上的泛函。模型 f 越复杂，复杂度 J(f) 就越大；反之，模型 f 越简单，复杂度 J(f) 就越小。</p>
<p>比如，贝叶斯估计中的最大后验概率估计（maximum posterior probability estimation，MAP）就是结构风险最小化的例子。当模型是条件概率分布、损失函数是对数损失函数、模型复杂度由模型的先验概率表示时，结构风险最小化就等驾驭最大后验概率估计。</p>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>算法是指学习模型的具体计算方法。</p>
<h2 id="模型评估与模型选择"><a href="#模型评估与模型选择" class="headerlink" title="模型评估与模型选择"></a>模型评估与模型选择</h2><h3 id="训练误差与测试误差"><a href="#训练误差与测试误差" class="headerlink" title="训练误差与测试误差"></a>训练误差与测试误差</h3><p>统计学习方法具体采用的损失函数未必是评估时使用的损失函数。当然，让两者一致是比较理想的。</p>
<h3 id="过拟合与模型选择"><a href="#过拟合与模型选择" class="headerlink" title="过拟合与模型选择"></a>过拟合与模型选择</h3><p>如果一味追求提高对训练数据的预测能力，所选模型的复杂度则往往会比真模型更高，这种现象称为过拟合（over-fitting）。过拟合是指学习时选择的模型所包含的参数过多，以至于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。</p>
<p><img src="/2019/08/11/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC1%E7%AB%A0-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E6%A6%82%E8%AE%BA/%E8%AE%AD%E7%BB%83%E8%AF%AF%E5%B7%AE%E4%B8%8E%E6%B5%8B%E8%AF%95%E8%AF%AF%E5%B7%AE.png" alt="训练误差与测试误差"></p>
<p>当模型的复杂度增大时，训练误差会逐渐减小并趋向于0；而测试误差会先减小，达到最小值后又增大。当选择的模型复杂度过于大时，过拟合现象就会发生。这样，在学习时就要防止过拟合，进行最优的模型选择，即选择复杂度适当的模型，以达到使测试误差最小的学习目的。下面介绍两种常用的模型选择方法：正则化与交叉验证。</p>
<h3 id="正则化与交叉验证"><a href="#正则化与交叉验证" class="headerlink" title="正则化与交叉验证"></a>正则化与交叉验证</h3><h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><p>模型选择的典型方法使正则化（regularization）。正则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项（regularizer）或罚项（penalty term）。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大。</p>
<p>正则化符合奥卡姆剃刀（Occam’s razor）原理。奥卡姆剃刀原理应用于模型选择时为以下想法：在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型，也就是应该选择的模型。从贝叶斯估计的角度来看，正则化项对应于模型的先验概率。可以假设复杂的模型有较小的先验概率，简单的模型有较大的先验概率。</p>
<h4 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h4><p>如果给定的样本数据充足，进行模型选择的一种简单方法是随机地将数据集切分成三部分，分为训练集（training set）、验证集（validation set）和测试集（test set）。训练集用来训练模型，验证集用于模型的选择，而测试集用于最终学习方法的评估。</p>
<p>但是，在许多实际应用中数据是不充足的。为了选择好的模型，可以采用交叉验证方法。交叉验证的基本想法是重复地使用数据；把给定的数据进行切分，将切分的数据集组合为训练集与测试集，在此基础上反复地进行训练、测试以及模型选择。</p>
<h5 id="简单交叉验证"><a href="#简单交叉验证" class="headerlink" title="简单交叉验证"></a>简单交叉验证</h5><p>简单交叉验证方法是：首先随机地将已给数据分为两部分，一部分作为训练集，另一部分作为测试集；然后用训练集在各种条件下训练模型，从而得到不同的模型；在测试集上评价各个模型的测试误差，选出测试误差最小的模型。</p>
<h5 id="S-折交叉验证"><a href="#S-折交叉验证" class="headerlink" title="S 折交叉验证"></a>S 折交叉验证</h5><p>应用最多的是 S 折交叉验证（S-flod cross validation)，方法如下：首先随机地将已给数据切分为 S 个互不相交的大小相同的子集；然后利用 S-1 个子集的数据训练模型，利用余下的子集测试模型；将这一过程对可能的 S 种选择重复进行；最后选出 S 次评测中平均测试误差最小的模型。</p>
<h5 id="留一交叉验证"><a href="#留一交叉验证" class="headerlink" title="留一交叉验证"></a>留一交叉验证</h5><p>S 折交叉验证的特殊情形是 S=N，称为留一交叉验证（leave-one-out cross validation），往往在数据缺乏的情况下使用。这里，N 是给定数据集的容量。</p>
<h3 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h3><h4 id="泛化误差"><a href="#泛化误差" class="headerlink" title="泛化误差"></a>泛化误差</h4><p>学习方法的泛化能力（generalization ability）是指由该方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。现实中采用最多的办法是通过测试误差来评价学习方法的泛化能力。</p>
<p>事实上，泛化误差就是所学习到的模型的期望风险。</p>
<h4 id="泛化误差上界"><a href="#泛化误差上界" class="headerlink" title="泛化误差上界"></a>泛化误差上界</h4><p>学习方法的泛化能力分析往往是通过研究泛化误差的概率上界进行的，简称为泛化误差上界（generalizaiton error bound）。具体来说，就是通过比较两种学习方法的泛化误差上界的大小来比较它们的优劣。泛化误差上界通常具有以下性质：它是样本容量的函数，当样本容量增加时，泛化上界趋于0；它是假设空间容量（capacity）的函数，假设空间容量越大，模型就越难学，泛化误差上界就越大。</p>
<h3 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h3><p>监督学习的任务就是学习一个模型，应用这一模型，对给定的输入预测相应的输出。这个模型的一般形式为决策函数：Y=f(X) 或者条件概率分布：P(Y|X)。</p>
<p>监督学习方法又可分为生成方法（generative approach）和判别方法（discriminative approach）。所学习到的模型分别称为生成模型（generative model）和判别模型（discriminative model）。</p>
<p>生成方法由数据学习联合概率分布 P(X, Y)，然后求出条件概率分布 P(Y|X) 作为预测的模型。这样的方法之所以称为生成方法。是因为模型表示了给定输入 X 产生输出 Y 的生成关系。典型的生成模型由：朴素贝叶斯法和隐马尔可夫模型。</p>
<p>判别方法由数据直接学习决策函数 f(X) 或者条件概率分布 P(Y|X) 作为预测的模型，即判别模型。判别方法关系的是对给定的输入 X，应该预测什么样的输出 Y。典型的判别模型包括：k 近邻法、感知机、决策树、逻辑斯蒂回归模型、最大熵模型、支持向量机、提升方法和条件随机场等。</p>
<p>生成方法的特点：生成方法可以还原出联合概率分布 P(X, Y)，而判别方法则不能；生成方法的学习收敛更快，即当样本容量增加的时候，学习的模型可以更快地收敛于真实模型；当存在隐变量时，仍可以用生成方法学习，此时判断方法就不能用。</p>
<p>判别方法的忒点：判别方法直接学习的是条件概率 P(Y|X) 或决策函数 f(X)，直接面对预测，往往学习的准确率更高；由于直接学习 P(Y|X) 或 f(X)，可以对数据进行个各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。</p>
<h3 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h3><p>在监督学习中，当输入变量 Y 取有限个离散值时，预测问题便称为分类问题。这时，输入变量 X 可以是离散的，也可以是连续的。监督学习从数据中学习一个分离诶模型或分类决策函数，称为分类器（classifier）。分类器对新的输入进行输出的预测（prediction），称为分类（classification）。可能的输出称为类（class）。分类的类别为多个时，称为多类分类问题。</p>
<p>评价分类器性能的指标一般是分类准确率（accuracy），其定义是：对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。也就是损失函数是 0-1 损失时测试数据集上的准确率。</p>
<h3 id="标注问题"><a href="#标注问题" class="headerlink" title="标注问题"></a>标注问题</h3><p>标注（tagging）也是一个监督学习问题。可以认为标注问题是分类问题的一个推广，标注问题又是更复杂的结构预测（structure prediction）问题的简单形式。标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。标注问题的目标在于学一个模型，使它能够对观测序列给出标记序列作为预测。注意，可能的标记个数是有限的，但其组合所成的标记序列的个数是依序列长度呈指数级增长的。</p>
<p>标注常用的统计学习方法有：隐马尔可夫模型、条件随机场。</p>
<h3 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h3><p>回归用于预测输入变量（自变量）和输出变量（因变量）之间的关系，特别是当输入变量的值发生变化时，输出变量的值随之发生的变化。</p>
<p>回归问题按照输入变量的个数，分为一元回归和多元回归；按照输入变量和输出变量之前的关系的类型即模型的类型，分类线性回归和非线性回归。</p>
<p>回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以由著名的最小二乘法（least squares）求解。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/12/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><span class="page-number current">13</span><a class="page-number" href="/page/14/">14</a><span class="space">&hellip;</span><a class="page-number" href="/page/69/">69</a><a class="extend next" rel="next" href="/page/14/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhang Wetts"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhang Wetts</p>
  <div class="site-description" itemprop="description">Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">681</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">67</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">349</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wetts" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wetts" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhang.wetts@163.com" title="E-Mail → mailto:zhang.wetts@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhang Wetts</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hibiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
</html>
