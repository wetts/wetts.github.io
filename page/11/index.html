<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wetts.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Stay Hungry, Stay Foolish. [build by hexo&#x2F;next&#x2F;gitalk&#x2F;hexo-generator-search&#x2F;LaTeX]">
<meta property="og:type" content="website">
<meta property="og:title" content="Wetts&#39;s blog">
<meta property="og:url" content="https://wetts.github.io/page/11/index.html">
<meta property="og:site_name" content="Wetts&#39;s blog">
<meta property="og:description" content="Stay Hungry, Stay Foolish. [build by hexo&#x2F;next&#x2F;gitalk&#x2F;hexo-generator-search&#x2F;LaTeX]">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Zhang Wetts">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://wetts.github.io/page/11/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Wetts's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Wetts's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Stay Hungry, Stay Foolish.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/wetts" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/11/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E4%BB%BF%E5%B0%84%E5%87%BD%E6%95%B0%E5%92%8C%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/11/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E4%BB%BF%E5%B0%84%E5%87%BD%E6%95%B0%E5%92%8C%E7%BA%BF%E6%80%A7%E5%87%BD%E6%95%B0/" class="post-title-link" itemprop="url">仿射函数和线性函数</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-11 14:07:48" itemprop="dateCreated datePublished" datetime="2019-09-11T14:07:48+08:00">2019-09-11</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>仿射函数即由 1 阶多项式构成的函数，一般形式为 <code>f(x)=Ax+b</code>，这里，A 是一个 m×k 矩阵，x 是一个 k 向量，b 是一个 m 向量，实际上反映了一种从 k 维到 m 维的空间映射关系。设 f 是一个矢性（值）函数，若它可以表示为 <code>f(x1,x2,…,xn)=A1x1+A2x2+…+Anxn+b</code>，其中 Ai 可以是标量，也可以是矩阵，则称f是仿射函数。其中的特例是，标性（值）函数 <code>f(x)=ax+b</code>，其中 a、x、b 都是标量。此时严格讲，只有 b=0 时，仿射函数才可以叫“线性函数”（“正比例”关系）。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/" class="post-title-link" itemprop="url">微积分-拉格朗日对偶性</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-10 13:45:42" itemprop="dateCreated datePublished" datetime="2019-09-10T13:45:42+08:00">2019-09-10</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在约束最优化问题中，常常利用拉格朗日对偶性（Lagrange duality）将原始问题转换为对偶问题，通常解对偶问题而得到原始问题的解。该方法应用在许多统计学习方法中，例如，最大熵模型与支持向量机。</p>
<h3 id="原始问题"><a href="#原始问题" class="headerlink" title="原始问题"></a>原始问题</h3><p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%98.png" alt="原始问题"></p>
<p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%982.png" alt="原始问题2"></p>
<p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%983.png" alt="原始问题3"></p>
<p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%984.png" alt="原始问题4"></p>
<h3 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h3><p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98.png" alt="对偶问题"></p>
<h3 id="原始问题和对偶问题的关系"><a href="#原始问题和对偶问题的关系" class="headerlink" title="原始问题和对偶问题的关系"></a>原始问题和对偶问题的关系</h3><p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%98%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E6%9C%80%E4%BC%98%E5%80%BC.png" alt="原始问题与对偶问题最优值"></p>
<p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%98%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E6%8E%A8%E8%AE%BA1.png" alt="原始问题与对偶问题推论1"></p>
<p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%98%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E5%AE%9A%E7%90%862.png" alt="原始问题与对偶问题定理2"></p>
<p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%98%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E5%AE%9A%E7%90%863-1.png" alt="原始问题与对偶问题定理3-1"></p>
<p><img src="/2019/09/10/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E6%80%A7/%E5%8E%9F%E5%A7%8B%E9%97%AE%E9%A2%98%E4%B8%8E%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E5%AE%9A%E7%90%863-2.png" alt="原始问题与对偶问题定理3-2"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/" class="post-title-link" itemprop="url">矩阵求导实例</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-09-05 17:30:48" itemprop="dateCreated datePublished" datetime="2019-09-05T17:30:48+08:00">2019-09-05</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/wlzy/p/8007045.html">https://www.cnblogs.com/wlzy/p/8007045.html</a></p>
<h2 id="前提及说明"><a href="#前提及说明" class="headerlink" title="前提及说明"></a>前提及说明</h2><p>第一次遇见矩阵求导，大多数人都是一头雾水，而搜了维基百科看也还是云里雾里，一堆的名词和一堆的表格到底都是什么呢？这里总结了我个人的学习经验，并且通过一个例子可以让你感受如何进行矩阵求导，下次再遇到需要进行矩阵求导的地方就不会措手不及。</p>
<p>在进行概念的解说之前，首先大家需要先知道下面的这个前提：</p>
<blockquote>
<p>前提： 若 x 为向量，则默认 x 为列向量， xT 为行向量</p>
</blockquote>
<h2 id="布局的概念"><a href="#布局的概念" class="headerlink" title="布局的概念"></a>布局的概念</h2><p>布局简单地理解就是分子 y 、分母 x 是行向量还是列向量。</p>
<ul>
<li>分子布局（Numerator-layout）：分子为 y 或者分母为 xT (即，分子为列向量或者分母为行向量)</li>
<li>分母布局（Denominator-layout）：分子为 yT 或者分母为 x (即，分子为行向量或者分母为列向量)</li>
</ul>
<p>为了更加深刻地理解两种布局的特点和区别，下面是从维基百科中布局部分拿来的例子</p>
<h3 id="分子布局"><a href="#分子布局" class="headerlink" title="分子布局"></a>分子布局</h3><ul>
<li>标量/向量：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E5%AD%90%E5%B8%83%E5%B1%80-%E6%A0%87%E9%87%8Fd%E5%90%91%E9%87%8F.png" alt="分子布局-标量d向量">（分母的向量为行向量）</li>
<li>向量/标量：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E5%AD%90%E5%B8%83%E5%B1%80-%E5%90%91%E9%87%8Fd%E6%A0%87%E9%87%8F.png" alt="分子布局-向量d标量">（分子的向量为列向量）</li>
<li>向量/向量：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E5%AD%90%E5%B8%83%E5%B1%80-%E5%90%91%E9%87%8Fd%E5%90%91%E9%87%8F.png" alt="分子布局-向量d向量">（分子为列向量横向平铺，分母为行向量纵向平铺）</li>
<li>标量/矩阵：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E5%AD%90%E5%B8%83%E5%B1%80-%E6%A0%87%E9%87%8Fd%E7%9F%A9%E9%98%B5.png" alt="分子布局-标量d矩阵">（注意这个矩阵部分是转置的，而下面的分母布局是非转置的）</li>
<li>矩阵/标量：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E5%AD%90%E5%B8%83%E5%B1%80-%E7%9F%A9%E9%98%B5d%E6%A0%87%E9%87%8F.png" alt="分子布局-矩阵d标量"></li>
</ul>
<h3 id="分母布局"><a href="#分母布局" class="headerlink" title="分母布局"></a>分母布局</h3><ul>
<li>标量/向量：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E6%AF%8D%E5%B8%83%E5%B1%80-%E6%A0%87%E9%87%8Fd%E5%90%91%E9%87%8F.png" alt="分母布局-标量d向量">（分母的向量为列向量）</li>
<li>向量/标量：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E6%AF%8D%E5%B8%83%E5%B1%80-%E5%90%91%E9%87%8Fd%E6%A0%87%E9%87%8F.png" alt="分母布局-向量d标量">（分子的向量为行向量）</li>
<li>向量/向量：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E6%AF%8D%E5%B8%83%E5%B1%80-%E5%90%91%E9%87%8Fd%E5%90%91%E9%87%8F.png" alt="分母布局-向量d向量">（分子为行向量纵向平铺，分母为列向量横向平铺）</li>
<li>标量/矩阵：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%88%86%E6%AF%8D%E5%B8%83%E5%B1%80-%E6%A0%87%E9%87%8Fd%E7%9F%A9%E9%98%B5.png" alt="分母布局-标量d矩阵">（矩阵部分为原始矩阵）</li>
</ul>
<h2 id="一个求导的例子"><a href="#一个求导的例子" class="headerlink" title="一个求导的例子"></a>一个求导的例子</h2><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E9%97%AE%E9%A2%98.png" alt="问题"></p>
<blockquote>
<p>说明： y、w为列向量，X为矩阵</p>
</blockquote>
<h3 id="式子演化"><a href="#式子演化" class="headerlink" title="式子演化"></a>式子演化</h3><p>看到这个例子不要急着去查表求导，先看看它的形式，是 <img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%BC%8F%E5%AD%90%E6%BC%94%E5%8C%96.png" alt="式子演化"> 的形式，这种形式一般求导较为复杂，因此为了简化运算，我们先把式子展开成下面的样子（注意：<img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%BC%8F%E5%AD%90%E6%BC%94%E5%8C%962.png" alt="式子演化2"> ： ）</p>
<p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%BC%8F%E5%AD%90%E6%BC%94%E5%8C%963.png" alt="式子演化3"></p>
<p>然后就可以写成四个部分求导的形式如下（累加后求导=求导后累加）： </p>
<p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E5%BC%8F%E5%AD%90%E6%BC%94%E5%8C%964.png" alt="式子演化4"></p>
<h3 id="求导"><a href="#求导" class="headerlink" title="求导"></a>求导</h3><ul>
<li><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E6%B1%82%E5%AF%BC1.png" alt="求导1"></li>
</ul>
<p>说明：分子部分为标量，分母部分为向量，找到维基百科中的Scalar-by-vector identities表格，在表格中匹配形式到第1行的位置，因为分母为列向量，因此为分母布局，对应的求导结果就是 0 。</p>
<ul>
<li><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E6%B1%82%E5%AF%BC2.png" alt="求导2"></li>
</ul>
<p>说明：同样的，在维基百科中的Scalar-by-vector identities表格，在表格中匹配形式到第11行的位置。</p>
<ul>
<li><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E6%B1%82%E5%AF%BC3.png" alt="求导3"></li>
</ul>
<p>说明：因为分子为标量，标量的转置等于本身，所以对分子进行转置操作，其等价于第二部分。</p>
<ul>
<li><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E6%B1%82%E5%AF%BC4.png" alt="求导4"></li>
</ul>
<p>说明：同样的，在维基百科中的Scalar-by-vector identities表格，在表格中匹配形式到第13行的位置。</p>
<h3 id="整合"><a href="#整合" class="headerlink" title="整合"></a>整合</h3><p>把四个部分求导结果进行相应的加减就可以得到最终的结果： </p>
<ul>
<li><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E6%95%B4%E5%90%88.png" alt="整合"></li>
</ul>
<hr>
<ul>
<li><p>分子布局，即按照 y 和xT (相比较于x)的布局。（求导结果中分子保持原始形式，分母为转置形式）</p>
</li>
<li><p>分母布局, 即按照 yT 和 x (相比较于y)。（求导结果中分子为转置形式，分母保持原始形式）</p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC1.png" alt="表格1"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC2.png" alt="表格2"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC3.png" alt="表格3"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC4.png" alt="表格4"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC5.png" alt="表格5"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC6.png" alt="表格6"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC7.png" alt="表格7"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC8.png" alt="表格8"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC9.png" alt="表格9"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC10.png" alt="表格10"></p>
</li>
<li><p><img src="/2019/09/05/%E6%95%B0%E5%AD%A6/%E5%85%B6%E4%BB%96/%E7%9F%A9%E9%98%B5%E6%B1%82%E5%AF%BC%E5%AE%9E%E4%BE%8B/%E8%A1%A8%E6%A0%BC11.png" alt="表格11"></p>
</li>
</ul>
<hr>
<h2 id="附录：公式推导"><a href="#附录：公式推导" class="headerlink" title="附录：公式推导"></a>附录：公式推导</h2><h3 id="公式一"><a href="#公式一" class="headerlink" title="公式一"></a>公式一</h3><p>对任意行向量 $\mathbf{w} = (w_1, w_2, \cdots w_n)$ 都有<br>$$<br>\left.\frac{\partial(\mathbf{w} \mathbf{x})}{\partial \mathbf{x}}=\left[\begin{array}{c}{\frac{\partial(\mathbf{w} \mathbf{x})}{x_{1}}} \ {\frac{\partial(\mathbf{w} \mathbf{x})}{x_{2}}} \ {\vdots} \ {\frac{\partial(\mathbf{w} \mathbf{x})}{x_{n}}}\end{array}\right]=\left[\begin{array}{c}{\frac{\partial\left(w_1 x_1+w_2 x_{2}+\cdots+w_{n} x_{n}\right)}{x_{1}}} \ {\frac{\partial\left(w_{1} x_{1}+w_{2} x_{2}+\cdots+w_{n} x_{n}\right)}{x_{2}}} \ {\vdots} \ {\frac{\partial\left(w_1 x_1+w_2 x_{2}+\cdots+w_{n} x_{n}\right)}{x_{n}}}\end{array}\right]=\left[\begin{array}{c}{w_{1}} \ {w_{2}} \ {\vdots} \ {w_{n}}\end{array}\right]=\mathbf{w}^{T}\right.<br>$$<br>同时注意,如果 $\mathbf{w}$ 表示一个列向量，则<br>$$<br>\frac{\partial\left(\mathbf{x}^{\mathrm{T}} \mathbf{w}\right)}{\partial \mathbf{x}}=\mathbf{w}<br>$$</p>
<h3 id="公式二"><a href="#公式二" class="headerlink" title="公式二"></a>公式二</h3><p>$\mathbf{A}$ 表示一个矩阵，其中 $\mathbf{a_1, a_2, \cdots a_n}$ 表示行向量<br>$$<br>\mathbf{A}=\left(\mathbf{a}<em>{\mathbf{1}}, \mathbf{a}</em>{2}, \cdots, \mathbf{a}<em>{\mathbf{n}}\right)^{T}<br>$$<br>都有<br>$$<br>\frac{\partial(\mathbf{A} \mathbf{x})}{\partial \mathbf{x}}=\frac{\partial\left(\mathbf{a}</em>{1} \mathbf{x}, \mathbf{a}<em>{2} \mathbf{x}, \cdots, \mathbf{a}</em>{\mathbf{n}} \mathbf{x}\right)^{T}}{\partial \mathbf{x}}=\left(\mathbf{a}<em>{1}^{T}, \mathbf{a}</em>{2}^{T}, \cdots, \mathbf{a}<em>{\mathbf{n}}^{T}\right)=\mathbf{A}^{T}<br>$$<br>$\mathbf{B}$ 表示一个矩阵，其中 $\mathbf{b_1, b_2, \cdots b_n}$ 表示列向量<br>$$<br>\mathbf{B}=\left(\mathbf{b}</em>{\mathbf{1}}, \mathbf{b}<em>{2}, \cdots, \mathbf{b}</em>{\mathbf{n}}\right)<br>$$<br>都有<br>$$<br>\frac{\partial\left(\mathbf{x}^{\mathrm{T}} \mathbf{B}\right)}{\partial \mathbf{x}}=\frac{\partial\left(\mathbf{x}^{\mathrm{T}} \mathbf{b}<em>{1}, \mathbf{x}^{\mathrm{T}} \mathbf{b}</em>{2}, \cdots, \mathbf{x}^{\mathrm{T}} \mathbf{b}<em>{\mathbf{n}}\right)}{\partial \mathbf{x}}=\left(\mathbf{b}</em>{1}, \mathbf{b}<em>{2}, \cdots, \mathbf{b}</em>{\mathbf{n}}\right)=\mathbf{B}<br>$$</p>
<h3 id="公式三"><a href="#公式三" class="headerlink" title="公式三"></a>公式三</h3><p>$$<br>\frac{\partial\left(\mathbf{x}^{\mathrm{T}} \mathbf{x}\right)}{\partial \mathbf{x}}=\left[\begin{array}{c}{\frac{\partial \mathbf{x}^{\mathrm{T}} \mathbf{x}}{x_{1}}} \ {\frac{\partial \mathbf{x}^{\mathrm{T}} \mathbf{x}}{x_2}} \ {\vdots} \ {\frac{\partial \mathbf{x}^{\mathrm{T}} \mathbf{x}}{x_{n}}}\end{array}\right]=\left[\begin{array}{c}{\frac{\partial\left(x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2}\right)}{x_{1}}} \ {\frac{\partial\left(x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2}\right)}{x_{2}}} \ {\vdots} \ {\frac{\partial\left(x_{1}^{2}+x_{2}^{2}+\cdots+x_{n}^{2}\right)}{x_{n}}}\end{array}\right]=\left[\begin{array}{c}{2 x_{1}} \ {2 x_{2}} \ {\vdots} \ {2 x_{n}}\end{array}\right]=2 \mathbf{x}<br>$$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/" class="post-title-link" itemprop="url">微积分-拉格朗日乘子法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-30 09:11:00" itemprop="dateCreated datePublished" datetime="2019-08-30T09:11:00+08:00">2019-08-30</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://www.matongxue.com/madocs/939.html">https://www.matongxue.com/madocs/939.html</a></p>
<h3 id="与原点的最短距离"><a href="#与原点的最短距离" class="headerlink" title="与原点的最短距离"></a>与原点的最短距离</h3><p>假如有方程：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1"></p>
<p>图像是这个样子滴：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/2.png" alt="2"></p>
<p>现在我们想求其上的点与原点的最短距离：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/3.gif" alt="3"></p>
<p>这里介绍一种解题思路。首先，与原点距离为 a 的点全部在半径为 a 的圆上：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/4.gif" alt="4"></p>
<p>那么，我们逐渐扩大圆的半径：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/5.gif" alt="5"></p>
<p>显然，第一次与 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1"> 相交的点就是距离原点最近的点：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/6.png" alt="6"></p>
<p>此时，圆和曲线相切，也就是在该点切线相同：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/7.png" alt="7"></p>
<p>至此，我们分析出了：<strong>在极值点，圆与曲线相切</strong></p>
<h3 id="等高线"><a href="#等高线" class="headerlink" title="等高线"></a>等高线</h3><p><img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/8.png" alt="8"></p>
<p>可以看作函数 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/9.png" alt="9"> 的等高线：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/10.png" alt="10"></p>
<p>梯度向量：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/11.png" alt="11"></p>
<p>是等高线的法线：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/12.png" alt="12"></p>
<p>另外一个函数 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/13.png" alt="13"> 的等高线为：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/14.png" alt="14"></p>
<p>之前的曲线 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1"> 就是其中值为3的等高线：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/15.png" alt="15"></p>
<p>因此，梯度向量：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/16.png" alt="16"></p>
<p>也垂直于等高线 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1">：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/17.png" alt="17"></p>
<p>梯度向量是等高线的法线，更准确地表述是：<strong>梯度与等高线的切线垂直</strong></p>
<h3 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="headerlink" title="拉格朗日乘子法"></a>拉格朗日乘子法</h3><h4 id="求解"><a href="#求解" class="headerlink" title="求解"></a>求解</h4><p>根据之前的两个分析：</p>
<ol>
<li>在极值点，圆与曲线相切</li>
<li>梯度与等高线的切线垂直</li>
</ol>
<p>综合可知，在相切点，圆的梯度向量和曲线的梯度向量平行：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/18.gif" alt="18"></p>
<p>也就是梯度向量平行，用数学符号表示为：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/19.png" alt="19"></p>
<p>还必须引入 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/1.png" alt="1"> 这个条件，否则这么多等高线，不知道指的是哪一根：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/20.png" alt="20"></p>
<p>因此联立方程：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/21.png" alt="21"></p>
<p>求一下试试：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/22.png" alt="22"></p>
<p>这就是拉格朗日乘子法。</p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>要求函数 f 在 g 约束下的极值这种问题可以表示为：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/23.png" alt="23"></p>
<p><em>s.t.</em> 意思是subject to，服从于，约束于的意思。</p>
<p>可以列出方程组进行求解：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/24.png" alt="24"></p>
<p>用这个定义来翻译下刚才的例子，要求：</p>
<p>令：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/25.png" alt="25"></p>
<p>求：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/26.png" alt="26"></p>
<p>联立方程进行求解：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/27.png" alt="27"></p>
<h4 id="变形"><a href="#变形" class="headerlink" title="变形"></a>变形</h4><p>这个定义还有种变形也比较常见，要求：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/23.png" alt="23"></p>
<p>定义：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/28.png" alt="28"></p>
<p>求解下面方程组即可得到答案：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/29.png" alt="29"></p>
<p>把等式左边的偏导算出来就和上面的定义是一样的了。</p>
<h4 id="多个约束条件"><a href="#多个约束条件" class="headerlink" title="多个约束条件"></a>多个约束条件</h4><p>如果增加一个约束条件呢？比如说：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/30.png" alt="30"></p>
<p>求：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/31.png" alt="31"></p>
<p>从图上看约束条件是这样的：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/32.png" alt="32"></p>
<p>很显然所求的距离是这样的：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/33.png" alt="33"></p>
<p>那这三者的法线又有什么关系呢？<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/34.png" alt="34"> 的法线是 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/35.png" alt="35"> 和 <img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/36.png" alt="36"> 的法线的线性组合：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/37.png" alt="37"></p>
<p>假设：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/38.png" alt="38"></p>
<p>那么线性组合就表示为：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/39.png" alt="39"></p>
<p>联立方程：<img src="/2019/08/30/%E6%95%B0%E5%AD%A6/%E5%BE%AE%E7%A7%AF%E5%88%86/%E5%BE%AE%E7%A7%AF%E5%88%86-%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/40.png" alt="40"></p>
<p>即可求解。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/" class="post-title-link" itemprop="url">统计学系方法-第6章-逻辑斯谛回归与最大熵模型</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-29 11:37:12" itemprop="dateCreated datePublished" datetime="2019-08-29T11:37:12+08:00">2019-08-29</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>逻辑斯谛回归（logistic regression）是统计学习中的经典分类方法。最大熵是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型（maximum entropy model）。逻辑斯蒂回归模型与最大熵模型都属于对数线性模型。</p>
<h2 id="逻辑斯谛回归模型"><a href="#逻辑斯谛回归模型" class="headerlink" title="逻辑斯谛回归模型"></a>逻辑斯谛回归模型</h2><h3 id="逻辑斯谛分布"><a href="#逻辑斯谛分布" class="headerlink" title="逻辑斯谛分布"></a>逻辑斯谛分布</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%88%86%E5%B8%83.png" alt="逻辑斯谛分布"> </p>
<h3 id="二项逻辑斯谛回归模型"><a href="#二项逻辑斯谛回归模型" class="headerlink" title="二项逻辑斯谛回归模型"></a>二项逻辑斯谛回归模型</h3><p>二项逻辑斯谛回归模型（binomial logistic regression model）是一种分类模型，由条件概率分布 P(Y|X) 表示，形式为参数化的逻辑斯谛分布。这里，随机变量 X 取值为实数，随机变量 Y 取值为 1 或 0。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E4%BA%8C%E9%A1%B9%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B.png" alt="二项逻辑斯谛回归模型"> </p>
<p>一个事件的几率（odds）是指该事件发生的概率与该事件不发生的概率的比值。如果事件发生的概率是 p，那么该事件的几率是 p/(1-p)，该事件的对数几率（log odds）或 logit 函数是 <img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/logit.png" alt="logit"></p>
<p>对逻辑斯谛回归而言，<img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E5%87%A0%E7%8E%87.png" alt="逻辑斯谛回归几率"></p>
<p>这就是说，在逻辑斯谛回归模型中，输出 Y=1 的对数几率是输入 x 的线性函数。或者说，输出 Y=1 的对数几率是由输入 x 的线性函数表示的模型，即逻辑斯谛回归模型。</p>
<h3 id="模型参数估计"><a href="#模型参数估计" class="headerlink" title="模型参数估计"></a>模型参数估计</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1.png" alt="逻辑斯谛回归-模型参数估计"></p>
<h3 id="多项逻辑斯谛回归"><a href="#多项逻辑斯谛回归" class="headerlink" title="多项逻辑斯谛回归"></a>多项逻辑斯谛回归</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%A4%9A%E9%A1%B9%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92.png" alt="多项逻辑斯谛回归"></p>
<h2 id="最大熵模型"><a href="#最大熵模型" class="headerlink" title="最大熵模型"></a>最大熵模型</h2><p>最大熵模型（maximum entropy model）由最大熵原理推导实现。</p>
<h3 id="最大熵原理"><a href="#最大熵原理" class="headerlink" title="最大熵原理"></a>最大熵原理</h3><p>最大熵原理是概率模型学习的一个准则。最大熵原理认为，学习概率模型时，在所有可能的概率模型（分布）中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足条件的模型集合中选取熵最大的模型。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E7%86%B5.png" alt="熵"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E5%87%A0%E4%BD%95%E8%A7%A3%E9%87%8A1.png" alt="最大熵几何解释1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E5%87%A0%E4%BD%95%E8%A7%A3%E9%87%8A2.png" alt="最大熵几何解释2"></p>
<h3 id="最大熵模型的定义"><a href="#最大熵模型的定义" class="headerlink" title="最大熵模型的定义"></a>最大熵模型的定义</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%891.png" alt="最大熵模型的定义1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%892.png" alt="最大熵模型的定义2"></p>
<h3 id="最大熵模型的学习"><a href="#最大熵模型的学习" class="headerlink" title="最大熵模型的学习"></a>最大熵模型的学习</h3><p>最大熵模型的学习过程就是求解最大熵模型的过程。最大熵模型的学习可以形式化为约束最优化问题。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A01.png" alt="最大熵模型的学习1"></p>
<p>求解上述约束最优问题，所得出的解，就是最大熵模型学习的解。</p>
<p>将约束最优化的原始问题转换为无约束最优化的对偶问题。通过求解对偶问题求解原始问题。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E5%AF%B9%E5%81%B6%E5%BD%A2%E5%BC%8F.png" alt="拉格朗日对偶形式"></p>
<p>由于拉格朗日函数 L(P, w) 是 P 的凸函数，原始问题（6.18）的解与对偶问题（6.19）的解是等价的。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A31.png" alt="对偶问题求解1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A32.png" alt="对偶问题求解2"></p>
<h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E5%81%B6%E5%87%BD%E6%95%B0%E6%9E%81%E5%A4%A7%E5%8C%96%E7%AD%89%E4%BB%B7%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E8%AF%81%E6%98%8E1.png" alt="对偶函数极大化等价于最大熵模型的极大似然估计证明1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/%E5%AF%B9%E5%81%B6%E5%87%BD%E6%95%B0%E6%9E%81%E5%A4%A7%E5%8C%96%E7%AD%89%E4%BB%B7%E4%BA%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E8%AF%81%E6%98%8E2.png" alt="对偶函数极大化等价于最大熵模型的极大似然估计证明2"></p>
<h2 id="模型学习的最优化算法"><a href="#模型学习的最优化算法" class="headerlink" title="模型学习的最优化算法"></a>模型学习的最优化算法</h2><p>逻辑斯谛回归模型、最大熵模型学习归结为似然函数为目标函数的最优化问题，通常通过迭代算法求解。从最优化的观点看，这时的目标函数具有很好的性质。它是光滑的凸函数，因此多种最优化的方法都适用，保证能找到全局最优解。常用的方法有改进的迭代尺度法、梯度下降法、牛顿法或拟牛顿法。牛顿法或拟牛顿法一般收敛速度更快。</p>
<h3 id="改进的迭代尺度法"><a href="#改进的迭代尺度法" class="headerlink" title="改进的迭代尺度法"></a>改进的迭代尺度法</h3><p>改进的迭代尺度法（improved iterative scaling, IIS）是一种最大熵模型学习的最优化算法。</p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/IIS.png" alt="IIS"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/IIS%E7%AE%97%E6%B3%951.png" alt="IIS算法1"></p>
<p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/IIS%E7%AE%97%E6%B3%952.png" alt="IIS算法2"></p>
<h3 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h3><p><img src="/2019/08/29/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC6%E7%AB%A0-%E9%80%BB%E8%BE%91%E6%96%AF%E8%B0%9B%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/BFGS.png" alt="BFGS"></p>
<hr>
<p>Logistic Regression：根据周志华老师的讲法，这里 logistic 是对数几率的意思，所以正确的翻译方法应该叫 __对数几率回归__，所以不要以为这个东西叫 __逻辑回归__，逻辑回归是错误的翻译。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/" class="post-title-link" itemprop="url">统计学系方法-第5章-决策树</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-24 18:37:12" itemprop="dateCreated datePublished" datetime="2019-08-24T18:37:12+08:00">2019-08-24</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>决策树（decision tree）是一种基本的分类与回归方法。决策树模型呈树形结构，在分类问题中，表示基于特征对实例进行分类的过程。它可以认为是 if-then 规则的集合，也可以认为是定义在特征空间与类空间伤的条件概率分布。其主要优点是模型具有可读性，分类速度快。学习时，利用训练数据，根据损失函数最小化的原则简历决策树模型。预测时，对新的数据，利用决策树模型进行分类。决策树学习通常包括 3 个步骤：特征选择、决策树的生成和决策树的修剪。</p>
<h2 id="决策树模型与学习"><a href="#决策树模型与学习" class="headerlink" title="决策树模型与学习"></a>决策树模型与学习</h2><h3 id="决策树模型"><a href="#决策树模型" class="headerlink" title="决策树模型"></a>决策树模型</h3><p>分类决策树模型是一种描述对实例进行分类的树形结构。决策树由结点（node）和有向边（directed edge）组成。结点有两种类型：内部结点（internal node）和叶结点（leaf node）。内部结点表示一个特征或属性，叶结点表示一个类。</p>
<p>用决策树分类，从根结点开始，对实例的某一特征进行测试，根据测试结果，将实例分配到其子节点；这时，每一个子节点对应着该特征的一个取值。如此递归地对实例进行测试并分配，直至达到叶结点。最后将实例分到叶结点的类中。</p>
<h3 id="决策树与-if-then-规则"><a href="#决策树与-if-then-规则" class="headerlink" title="决策树与 if-then 规则"></a>决策树与 if-then 规则</h3><p>可以将决策树看成一个 if-then 规则的集合。将决策树转换成 if-then 规则的过程是这样的：由决策树的根结点到叶结点的每一条路径构建一条规则；路径上内部结点的特征对应着规则的条件，而叶结点的类对应着规则的结论。决策树的路径或其对应的 if-then 规则集合具有一个重要的性质：互斥并且完备。这就是说，每一个实例都被一条路径或一条规则所覆盖，而且只被一条路径或一条规则所覆盖。这里所谓的覆盖是指实例的特征与路径上的特征一致或实例满足规则的条件。</p>
<h3 id="决策树与条件概率分布"><a href="#决策树与条件概率分布" class="headerlink" title="决策树与条件概率分布"></a>决策树与条件概率分布</h3><p>决策树还表示给定特征条件下类的条件概率分布。这一条件概率分布定义在特征空间的一个划分（partition）上。将特征空间划分为互不相交的单元（cell）或区域（region），并在每个单元定义一个类的概率分布就构成了一个条件概率分布。决策树的一条路径对应于划分中的一个单元。决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。假设 X 为表示特征的随机变量，Y 为表示类的随机变量，那么这个条件概率分布可以表示为 P(Y|X)。X 取值于给定划分下单元的集合，Y 取值于类的集合。各叶结点（单元）上的条件概率往往偏向某一个类，即属于某一类的概率较大。决策树分类时将该结点的实例强行分到条件概率的那一类去。</p>
<h3 id="决策树学习"><a href="#决策树学习" class="headerlink" title="决策树学习"></a>决策树学习</h3><p>决策树学习本质上是从训练数据集中归纳出一组分类规则。与训练数据集不相矛盾的决策树（即能对训练数据进行正确分类的决策树）可能有多个，也可能一个也没有。我们需要的是一个与训练数据矛盾较小的决策树，同时具有较好的泛化能力。从另一个角度看，决策树学习是由训练数据集估计条件概率模型。基于特征空间划分的类的条件概率模型有无穷多个。我们选择的条件概率模型应该不仅对训练数据有很好的拟合，而且对位置数据有很好的预测。</p>
<p>决策树学习用损失函数表示这一目标。决策树学习的损失函数通常是正则化的极大似然函数。决策树学习的策略是以损失函数为目标函数的最小化。</p>
<p>决策树学习的算法通常是一个递归地选择最优特征，并根据该特征对训练数据进行分割，使得各个子数据集有一个最好的分类的过程。</p>
<p>以上方法生成的决策树可能对训练数据有很好的分类能力，但对未知的测试数据却未必有很好的分类能力，即可能发生过拟合现象。我们需要对已生成的树自下而上进行剪枝，将树变得更简单，从而使它具有更好的泛化能力。</p>
<p>如果特征数量很多，也可以在决策树学习开始的时候，对特征进行选择，只留下对训练数据有足够分类能力的特征。</p>
<p>决策树学习算法包含特征选择、决策树的生成与决策树的剪枝过程。由于决策树表示一个条件概率分布，所以深浅不同的决策树对应着不同复杂度的概率模型。决策树的生成对应于模型的局部选择，决策树的剪枝对应于模型的全局选择。决策树的生成只考虑局部最优，相对地，决策树的剪枝则考虑全局最优。</p>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><h3 id="特征选择问题"><a href="#特征选择问题" class="headerlink" title="特征选择问题"></a>特征选择问题</h3><p>特征选择在于选取对训练数据具有分类能力的特征。这样可以提高决策树学习的效率。如果利用一个特征进行分类的结果与随机分类的结果没有很大差别，则称这个特征是没有分类能力的。经验上扔掉这样的特征对决策树学习的精度影响不大。通常特征选择的准则是信息增益或信息增益比。</p>
<h3 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h3><p>在信息论与概率统计中，熵（entropy）是表示随机变量不确定性的度量。设 X 是一个取有限个值的离散随机变量，其概率分布为 P(X=xi)=pi，i=1,2,…,n，则随机变量 X 的熵的定义为 <img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E7%86%B5.png" alt="熵"> </p>
<p>设有随机变量(X, Y)，其联合概率分布为 P(X=xi, Y=yj)=pij, i=1,2,…,n; j=1,2,…,m，条件熵 H(Y|X) 表示在已知随机变量 X 的条件下随机变量 Y 的不确定性。随机变量 X 给定的条件下随机变量 Y 的条件熵（conditional entropy）H(Y|X)，定义为 X 给定条件下 Y 的条件概率分布的熵对 X 的数学期望 <img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%9D%A1%E4%BB%B6%E7%86%B5.png" alt="条件熵">，这里，pi=P(X=xi), i=1,2,…,n</p>
<p>当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为经验熵（empirical entropy）和经验条件熵（empirical conditional entropy）。此时如果有 0 概率，令 0log0=0。</p>
<p>信息增益（information gain）表示得知特征 X 的信息而使得类 Y 的信息不确定性减少的程度。</p>
<p><strong>信息增益：</strong> 特征 A 对训练数据集 D 的信息增益 g(D, A)，定义为集合 D 的经验熵 H(D) 与特征 A 给定条件下 D 的经验条件熵 H(D|A) 之差。即 <code>g(D, A) = H(D) - H(D|A)</code></p>
<p>一般地，熵 H(Y) 与条件熵 H(Y|X) 之差称为互信息（mutual information）。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。</p>
<p>信息增益大的特征具有更强分类能力。</p>
<p>根据信息增益准则的特征选择方法是：对训练数据集（或子集）D，计算其每个特征的信息增益，并比较它们的大小，选择信息增益最大的特征。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%AE%97%E6%B3%951.png" alt="信息增益算法1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%AE%97%E6%B3%952.png" alt="信息增益算法2"> </p>
<h3 id="信息增益比"><a href="#信息增益比" class="headerlink" title="信息增益比"></a>信息增益比</h3><p>以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题。使用信息增益比（information gain ratio）可以对这一问题进行校正。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E6%AF%94.png" alt="信息增益比"> </p>
<h2 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h2><h3 id="ID3-算法"><a href="#ID3-算法" class="headerlink" title="ID3 算法"></a>ID3 算法</h3><p>ID3 算法的核心是在决策树各个节点上应用信息增益准则选择特征，递归地构建决策树。具体方法是：从根结点（root node）开始，对结点计算所有可能的特征信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子节点；再对子节点递归地调用以上方法，构建决策树；直到所有特征的信息增益均很小或没有特征可以选择为止。最后得到一个决策树。ID3 相当于用极大似然法进行概率模型的选择。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/ID3.png" alt="ID3"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/ID3-2.png" alt="ID3-2"> </p>
<p>ID3 算法只有树的生成，所以该算法生成的树容易产生过拟合。</p>
<h3 id="C4-5-的生成算法"><a href="#C4-5-的生成算法" class="headerlink" title="C4.5 的生成算法"></a>C4.5 的生成算法</h3><p>C4.5 算法与 ID3 算法相似，C4.5 算法对 ID3 算法进行了改进。C4.5 在生成的过程中，用信息增益比来选择特征。<br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/C4.5%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95.png" alt="C4.5生成算法"> </p>
<h2 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h2><p>决策树生成算法递归地产生决策树，直到不能继续下去为止。这样产生的树往往对训练数据的分类很准确，但对未知的测试数据的分类却没有那么准确，即出现过拟合现象。过拟合的原因在于学习时过多地考虑如何提高对训练数据的正确分类，从而构建出过于复杂的决策树。解决这个问题的办法是考虑决策树的复杂度，对已生成的决策树进行简化。</p>
<p>在决策树学习中将已生成的树进行简化的过程称为剪枝（pruning）。具体地，剪枝从已生成的树上裁掉一些子树或叶结点，并将其根结点或父节点作为新的叶结点，从而简化分类树模型。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%951.png" alt="剪枝算法1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%952.png" alt="剪枝算法2"> </p>
<p>剪枝，就是当 α 确定时，选择损失函数最小的模型，即损失函数最小的子树。当 α 值确定时，子树越大，往往与训练数据的拟合越好，但是模型的复杂度就越高；相反，子树越小，模型的复杂度就越低，但是往往与训练数据的拟合不好。损失函数正好表示了对两者的平衡。</p>
<p>可以看出，决策树生成只考虑了通过提高信息增益（或信息增益比）对训练数据进行更好的拟合。而决策树剪枝通过优化损失函数还考虑减小模型复杂度。决策树生成学习局部的模型，而决策树剪枝学习整体的模型。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%A0%91%E7%9A%84%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%951.png" alt="树的剪枝算法1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%A0%91%E7%9A%84%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%952.png" alt="树的剪枝算法2"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%A0%91%E7%9A%84%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%953.png" alt="树的剪枝算法3"> </p>
<h2 id="CART-算法"><a href="#CART-算法" class="headerlink" title="CART 算法"></a>CART 算法</h2><p>分类与回归树（classification and regression tree, CART）模型由 Breiman 等人在 1984年提出，是应用广泛的决策树学习方法。CART 同样由特征选择、树的生成及剪枝组成，即可以用于分类也可以用于回归。以下将用于分类与回归的树统称为决策树。</p>
<p>CART 是在给定输入随机变量 X 条件下输出随机变量 Y 的条件概率分布的学习方法。CART 假设决策树是二叉树，内部结点特征的取值为“是”与“否”，左分支是取值为“是”的分支，右分支是取值为“否”的分支。这样的决策树等价于递归地二分每个特征，将输入空间即特征空间划分为有限个单元，并在这些单元上确定预测的概率分布，也就是在输入给定的条件下输出的条件概率分布。</p>
<p>CART 算法由以下两步组成：</p>
<ol>
<li>决策树生成：基于训练数据集生成决策树，生成的决策树要尽量大；</li>
<li>决策树剪枝：用验证数据集对已生成的树进行剪枝并选择最优子树，这时用损失函数最小作为剪枝的标准。</li>
</ol>
<h3 id="CART-生成"><a href="#CART-生成" class="headerlink" title="CART 生成"></a>CART 生成</h3><p>决策树的生成就是递归地构建二叉决策树的过程。对回归树用平方误差最小化准则，对分类树用基尼指数（Gini index）最小化准则，进行特征选择，生成二叉树。</p>
<h4 id="回归树的生成"><a href="#回归树的生成" class="headerlink" title="回归树的生成"></a>回归树的生成</h4><p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E5%9B%9E%E5%BD%92%E6%A0%91%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95.png" alt="最小二乘回归树生成算法"> </p>
<h4 id="分类树的生成"><a href="#分类树的生成" class="headerlink" title="分类树的生成"></a>分类树的生成</h4><p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B01.png" alt="基尼指数1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/%E5%9F%BA%E5%B0%BC%E6%8C%87%E6%95%B02.png" alt="基尼指数2"> </p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/CART%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%951.png" alt="CART生成算法1"><br><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/CART%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%952.png" alt="CART生成算法2"> </p>
<h3 id="CART-剪枝"><a href="#CART-剪枝" class="headerlink" title="CART 剪枝"></a>CART 剪枝</h3><p>CART 剪枝算法从“完全生长”的决策树的底端剪去一些子树，使决策树变小（模型变简单），从而能够对未知数据有更准确的预测。CART 剪枝算法由两步组成：首先从生成算法产生的决策树 T0底端开始不断剪枝，直到 T0 的根结点，形成一个子树序列 {T0, T1,…Tn}；然后通过交叉验证法在独立的验证数据集上对子树序列进行测试，从中选择最优子树。</p>
<p><img src="/2019/08/24/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/CART%E5%89%AA%E6%9E%9D%E7%AE%97%E6%B3%95.png" alt="CART剪枝算法 "> </p>
<hr>
<h3 id="附西瓜书第4章-决策树部分内容"><a href="#附西瓜书第4章-决策树部分内容" class="headerlink" title="附西瓜书第4章-决策树部分内容"></a>附西瓜书第4章-决策树部分内容</h3><p>决策树的剪枝（pruning）的基本策略有“预剪枝”（prepruning）和“后剪枝”（postpruning）。预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点；后剪枝则是先从训练集生成一颗完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为子节点。</p>
<p>后剪枝决策树通常比预剪枝决策树保留了更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/22/%E8%AF%AD%E8%A8%80/Python/API/numpy/Python-numpy-newaxis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/22/%E8%AF%AD%E8%A8%80/Python/API/numpy/Python-numpy-newaxis/" class="post-title-link" itemprop="url">Python-numpy-newaxis</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-22 20:33:12" itemprop="dateCreated datePublished" datetime="2019-08-22T20:33:12+08:00">2019-08-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>转自：<a target="_blank" rel="noopener" href="https://blog.csdn.net/xtingjie/article/details/72510834">https://blog.csdn.net/xtingjie/article/details/72510834</a></p>
<p>numpy中包含的newaxis可以给原数组增加一个维度</p>
<p>np.newaxis放的位置不同，产生的新数组也不同</p>
<p>一维数组</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">x</span><br><span class="line">Out[48]: array([4, 6, 6, 6, 5])</span><br><span class="line"></span><br><span class="line">x1 = x[np.newaxis, :]</span><br><span class="line"></span><br><span class="line">x1</span><br><span class="line">Out[50]: array([[4, 6, 6, 6, 5]])</span><br><span class="line"></span><br><span class="line">x2 = x[:, np.newaxis]</span><br><span class="line"></span><br><span class="line">x2</span><br><span class="line">Out[52]: </span><br><span class="line">array([[4],</span><br><span class="line">       [6],</span><br><span class="line">       [6],</span><br><span class="line">       [6],</span><br><span class="line">       [5]])</span><br></pre></td></tr></table></figure>
<p>由以上代码可以看出，当把newaxis放在前面的时候</p>
<p>以前的shape是5，现在变成了1×5，也就是前面的维数发生了变化，后面的维数发生了变化</p>
<p>而把newaxis放后面的时候，输出的新数组的shape就是5×1，也就是后面增加了一个维数</p>
<p>所以，newaxis放在第几个位置，就会在shape里面看到相应的位置增加了一个维数</p>
<p>如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">x = np.random.randint(1, 8, size=(2, 3, 4))</span><br><span class="line">y = x[:, np.newaxis, :, :]</span><br><span class="line">z = x[:, :, np.newaxis, :]</span><br><span class="line"></span><br><span class="line">x.shape</span><br><span class="line">Out: (2, 3, 4)</span><br><span class="line"></span><br><span class="line">y.shape</span><br><span class="line">Out: (2, 1, 3, 4)</span><br><span class="line"></span><br><span class="line">z.shape</span><br><span class="line">Out: (2, 3, 1, 4)</span><br></pre></td></tr></table></figure>

<h4 id="一般问题"><a href="#一般问题" class="headerlink" title="一般问题"></a>一般问题</h4><p>经常会遇到这样的问题，需要从数组中取出一部分的数据，也就是取出“一片”或者“一条”</p>
<p>比如需要从二维数组里面抽取一列</p>
<p>取出来之后维度却变成了一维</p>
<p>假如我们需要将其还原为二维，就需要上面的方法了</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/22/%E8%AF%AD%E8%A8%80/Python/API/numpy/Python-numpy-%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%87%E7%89%87/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/22/%E8%AF%AD%E8%A8%80/Python/API/numpy/Python-numpy-%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%87%E7%89%87/" class="post-title-link" itemprop="url">Python-numpy-索引与切片</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-22 14:55:49" itemprop="dateCreated datePublished" datetime="2019-08-22T14:55:49+08:00">2019-08-22</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>参考：<a target="_blank" rel="noopener" href="https://www.numpy.org.cn/user_guide/numpy_basics/indexing.html">https://www.numpy.org.cn/user_guide/numpy_basics/indexing.html</a></p>
<h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><h4 id="单个元素索引"><a href="#单个元素索引" class="headerlink" title="单个元素索引"></a>单个元素索引</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(10)</span><br><span class="line">&gt;&gt;&gt; x[2]</span><br><span class="line">2</span><br><span class="line">&gt;&gt;&gt; x[-2]</span><br><span class="line">8</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; x.shape = (2,5) # now x is 2-dimensional</span><br><span class="line">&gt;&gt;&gt; x[1,3]</span><br><span class="line">8</span><br><span class="line">&gt;&gt;&gt; x[1,-1]</span><br><span class="line">9</span><br><span class="line">&gt;&gt;&gt; x[0]</span><br><span class="line">array([0, 1, 2, 3, 4])</span><br></pre></td></tr></table></figure>
<p>指定的每个索引都会选择与所选维度的其余部分相对应的数组。在上面的例子中，选择0表示长度为5的剩余维度未指定，并且返回的是具有该维度和大小的数组。必须注意的是，返回的数组不是原始数据的副本，而是指向与原始数组相同的内存值。在这种情况下，返回第一个位置（0）处的一维数组。因此，在返回的数组上使用单个索引会导致返回一个元素。那是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[0][2]</span><br><span class="line">2</span><br></pre></td></tr></table></figure>
<p>因此，请注意，<code>x[0, 2] = x[0][2]</code>， 但是第二种情况效率更低，因为一个新的临时数组在第一个索引后创建了，这个临时数组随后才被2这个数字索引。</p>
<h4 id="其他索引选项"><a href="#其他索引选项" class="headerlink" title="其他索引选项"></a>其他索引选项</h4><p>可以对数组进行切片和步进，以提取具有相同数量维数的数组，但其大小与原始数据不同。切片和跨步的工作方式与对列表和元组完全相同，除此之外它们还可以应用于多个维度。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(10)</span><br><span class="line">&gt;&gt;&gt; x[2:5]</span><br><span class="line">array([2, 3, 4])</span><br><span class="line">&gt;&gt;&gt; x[:-7]</span><br><span class="line">array([0, 1, 2])</span><br><span class="line">&gt;&gt;&gt; x[1:7:2]</span><br><span class="line">array([1, 3, 5])</span><br><span class="line">&gt;&gt;&gt; y = np.arange(35).reshape(5,7)</span><br><span class="line">&gt;&gt;&gt; y[1:5:2,::3]</span><br><span class="line">array([[ 7, 10, 13],</span><br><span class="line">       [21, 24, 27]])</span><br></pre></td></tr></table></figure>
<p>请注意，数组切片不会复制内部数组数据，但也会产生原始数据的新视图。</p>
<h4 id="索引数组"><a href="#索引数组" class="headerlink" title="索引数组"></a>索引数组</h4><p>数组索引指的是使用方括号（[]）来索引数组值。有很多选项来索引，这使numpy索引很强大，但功能上的强大也带来一些复杂性和潜在的混乱。</p>
<p>索引数组必须是整数类型。数组中的每个值指示数组中要使用哪个值来代替索引。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(10,1,-1)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([10,  9,  8,  7,  6,  5,  4,  3,  2])</span><br><span class="line">&gt;&gt;&gt; x[np.array([3, 3, 1, 8])]</span><br><span class="line">array([7, 7, 9, 2])</span><br></pre></td></tr></table></figure>

<p>索引值超出范围是错误的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[np.array([3, 3, 20, 8])]</span><br><span class="line">&lt;type &#x27;exceptions.IndexError&#x27;&gt;: index 20 out of bounds 0&lt;=index&lt;9</span><br></pre></td></tr></table></figure>
<p>一般来说，使用索引数组时返回的是与索引数组具有相同形状的数组，但是索引数组的类型和值。作为一个例子，我们可以使用多维索引数组来代替：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[np.array([[1,1],[2,3]])]</span><br><span class="line">array([[9, 9],</span><br><span class="line">       [8, 7]])</span><br></pre></td></tr></table></figure>

<h4 id="索引多维数组"><a href="#索引多维数组" class="headerlink" title="索引多维数组"></a>索引多维数组</h4><p>对多维数组进行索引时，情况会变得更加复杂，特别是对于多维索引数组。这些往往是更常用的用途，但它们是允许的，并且它们对于一些问题是有用的。我们将从最简单的多维情况开始：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y = np.arange(35).reshape(5,7)</span><br><span class="line">&gt;&gt;&gt; y[np.array([0,2,4]), np.array([0,1,2])]</span><br><span class="line">array([ 0, 15, 30])</span><br></pre></td></tr></table></figure>
<p>在这种情况下，如果索引数组具有匹配的形状，并且索引数组的每个维都有一个索引数组，则结果数组具有与索引数组相同的形状，并且这些值对应于每个索引集的索引在索引数组中的位置。在此示例中，两个索引数组的第一个索引值为0，因此结果数组的第一个值为<code>y[0, 0]</code>。下一个值是<code>y[2, 1]</code>，最后一个是<code>y[4, 2]</code>。</p>
<p>广播机制允许索引数组与其他索引的标量组合。结果是标量值用于索引数组的所有对应值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y[np.array([0,2,4]), 1]</span><br><span class="line">array([ 1, 15, 29])</span><br></pre></td></tr></table></figure>
<p>跳到复杂性的下一个级别，可以只用索引数组部分索引数组。理解在这种情况下会发生什么需要一些思考。例如，如果我们只使用一个索引数组与y：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y[np.array([0,2,4])]</span><br><span class="line">array([[ 0,  1,  2,  3,  4,  5,  6],</span><br><span class="line">       [14, 15, 16, 17, 18, 19, 20],</span><br><span class="line">       [28, 29, 30, 31, 32, 33, 34]])</span><br></pre></td></tr></table></figure>
<p>什么结果是一个新的数组的结构，其中索引数组的每个值从被索引的数组中选择一行，并且结果数组具有结果形状（行的大小，数字索引元素）。</p>
<p>这可能有用的一个示例是用于颜色查找表，我们想要将图像的值映射到RGB三元组中进行显示。查找表可能有一个形状（nlookup，3）。使用带有dtype = np.uint8（或任何整数类型，只要值与查找表的边界）形状（ny，nx）的图像索引这样一个数组将导致一个形状数组（ny，nx， 3）RGB值的三倍与每个像素位置相关联。</p>
<p>通常，resulant数组的形状将是索引数组形状（或所有索引数组广播的形状）与索引数组中任何未使用的维（未索引的维）的形状的串联。</p>
<h4 id="布尔值或掩码索引数组"><a href="#布尔值或掩码索引数组" class="headerlink" title="布尔值或掩码索引数组"></a>布尔值或掩码索引数组</h4><p>用作索引的布尔数组的处理方式完全不同于索引数组。布尔数组的形状必须与被索引数组的初始维相同。在最直接的情况下，布尔数组具有相同的形状：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; b = y&gt;20</span><br><span class="line">&gt;&gt;&gt; y[b]</span><br><span class="line">array([21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34])</span><br></pre></td></tr></table></figure>
<p>与整数索引数组不同，在布尔情况下，结果是一维数组，其中包含索引数组中所有对应于布尔数组中所有真实元素的元素。索引数组中的元素始终以行优先（C样式）顺序进行迭代和返回。结果也与<code>y[np.nonzero(b)]</code>相同。与索引数组一样，返回的是数据的副本，而不是像切片一样获得的视图。</p>
<p>如果y比b的维数更高，则结果将是多维的。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; b[:,5] # use a 1-D boolean whose first dim agrees with the first dim of y</span><br><span class="line">array([False, False, False,  True,  True], dtype=bool)</span><br><span class="line">&gt;&gt;&gt; y[b[:,5]]</span><br><span class="line">array([[21, 22, 23, 24, 25, 26, 27],</span><br><span class="line">       [28, 29, 30, 31, 32, 33, 34]])</span><br></pre></td></tr></table></figure>
<p>这里第4行和第5行是从索引数组中选择出来的，并组合起来构成一个二维数组。</p>
<p>一般来说，当布尔数组的维数小于被索引的数组时，这相当于<code>y[b, ...]</code></p>
<h4 id="组合索引和切片"><a href="#组合索引和切片" class="headerlink" title="组合索引和切片"></a>组合索引和切片</h4><p>索引数组可以与切片组合。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y[np.array([0,2,4]),1:3]</span><br><span class="line">array([[ 1,  2],</span><br><span class="line">       [15, 16],</span><br><span class="line">       [29, 30]])</span><br></pre></td></tr></table></figure>
<p>实际上，切片被转换为索引数组<code>np.array([[1,2]])</code>（形状（1,2）），该数组与索引数组一起广播以产生形状的结果数组（3,2） 。</p>
<p>同样，切片可以与广播布尔指数结合使用：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y[b[:,5],1:3]</span><br><span class="line">array([[22, 23],</span><br><span class="line">       [29, 30]])</span><br></pre></td></tr></table></figure>

<h4 id="结构化索引工具"><a href="#结构化索引工具" class="headerlink" title="结构化索引工具"></a>结构化索引工具</h4><p>为了便于将数组形状与表达式和赋值相匹配，可以在数组索引中使用np.newaxis对象来添加大小为1的新维度。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; y.shape</span><br><span class="line">(5, 7)</span><br><span class="line">&gt;&gt;&gt; y[:,np.newaxis,:].shape</span><br><span class="line">(5, 1, 7)</span><br></pre></td></tr></table></figure>
<p>请注意，数组中没有新元素，只是增加了维度。这可以很方便地以一种其他方式需要明确重塑操作的方式组合两个数组。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(5)</span><br><span class="line">&gt;&gt;&gt; x[:,np.newaxis] + x[np.newaxis,:]</span><br><span class="line">array([[0, 1, 2, 3, 4],</span><br><span class="line">       [1, 2, 3, 4, 5],</span><br><span class="line">       [2, 3, 4, 5, 6],</span><br><span class="line">       [3, 4, 5, 6, 7],</span><br><span class="line">       [4, 5, 6, 7, 8]])</span><br></pre></td></tr></table></figure>
<p>省略号语法可以用于指示完整地选择任何剩余的未指定的维度。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; z = np.arange(81).reshape(3,3,3,3)</span><br><span class="line">&gt;&gt;&gt; z[1,...,2]</span><br><span class="line">array([[29, 32, 35],</span><br><span class="line">       [38, 41, 44],</span><br><span class="line">       [47, 50, 53]])</span><br></pre></td></tr></table></figure>
<p>这相当于：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; z[1,:,:,2]</span><br><span class="line">array([[29, 32, 35],</span><br><span class="line">       [38, 41, 44],</span><br><span class="line">       [47, 50, 53]])</span><br></pre></td></tr></table></figure>

<h4 id="给被索引的数组赋值"><a href="#给被索引的数组赋值" class="headerlink" title="给被索引的数组赋值"></a>给被索引的数组赋值</h4><p>如前所述，可以使用单个索引，切片以及索引和掩码数组来选择数组的子集。分配给索引数组的值必须是形状一致的（形状与索引产生的形状相同或相同）。例如，允许为切片分配一个常量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(10)</span><br><span class="line">&gt;&gt;&gt; x[2:7] = 1</span><br></pre></td></tr></table></figure>
<p>或者正确大小的数组：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[2:7] = np.arange(5)</span><br></pre></td></tr></table></figure>
<p>请注意，如果将较高类型分配给较低类型（在int类型中添加浮点数（floats））或甚至导致异常（将复数分配给int/float类型），分配可能会导致更改：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x[1] = 1.2</span><br><span class="line">&gt;&gt;&gt; x[1]</span><br><span class="line">1</span><br><span class="line">&gt;&gt;&gt; x[1] = 1.2j</span><br><span class="line">&lt;type &#x27;exceptions.TypeError&#x27;&gt;: can&#x27;t convert complex to long; use</span><br><span class="line">long(abs(z))</span><br></pre></td></tr></table></figure>
<p>与一些引用（如数组和掩码索引）不同，赋值通常是对数组中的原始数据进行赋值的（事实上，没有其他意义了！）。但请注意，有些行为可能不会如人们所期望的那样行事。这个特殊的例子通常令人惊讶：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x = np.arange(0, 50, 10)</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([ 0, 10, 20, 30, 40])</span><br><span class="line">&gt;&gt;&gt; x[np.array([1, 1, 3, 1])] += 1</span><br><span class="line">&gt;&gt;&gt; x</span><br><span class="line">array([ 0, 11, 20, 31, 40])</span><br></pre></td></tr></table></figure>
<p>人们预计第一个地点会增加3。实际上，它只会增加1。原因是因为从原始数据（作为临时数据）中提取了一个新的数组，其中包含1,1,1,1,1,1的值，则将值1添加到临时数据中，然后将临时数据分配回原始数组。因此，<code>x[1]+1</code>处的数组值被分配给<code>x[1]</code>三次，而不是递增3次。</p>
<h4 id="处理程序中可变数量的索引"><a href="#处理程序中可变数量的索引" class="headerlink" title="处理程序中可变数量的索引"></a>处理程序中可变数量的索引</h4><p>索引语法非常强大，但在处理可变数量的索引时受到限制。例如，如果你想编写一个可以处理各种维数参数的函数，而不必为每个可能维数编写特殊的代码，那又怎么办？如果向元组提供元组，则该元组将被解释为索引列表。例如（使用数组z的前一个定义）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; z = np.arange(81).reshape(3,3,3,3)</span><br><span class="line">&gt;&gt;&gt; indices = (1,1,1,1)</span><br><span class="line">&gt;&gt;&gt; z[indices]</span><br><span class="line">40</span><br></pre></td></tr></table></figure>
<p>所以可以使用代码来构造任意数量的索引的元组，然后在索引中使用这些元组。</p>
<p>切片可以通过在Python中使用slice()函数在程序中指定。例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; indices = (1,1,1,slice(0,2)) # same as [1,1,1,0:2]</span><br><span class="line">&gt;&gt;&gt; z[indices]</span><br><span class="line">array([39, 40])</span><br></pre></td></tr></table></figure>
<p>同样，省略号可以通过使用省略号对象的代码指定：</p>
<p>````</p>
<blockquote>
<blockquote>
<blockquote>
<p>indices = (1, Ellipsis, 1) # same as [1,…,1]<br>z[indices]<br>array([[28, 31, 34],<br>       [37, 40, 43],<br>       [46, 49, 52]])</p>
</blockquote>
</blockquote>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">由于这个原因，可以直接使用np.where()函数的输出作为索引，因为它总是返回索引数组的元组。</span><br><span class="line"></span><br><span class="line">由于元组的特殊处理，它们不会自动转换为列表。举个例子：</span><br></pre></td></tr></table></figure>
<blockquote>
<blockquote>
<blockquote>
<p>z[[1,1,1,1]] # produces a large array<br>array([[[[27, 28, 29],<br>         [30, 31, 32], …<br>z[(1,1,1,1)] # returns a single value<br>40<br>```</p>
</blockquote>
</blockquote>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/" class="post-title-link" itemprop="url">统计学系方法-第4章-朴素贝叶斯法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-21 21:03:44" itemprop="dateCreated datePublished" datetime="2019-08-21T21:03:44+08:00">2019-08-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>朴素贝叶斯（naive Bayes）法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定的输入 x，利用贝叶斯定理求出后验概率的最大输出 y。</p>
<h2 id="朴素贝叶斯法的学习与分类"><a href="#朴素贝叶斯法的学习与分类" class="headerlink" title="朴素贝叶斯法的学习与分类"></a>朴素贝叶斯法的学习与分类</h2><h3 id="基本方法"><a href="#基本方法" class="headerlink" title="基本方法"></a>基本方法</h3><p>朴素贝叶斯法对条件概率分布作了条件独立性的假设。由于这是一个较强的假设，朴素贝叶斯法也由此得名。具体地，条件独立性假设是 <img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%9D%A1%E4%BB%B6%E7%8B%AC%E7%AB%8B%E5%81%87%E8%AE%BE.png" alt="条件独立假设"></p>
<p>朴素贝叶斯法实际上学习到生成数据的机制，所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下都是条件独立的。这一假设使朴素贝叶斯法变得简单，但有时会牺牲一定的分类准确率。</p>
<p>后验概率计算根据贝叶斯定理进行：<img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87.png" alt="后验概率"></p>
<h2 id="朴素贝叶斯法的参数估计"><a href="#朴素贝叶斯法的参数估计" class="headerlink" title="朴素贝叶斯法的参数估计"></a>朴素贝叶斯法的参数估计</h2><h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p><img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1.png" alt="极大似然估计"></p>
<h3 id="学习与分类算法"><a href="#学习与分类算法" class="headerlink" title="学习与分类算法"></a>学习与分类算法</h3><p>朴素贝叶斯算法（naive Bayes algorithm）<br><img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95.png" alt="朴素贝叶斯算法"></p>
<h3 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h3><p>用极大似然估计可能会出现所要估计的概率为 0 的情况。这时会影响到后验概率的计算结果，使分类产生偏差。解决这一问题的方法是采用贝叶斯估计。具体地，条件概率的贝叶斯估计是 <img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1.png" alt="条件概率的贝叶斯估计"> 式中 λ&gt;=0。等价于在随机变量各个取值的频数上赋予一个正数 λ&gt;0。当 λ=0 时就是极大似然估计。常取 λ=1，这时称为拉普拉斯平滑（Laplace smoothing）。显然，对任何 l=1,2,…,K。有 <img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91.png" alt="拉普拉斯平滑">。同样，先验概率的贝叶斯估计是 <img src="/2019/08/21/%E9%98%85%E8%AF%BB/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%AC%AC4%E7%AB%A0-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/%E5%85%88%E9%AA%8C%E6%A6%82%E7%8E%87%E7%9A%84%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1.png" alt="先验概率的贝叶斯估计"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://wetts.github.io/2019/08/19/%E6%95%B0%E5%AD%A6/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Zhang Wetts">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p>">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wetts's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2019/08/19/%E6%95%B0%E5%AD%A6/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" class="post-title-link" itemprop="url">A基本概念</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-08-19 14:57:42" itemprop="dateCreated datePublished" datetime="2019-08-19T14:57:42+08:00">2019-08-19</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B0%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">数学</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ul>
<li><p>中心极限定理：说明的是在一定条件下，大量独立随机变量的平均数是以正态分布为极限的。而大数定律只是揭示了大量随机变量的平均结果，但没有涉及到随机变量的分布的问题。</p>
</li>
<li><p>大数定律</p>
<ul>
<li>伯努利大数定律：证明了在多次相同的条件的重复试验中，频率有越接近一稳定值的趋势。也告诉了我们当实验次数很大时，可以用事件发生的频率来代替事件的概率。</li>
<li>辛钦大数定律：用算术平均值来近似实际真值是合理的，而在数理统计中，用算术平均值来估计数学期望就是根据此定律，这一定律使算术平均值的法则有了理论依据。</li>
<li>切比雪夫大数定律：随着样本容量n的增加，样本平均数将接近于总体平均数。 从而为统计推断中依据样本平均数估计总体平均数提供了理论依据。 同分布，相较于伯努利大数定律和辛钦大数定律更具一般性。</li>
</ul>
</li>
<li><p>百分位数（percentile）：如果将一组数据从小到大排序，并计算相应的累计百分位，则某一百分位所对应数据的值就称为这一百分位的百分位数。可表示为：一组n个观测值按数值大小排列。如，处于p%位置的值称第p百分位数。</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/70/">70</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhang Wetts"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhang Wetts</p>
  <div class="site-description" itemprop="description">Stay Hungry, Stay Foolish. <br><br><p style="font-size:8px;">[build by hexo/next/gitalk/hexo-generator-search/LaTeX]</p></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">694</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">65</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">343</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wetts" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;wetts" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zhang.wetts@163.com" title="E-Mail → mailto:zhang.wetts@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhang Wetts</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hibiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
</html>
